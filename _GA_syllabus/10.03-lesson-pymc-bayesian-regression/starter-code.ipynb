{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\"> \n",
    "# Lesson: PyMC & Bayesian Regression\n",
    "\n",
    "_Authors: Tim Book, Matt Brems, Noelle Brown_\n",
    "\n",
    "## LEARNING OBJECTIVES\n",
    "By the end of the lesson, students should be able to:\n",
    "- Define conjugacy.\n",
    "- Fit models in PyMC.\n",
    "- Interpret traceplots, posterior distributions, and posterior predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## Recap\n",
    "Remember that parameters have distributions. In Bayesian statistics, our goal is to **find the posterior distribution of our parameter of interest**.\n",
    "\n",
    "<details><summary>In order to generate a posterior distribution, what are the two components we need?</summary>\n",
    "\n",
    "- Prior distribution summarizing our beliefs about the parameter before observing any data.\n",
    "- Likelihood function summarizing how our data were generated.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Bayes?\n",
    "There are several reasons why we would prefer to use a Bayesian technique over a frequentist one. What are they? (THREAD)\n",
    "\n",
    "<details>\n",
    "    <summary>What are some reasons to use Bayesian techniques?</summary>\n",
    "    \n",
    "* When you have prior knowledge of a situation (ie, you might no better than data suggests)\n",
    "* When you have small data that can benefit from additional subject matter expertise\n",
    "* When you want to be able to make advanced probabilistic statements that are unavailable to frequentist techniques\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pymc3\n",
    "# !pip install pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Skittles!\n",
    "In a snack-size pack of Skittles, you are concerned with getting an unfair amount of green Skittles (the worst flavor). You think there are about 20 skittles per pack. There are 5 different colors of Skittles. \n",
    "\n",
    "<img src=\"./images/skittles.jpeg\" style=\"height: 300px\"> \n",
    "\n",
    "How can we determine if we get an unfair amount of green Skittles?\n",
    "\n",
    "**A frequentist would...**\n",
    "- Open many snack-size packs of Skittles, and estimate $\\hat{p}$, the probability of getting a green skittle.\n",
    "- Conduct a hypothesis test to determine if $p = 0.2$.\n",
    "\n",
    "**A Bayesian would...**\n",
    "- Begin with a preconceived notion about $p$ (a prior). This prior reflects not just our belief, but the strength of our belief.\n",
    "- Open many snack-size packs of Skittles and record the results (the likelihood).\n",
    "- Obtain a posterior distribution for $p$ that combines our priors with our data.\n",
    "- Make statements about this posterior.\n",
    "\n",
    "What is the (posterior) distribution of the number of green skittles I might find in a pack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import green skittle count data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define our likelihood and priors\n",
    "\n",
    "We'll start with our priors. \n",
    "\n",
    "What do we know/believe about the percentage of green skittles we might find in a pack? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What distribution will be best for this?</summary>\n",
    "\n",
    "- The percentage of green skittles we might find in a pack is a number between 0 and 1.\n",
    "- The Beta distribution will be good here!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Beta Distribution\n",
    "Recall that the beta distribution is a **continuous** distribution. It's often used in Bayesian statistics because it's one of the only continuous distributions that take values between 0 and 1. This makes it particularly convenient to use as a prior on probabilities.\n",
    "\n",
    "You can take a closer look at the Beta distribution [here](https://en.wikipedia.org/wiki/Beta_distribution)!\n",
    "\n",
    "If $X \\sim \\text{Beta}(a, b)$, then\n",
    "\n",
    "* $\\text{E}[X] = \\frac{a}{a + b}$\n",
    "* $\\text{Var}[X] = \\frac{ab}{(a + b)^2(a + b + 1)}$\n",
    "\n",
    "Also note: The $\\text{Beta}(1, 1)$ distribution is actually the $\\text{Uniform}(0, 1)$ distrubtion!\n",
    "\n",
    "Let's compute some beta means and variances. What do you think is a reasonable prior for our problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>In my opinion, setting up your priors and likelihoods is the hardest part of Bayesian inference.</summary>\n",
    "\n",
    "![](./images/modified_bayes.png)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_stats(a, b):\n",
    "    mean_ = a / (a + b)\n",
    "    var_ = a*b / ((a + b)**2 * (a + b + 1))\n",
    "    return mean_, var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We want the mean to be about 0.2 (20% of each flavor)\n",
    "beta_stats( , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior for percentage of green skittles we might find in a pack\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>We can also set a prior on the number of Skittles that are in a pack! What distribution will be best for this?</summary>\n",
    "\n",
    "- The number of Skittles in each pack is count data.\n",
    "- The Poisson distribution will work well here!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior for number of Skittles in a pack\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define our likelihood. \n",
    "\n",
    "We are interested in seeing how many green Skittles are in a bag.\n",
    "\n",
    "There's a fixed number of Skittles in a bag. Each of those Skittles has some probability of being green or not green.\n",
    "We are looking to see if a Skittle is green or not in our bag. \n",
    "\n",
    "A good tip from [Bayesian Methods for Hackers:](https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC3.ipynb)  \n",
    "> \"A good starting thought to Bayesian modeling is to think about how your data might have been generated. Position yourself in an omniscient position, and try to imagine how you would recreate the dataset.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What distribution will be best for this?</summary>\n",
    "\n",
    "- Each Skittle has some probability of being green and some probability of being not green.\n",
    "- The Binomial distribution will work here.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC Using PyMC3\n",
    "Markov chain Monte Carlo methods (commonly abbreviated MCMC methods) made conjugacy mostly unnecessary.\n",
    "\n",
    "![](./images/pymc3-res.png)\n",
    "\n",
    "[TL;DR](https://en.wikipedia.org/wiki/TL;DR) of MCMC: We use computers to take our prior and likelihood, then simulate a large number of samples from the posterior.\n",
    "- If I want to find the mean of my posterior distribution, then I can just do `np.mean(xs)`, where `xs` is my saved list of samples from my posterior.\n",
    "- If I want to find the median of my posterior distribution, then I can do `np.median(xs)`.\n",
    "- If I want to find the 95% [credible interval](http://www.statisticshowto.com/credible-interval/) for my parameter based on the posterior distribution of my parameter, then I can just find the 2.5th and 97.5th percentiles of `xs`!\n",
    "\n",
    "Today, we're going to use `PyMC3`, a Bayesian modeling library in Python that will enable us to use Markov chain Monte Carlo methods. Luckily, this is a package that is geared toward scientists, not necessarily statisticians. We'll be able to use what we currently know about Bayesian statistics to leverage this *really* powerful library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Situation:\n",
    "$$\n",
    "\\begin{align}\n",
    "    X | p &\\sim \\text{Binomial}(n, p) \\\\\n",
    "        p &\\sim \\text{Beta}(a, b)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We've also observed a certain number of greens in our 20 bags (our data).\n",
    "\n",
    "### PyMC3 models live in \"contexts\" instead of \"objects\"\n",
    "That means they'll look something like this:\n",
    "\n",
    "```python\n",
    "with pm.Model() as model:\n",
    "    # Define priors\n",
    "    # Define likelihood\n",
    "    # Execute MCMC\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Let's set this up in PyMC3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PyMC3 to solve for the posterior distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected mean that an individual skittle will be grean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected amount of green skittles is number of skittles in bag * prob of green\n",
    "mean_green = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the probability we will get an expected value of between 5 and 6 green skittles?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Election Day\n",
    "\n",
    "Let's review the election example from the other day using polling data from [FiveThirtyEight](https://projects.fivethirtyeight.com/2020-election-forecast/). This time, we will look at the probability that Trump wins.\n",
    "\n",
    "Reminder: our polls gave us the following totals:\n",
    "\n",
    "```python\n",
    "n_biden = 7_616 # number of successes\n",
    "n_surveys = 14_995 # number of trials\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the results of our polls.\n",
    "# 1 = Trump led the poll\n",
    "# 0 = Biden led the poll\n",
    "polls = np.array([1]*7379 + [0]*7616)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Establish our priors and our likelihood\n",
    "\n",
    "Here we are looking for the percentage of votes Trump is likely to win in the election.\n",
    "\n",
    "An important thing to note is that there is no such thing as sample data for problems like this, since elections only ever happen once. This is why pollsters conduct polls - to gather information about what will _probably_ happen in the future. Polls aren't perfect though, and they also change over time. **We know through personal experience that most elections end up being very close to 50/50.**\n",
    "\n",
    "We can use the Beta distribution for our prior. We need a mean of .5 (because we expect the election to be 50/50).\n",
    "\n",
    "_Hint:_ The priors are as subjective as they can get here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set up the PyMC3 model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyMC3 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traceplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Expected value that Trump will get more than 50% of the votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we didn't take any outside factors into account (which FiveThirtyEight does) or even talk about the electoral college. Read more about FiveThirtyEight's modeling [here](https://fivethirtyeight.com/features/how-fivethirtyeights-2020-presidential-forecast-works-and-whats-different-because-of-covid-19/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Bayesian Regression for Pay Equity\n",
    "It is an often-recited statistic that women are paid about 77 cents per dollar a man makes for equal work. But how is this number (and others like it) calculated? We actually conduct a log-regression based on a person's legitimate skill level (ie, things such as education or years of experience that may legitimately contribute to you being paid more) and an indicator for the protected class. For example:\n",
    "\n",
    "$$ \\log W = \\beta_0 + \\beta_1\\text{skill} + \\beta_2\\text{class} $$\n",
    "\n",
    "After exponentiating both sides:\n",
    "\n",
    "$$ W = e^{\\beta_0 + \\beta_1\\text{skill}}e^{\\beta_2\\text{class}} $$\n",
    "\n",
    "Where $e^{\\beta_2\\text{class}}$ simplifies to:\n",
    "\n",
    "* $e^{\\beta_2}$ if you are the (potentially) discriminated class.\n",
    "* $e^0 = 1$ if you are not the (potentially) discriminated class.\n",
    "\n",
    "Thus, given a dataset of salaries at a company, we might seek to estimate $e^{\\beta_2\\text{class}}$ to prove/disprove pay equity discrimination. Using the power of Bayesian statistics, we can actually begin with a prior assumption of _no_ pay inequity in order to allow the data to contradict it if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wages data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: What are the priors and likelihood?\n",
    "We actually have _four_ variables to set priors on here. Most of them we actually don't have any relevant prior information for. We might set these as **noninformative priors** - that is, priors that are incredibly vague and provide no information:\n",
    "\n",
    "* $\\beta_0$ and $\\beta_1$ - noninformative, we have no prior information.\n",
    "* $\\sigma$ - the model's variance - also noninformative, we have no good guesses.\n",
    "* $\\beta_2$ - the coefficient of protected class. We'll put a prior that assumes $\\beta_2 \\approx 0$ in order to assume innocence.\n",
    "\n",
    "For the likelihood, remember our parametrization of OLS as a GLM:\n",
    "\n",
    "$$Y = \\mathbf{x}^T\\beta + \\varepsilon$$\n",
    "\n",
    "where $\\varepsilon \\sim N(0, \\sigma)$, and so\n",
    "\n",
    "$$ Y \\sim N(\\mathbf{x}^T\\beta, \\sigma) $$\n",
    "\n",
    "So we can write \n",
    "\n",
    "$$ \\log W \\sim N(\\beta_0 + \\beta_1\\text{skill} + \\beta_2\\text{class}, \\sigma) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priors\n",
    "\n",
    "\n",
    "# Likelihoods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: PyMC3 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyMC3 Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traceplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponentiate beta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected value for e^beta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = wages.loc[:, [\"skill\", \"class\"]]\n",
    "X = sm.add_constant(X)\n",
    "y = np.log(wages[\"wage\"])\n",
    "lm = sm.OLS(y,X).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was actually simulated to be 0.8\n",
    "np.exp(-0.1853)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
