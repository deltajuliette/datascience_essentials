# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Regularizing Neural Networks

---

## Materials We Provide


| Topic | Description | Link |
| --- | --- | --- |
| Lesson | Regularizing Neural Networks | [Link](./starter-code.ipynb)|

---

## Learning Objectives

*After this lesson, students will be able to:*

1. Explain how the three deep learning regularization techniques work
    * L1/L2 regularization
    * Dropout
    * Early stopping
2. Implement these techniques in Keras

---

## Student Requirements

*Before this lesson(s), students should already be able to:*

1. Describe the basic anatomy of a feed forward neural network.
1. Fit a simple feed forward neural network in Keras.

## Lesson Outline


I. L1/L2 Regularization  
II. Dropout  
III. Early Stopping  

---

## OPTIONAL: Resources for Practice and Learning

*For supplemental reading material on this topic, check out the following resources:*

- [Blog on L1 & L2 Regularization](https://www.machinecurve.com/index.php/2020/01/21/what-are-l1-l2-and-elastic-net-regularization-in-neural-networks/)
- [Blog on L1, L2, & Dropout](https://towardsdatascience.com/regularization-in-deep-learning-l1-l2-and-dropout-377e75acc036)
- [Summary of all three techniques, plus data augmentation](https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/)

---

#### Authors
Matt Brems, Tim Book, Justin Pounders

---