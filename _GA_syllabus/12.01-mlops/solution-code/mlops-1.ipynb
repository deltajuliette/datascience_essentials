{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55542b27-2109-4885-8822-48f3817c34cb",
   "metadata": {},
   "source": [
    "# Machine Learning Operations (MLOps) - Part 1\n",
    "\n",
    "> MLOps is a set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently. The word is a compound of \"machine learning\" and the continuous development practice of DevOps in the software field\n",
    "\n",
    "Source: [Wikipedia](https://en.wikipedia.org/wiki/MLOps)\n",
    "\n",
    "- MLOps is a very big topic with several components such as\n",
    "    1. Experiment tracking\n",
    "    1. Model packaging and versioning\n",
    "    1. Model deployment for real time predictions\n",
    "    1. Model deployment for batch predictions\n",
    "    1. Deployment monitoring\n",
    "    1. End to End automations\n",
    "    1. etc\n",
    "- In general, most modern DS organizations have atleast a small MLOps team of 2-4 people. Bigger organizations can have entire teams of MLOps engineers. \n",
    "- MLOps or ML Engineering has become an individual field by itself similar to Data Science, Data Engineering or Data Analytics\n",
    "- Despite this, *\"No knowledge is wasted!\"* Even if you want to be a Data Scientist or Data Analyst, having basic MLOps knowledge will make your skills more well rounded and more employable!\n",
    "- Luckily for us, there are several frameworks available nowadays that abstract away the complex and repeatable parts of MLOps.\n",
    "- In this series of lessons, we'll focus on taking an ML model to production (Model deployment).\n",
    "    - We'll do it using technologies that we already covered in this course so far: [Flask](https://flask.palletsprojects.com/en/2.0.x/)\n",
    "    - You can simplify a lot of the development by directly using more high level libraries like [Bento ML](https://www.bentoml.com/). I'll leave this up to you to experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aba17f-90d9-4f27-a500-3ca0ef85025b",
   "metadata": {},
   "source": [
    "# Flask (Recap)\n",
    "- Microservices architecture [Link](https://docs.google.com/presentation/d/1oT4tqCMQjpkF5ZchsnBEsqbUP6E3PcfrB-KGjRDjyHE)\n",
    "![](../images/microservice.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719a43f-c631-4e2d-9992-61d066d591c4",
   "metadata": {},
   "source": [
    "# Local Serving\n",
    "To use Flask to package and deploy our model locally, we need to do the following\n",
    "1. Train an ML model as per normal\n",
    "1. Save the model as per normal\n",
    "1. Test the saved model\n",
    "1. [NEW] Create a `serve.py` file to serve the saved model as a Flask API\n",
    "1. [NEW] Test the `serve.py` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e85e7-5fdf-4559-b436-1a808e442950",
   "metadata": {},
   "source": [
    "## 1. Train an ML model as per normal\n",
    "- Download the dataset from here: [Link](https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip). Download and unzip the file into the data directory\n",
    "- Below code is directly copied from [9.04-lesson-cnn](../../9.04-lesson-cnn/solution-code/solution-code.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb39333-038a-470d-a9aa-412df7daa35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d5cb99-7cf3-4297-9174-3c2898bfb218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2001 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the Train and Validation data\n",
    "train_data = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory('../data/cats_and_dogs_filtered/train/', \n",
    "                                                                                             target_size=(224,224), \n",
    "                                                                                             class_mode='binary'\n",
    "                                                                                            )\n",
    "\n",
    "val_data = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory('../data/cats_and_dogs_filtered/validation/', \n",
    "                                                                                           target_size=(224,224), \n",
    "                                                                                           class_mode='binary'\n",
    "                                                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "756db18a-4b16-4111-8b92-ec52b5ad3055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 11:12:23.970200: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import the desired pre-trained model\n",
    "# List of pre-trained models: https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "pre_trained_model = MobileNetV2(include_top=False, pooling='avg')\n",
    "\n",
    "# Freeze the model so we don't accidentally change the pre-trained model\n",
    "pre_trained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64738e67-0776-49f3-9568-b74725e41c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create our model architecture\n",
    "trf_model = Sequential()\n",
    "\n",
    "# Then add the pre-trained model to use Transfer Learning\n",
    "trf_model.add(pre_trained_model)\n",
    "\n",
    "# Finally add our custom modifications\n",
    "trf_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "trf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "133e70e1-5a79-4ecc-9d1e-f934700f50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "opt = Adam(learning_rate=0.001)\n",
    "trf_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0779608a-d082-4db7-9878-d4f32cbc012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "63/63 [==============================] - 62s 944ms/step - loss: 0.2508 - accuracy: 0.9000 - val_loss: 0.0956 - val_accuracy: 0.9740\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 63s 996ms/step - loss: 0.0772 - accuracy: 0.9800 - val_loss: 0.0674 - val_accuracy: 0.9810\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 59s 946ms/step - loss: 0.0568 - accuracy: 0.9815 - val_loss: 0.0593 - val_accuracy: 0.9800\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 58s 919ms/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.0549 - val_accuracy: 0.9800\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 58s 925ms/step - loss: 0.0397 - accuracy: 0.9895 - val_loss: 0.0508 - val_accuracy: 0.9820\n"
     ]
    }
   ],
   "source": [
    "# Fit model on training data\n",
    "history = trf_model.fit(train_data, \n",
    "                        batch_size=64,\n",
    "                        validation_data=val_data,\n",
    "                        epochs=5,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce50bb6-fc0a-402e-8e7f-0a72fd10626a",
   "metadata": {},
   "source": [
    "## 2. Save the model as per normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a053735-1128-4b5e-92ed-daa3ed16c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trf_model.save('cats_vs_dogs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66e661-3114-448a-9ab8-7f4a69b5ec19",
   "metadata": {},
   "source": [
    "## 3. Test the saved model as per normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee7f499-c91d-42ab-81fa-e30d752e6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e49fa2c-cc5c-4018-bea5-d40f493edbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images into Python\n",
    "images = ['../images/test.jpeg', '../images/test_1.jpeg']\n",
    "test_images = [image.load_img(img, target_size=(224, 224)) for img in images]\n",
    "\n",
    "# Convert the images to a matrix of numbers\n",
    "test_images = [image.img_to_array(img).tolist() for img in test_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4859019-ab58-4e77-8e10-522a07462b2b",
   "metadata": {},
   "source": [
    "----\n",
    "We can decide to use the code below this line in the Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1f81fd8-a93b-4d34-a5a2-40f1b3b025f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "trf_model = load_model('cats_vs_dogs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1fac7fa-ec25-4db3-8f30-2cb86738181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "test_images = preprocess_input(np.array(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a61d0b7-af36-4acb-818d-ec9cf9de0596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dog', 'Cat']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "result = trf_model.predict(test_images)\n",
    "\n",
    "# Convert the probability to actual predictions\n",
    "['Dog' if pred[0]>0.5 else 'Cat' for pred in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45e1c7-2e21-4994-972e-18cbaf9666ed",
   "metadata": {},
   "source": [
    "## 4. [NEW] Create a `serve.py` file to serve the saved model as a Flask API\n",
    "\n",
    "Copy this code into a new `serve.py` file\n",
    "\n",
    "```\n",
    "from flask import Flask, request\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "app = Flask('myApp')\n",
    "\n",
    "# Load in the model outside any route so that we load the model only once\n",
    "# Loading the model takes time (especially deep learning models)\n",
    "# So if you happen to load the model inside a route, it'll load every single time a request is received which is very inefficient\n",
    "trf_model = load_model('cats_vs_dogs.h5')\n",
    "\n",
    "# route 1: Return Success status\n",
    "@app.route('/')\n",
    "def home():\n",
    "    # return a simple string\n",
    "    return {\"success\": True}, 200\n",
    "\n",
    "# route 2: accept input data\n",
    "# Post method is used when we want to receive some data from the user\n",
    "@app.route('/predict', methods = ['POST'])\n",
    "def make_predictions():\n",
    "    # Get the data sent over the API\n",
    "    user_input = request.get_json(force=True)\n",
    "    data = user_input['X']\n",
    "    \n",
    "    # Preprocess\n",
    "    data = preprocess_input(np.array(data))\n",
    "\n",
    "    # Make predictions\n",
    "    result = trf_model.predict(data)\n",
    "\n",
    "    # Convert the probability to actual predictions\n",
    "    predictions = ['Dog' if pred[0]>0.5 else 'Cat' for pred in result]\n",
    "\n",
    "    # return the results with our predictions\n",
    "    return {'response': predictions}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Run the App!\n",
    "    app.run(host='0.0.0.0', debug=True, port=int(os.environ.get(\"PORT\", 8080)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1732c424-7a6d-401b-a019-cecc924f3c01",
   "metadata": {},
   "source": [
    "## 5. [NEW] Test the serve.py file\n",
    "- Open a new terminal and run the below commands to start the flask server on your machine.\n",
    "```\n",
    "conda activate dsi-sg\n",
    "cd 12.01-mlops/solution-code\n",
    "python serve.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cdb258f-6fb7-4129-94b8-ef98b9589cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5256df3-715a-4cb8-bd8a-ec2c128b39a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images into Python\n",
    "images = ['../images/test.jpeg', '../images/test_1.jpeg']\n",
    "test_images = [image.load_img(img, target_size=(224, 224)) for img in images]\n",
    "\n",
    "# Convert the images to a matrix of numbers\n",
    "test_images = [image.img_to_array(img).tolist() for img in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb66c1bb-2955-4cc3-a498-5cbaab889c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': ['Dog', 'Cat']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = {'X': test_images}\n",
    "\n",
    "# IP address 127.0.0.1 is your local machine\n",
    "response = requests.post('http://127.0.0.1:8080/predict', json=user_input)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc651b-2b20-45f4-bd79-249ccd6c2a69",
   "metadata": {},
   "source": [
    "# Cloud Serving\n",
    "- Once we have the model file and the serve.py, we can run this serve.py file from a machine in the cloud as well!\n",
    "- Running on a cloud virtual machine involves a few steps. They are not very user friendly, so we will never actually do this in production. Just showing the steps here to convince you the same code can run on any machine as long as the dependencies are met\n",
    "\n",
    "## Below are a one time setup on your GCP project\n",
    "- Create a new firewall rule to allow internet traffic into your VM as mentioned here: [Link](https://serverfault.com/questions/831273/unable-to-reach-a-python-flask-enabled-web-server-on-gce). \n",
    "- Beware! this is not secure and you should not do this for your company data!\n",
    "- Rather you should get your company's IT to setup the required firewall rules for you.\n",
    "\n",
    "## Below are one time setup when creating the Virtual Machine for the first time\n",
    "1. Create a server on the cloud. Let's use a Google Cloud Compute Engine VM to deploy this model\n",
    "    - Change `Boot Disk` from `Debian` to `Ubuntu 20.04 LTS`\n",
    "    - Allow HTTPS and HTTP traffic\n",
    "1. Once the machine is created, connect to it by clicking on the SSH button.\n",
    "\n",
    "### Below is a one time setup if you are provided a server by someone else\n",
    "1. Install Anaconda by running these commands in the SSH terminal\n",
    "    ```\n",
    "    # download anaconda for linux from the official website\n",
    "    wget https://repo.anaconda.com/archive/Anaconda3-2021.11-Linux-x86_64.sh\n",
    "\n",
    "    # install downloaded anaconda\n",
    "    sh Anaconda3-2021.11-Linux-x86_64.sh\n",
    "\n",
    "    # source the bashrc to be able to access the newly installed conda\n",
    "    source ~/.bashrc\n",
    "    ```\n",
    "\n",
    "## Below is a one time setup for each new project\n",
    "1. Create an Anaconda environment for the project\n",
    "    ```\n",
    "    # Create an anaconda environment for our model to run and activate it\n",
    "    conda create --name=cats_v_dogs python=3.8 -y\n",
    "    conda activate cats_v_dogs\n",
    "\n",
    "    # Install any libraries that are needed in this environment\n",
    "    pip install numpy flask tensorflow\n",
    "    ```\n",
    "1. Upload our model and serving files to the VM. You can also use [Filezilla](https://filezilla-project.org/) if you're using a server provided by your company.\n",
    "1. Create a directory to store our files and move the uploaded files into it \n",
    "    ```\n",
    "    mkdir cats_v_dogs \n",
    "    mv cats_vs_dogs.h5 serve.py cats_v_dogs/\n",
    "    cd cats_v_dogs\n",
    "    ls\n",
    "    ```\n",
    "1. Use tmux (terminal multiplexer) to start a terminal session in the background that wont get terminated when we close the SSH terminal window: `tmux new -s cats_v_dogs`\n",
    "1. Activate the anaconda environment: `conda activate cats_v_dogs`\n",
    "1. Run the serve.py file: `python serve.py`\n",
    "1. Press `Ctrl+b` then lift both fingers and press only `d` to exit the tmux session. Close the SSH terminal if you want to\n",
    "1. Copy the `External IP` of the VM from the GCP console webpage\n",
    "1. As long as this VM is running, you can post requests to it from anywhere on the internet!\n",
    "\n",
    "## Subsequently everytime you update your model or your serving code\n",
    "1. Replace the files in the `cats_v_dogs` directory\n",
    "1. Enter the tmux session: `tmux attach-session -t cats_v_dogs`\n",
    "1. Stop the running flask server: Ctrl+C\n",
    "1. Start the flask server again `python serve.py`\n",
    "\n",
    "## Useful snippets for `tmux`\n",
    "- Start a new tmux session: `tmux new -s session_name`\n",
    "- Detach from a tmux session: `Ctrl+b d`\n",
    "- List running tmux sessions: `tmux ls`\n",
    "- Reattach to a tmux session: `tmux attach-session -t session_name`\n",
    "- If Anaconda is not detected inside a tmux session: Exit the session, run `conda deactivate`, then create a new tmux session and Anaconda should now be detected\n",
    "\n",
    "## Clean Up\n",
    "1. Delete the VM we created\n",
    "1. Delete the very relaxed firewall rule to protect your other VMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e2eeff-985d-437c-b68d-fa2929861260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the server running on GCP\n",
    "# Same code as testing locally, only the IP address changed!\n",
    "import requests\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the images into Python\n",
    "images = ['../images/test.jpeg', '../images/test_1.jpeg']\n",
    "test_images = [image.load_img(img, target_size=(224, 224)) for img in images]\n",
    "\n",
    "# Convert the images to a matrix of numbers\n",
    "test_images = [image.img_to_array(img).tolist() for img in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a50d97-d00c-4c23-851b-22e3533ce8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': ['Dog', 'Cat']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = {'X': test_images}\n",
    "response = requests.post('http://35.227.135.198:8080/predict', json=user_input)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e70d19a-c3da-4b8a-b926-4d74b30f0d98",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- You now have the model deployed as a real time endpoint on your local machine and on a GCP VM!\n",
    "- This is one of the many ways to \"deploy\" a model\n",
    "- Pros:\n",
    "    - Simple and easy to implement\n",
    "- Cons:\n",
    "    - Not very robust. If the same machine is serving many models, each model's dependencies WILL start to clash with each other eventually!\n",
    "    - Very susceptible to \"It works on my machine cliche\"\n",
    "    - Using Anaconda environments partly solves the issues of conflicting libraries, but doesn't solve the issue of conflicting OS dependencies. \n",
    "    - There's an even better way called \"Docker\"\n",
    "\n",
    "![](../images/it-works-on-my-machine.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e88e8-93cb-41d6-be75-f6b7e7a5ed73",
   "metadata": {},
   "source": [
    "# Test your knowledge\n",
    "1. Try to package the ham vs spam TFIDF + SklearnNLP classifier model from [5.06-lesson-nlp-ii](../../5.06-lesson-nlp-ii/solution-code/solution-code.ipynb) as a Flask API.\n",
    "1. Use [FastAPI](https://fastapi.tiangolo.com/tutorial/first-steps/) instead of Flask to get auto documentation and an even faster API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3f62b-46a8-4eef-a68a-1b0f9c8eeb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
