{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55542b27-2109-4885-8822-48f3817c34cb",
   "metadata": {},
   "source": [
    "# Machine Learning Operations (MLOps) - Part 2\n",
    "\n",
    "![](../images/containers.jpeg)\n",
    "\n",
    "- [Docker](https://docs.docker.com/get-docker/) is THE MOST popular way to package code and dependencies for web applications including ML model deployments\n",
    "- Docker works on the concept of [Containers](https://www.docker.com/resources/what-container) which is a self-contained unit of OS, dependencies and code necessary to run an App\n",
    "- Docker containers are EVERYWHERE! Chances are, every single modern app or website you'll ever interact with is running in a Docker container\n",
    "- Despite being ubiquitous everywhere, it's surprisingly easy to create a docker container of your Flask App, if you stick to the basics!\n",
    "- Of course, Docker has significant depth that you can exploit to build all kinds of complex applications!\n",
    "- In this lesson, we'll use Docker to containerize our ML model flask app and run it both locally and in the cloud!\n",
    "- We start from where we left off in the previous lesson. We already have a serve.py file that can run our model as a Flask API\n",
    "- Steps\n",
    "    1. Train an ML model as per normal\n",
    "    1. Save the model as per normal\n",
    "    1. Test the saved model\n",
    "    1. Create a `serve.py` file to serve the saved model as a Flask API\n",
    "    1. Test the `serve.py` file\n",
    "    1. [NEW] Create a Docker container to package our serving code\n",
    "    1. [NEW] Test the Docker container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f818a-d187-49fd-b705-4526e0baeb37",
   "metadata": {},
   "source": [
    "# Docker\n",
    "![](../images/docker_logo.png)\n",
    "- A docker container is a mini-computer running within your computer\n",
    "- Docker allows us to create ***\"Containerized Applications\"***\n",
    "- It's smaller and more efficient than using a brand new VM for each application\n",
    "- Take a look at this [link](https://www.docker.com/resources/what-container) to read up more about docker containers\n",
    "![](../images/container_vs_VM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7964c196-1878-4285-86ff-6d6c2053c034",
   "metadata": {},
   "source": [
    "## 6. [NEW] Create a Docker container to package our serving code\n",
    "\n",
    "There are a few steps involved\n",
    "1. Create a `requirements.txt` file including all the Python libraries we need for the app to work\n",
    "1. Create a `Dockerfile` which contains the steps on how to create the Docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2addbed-c985-49a8-8975-118107f31592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.22.2\n",
      "Numpy version: 2.0.3\n",
      "Numpy version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "# Check the versions of each library that is needed by our serve.py\n",
    "import numpy as np\n",
    "import flask\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f'Numpy version: {np.__version__}')\n",
    "print(f'Flask version: {flask.__version__}')\n",
    "print(f'Tensorflow version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b7574-429e-4cb9-8083-33767ab48e10",
   "metadata": {},
   "source": [
    "### 6.1 Create a requirements.txt file including all the Python libraries we need for the app to work\n",
    "Create a `requirements.txt` file with the below contents:\n",
    "\n",
    "```\n",
    "numpy==1.22.2\n",
    "flask==2.0.3\n",
    "tensorflow==2.8.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1884a1-6543-4f1b-ac69-49526cb3ba4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6.2 Create a Dockerfile which contains the steps on how to create the Docker container\n",
    "- Create a `Dockerfile` (no file extension!) file with the below contents\n",
    "- For a complete list of all possible Dockerfile commands, see [here](https://docs.docker.com/engine/reference/builder/)\n",
    "- Below are probably the most common commands you'll ever need\n",
    "\n",
    "```\n",
    "# Use the official lightweight Python image.\n",
    "# https://hub.docker.com/_/python\n",
    "FROM python:3.8-slim\n",
    "\n",
    "# Copy all the files needed for the app to work\n",
    "COPY requirements.txt serve.py cats_vs_dogs.h5 .\n",
    "\n",
    "# Install all the necessary libraries\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "# Run the app!\n",
    "CMD python serve.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823bccc0-ca1b-4e46-82f3-ab4820eece1c",
   "metadata": {},
   "source": [
    "## 7. [NEW] Test the Docker container\n",
    "There are many many ways to run a docker container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4221887-ddd3-40c6-932b-68a36a73e0b6",
   "metadata": {},
   "source": [
    "### 7.1. Locally or any server that has installed docker. Run on Terminal: \n",
    "\n",
    "- Build the docker container from the Dockerfile in the current directory(.) \n",
    "- Give it a name given by --tag\n",
    "- Docker naming convention is <name_of_service>:<version>. latest means latest version\n",
    "    \n",
    "```\n",
    "docker build . --tag cats_v_dogs:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8014b5-36a2-483a-8b50-fa60965d0d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38275df4d27d7e34462c23c7e390c83730593ddf4279835608c2785588c30ddb\n"
     ]
    }
   ],
   "source": [
    "# Run the docker container in -d (detached) mode\n",
    "## -p 5000:5000 -> map the port 5000 in the docker container to 5000 on your local machine\n",
    "## --rm -> remove the container when its stopped (optional)\n",
    "## --name cats_v_dogs -> name the running container cats_v_dogs\n",
    "## cats_v_dogs:latest -> the name of the container to run\n",
    "\n",
    "! docker run -d -p 8080:8080 --rm --name cats_v_dogs cats_v_dogs:latest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36d8fdd-c892-4cd3-9d2b-944da40c506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the docker locally\n",
    "import requests\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8ea60d-dffa-4f95-9de4-c36af7698228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images into Python\n",
    "images = ['../images/test.jpeg', '../images/test_1.jpeg']\n",
    "test_images = [image.load_img(img, target_size=(224, 224)) for img in images]\n",
    "\n",
    "# Convert the images to a matrix of numbers\n",
    "test_images = [image.img_to_array(img).tolist() for img in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd8f55e9-ae41-48d4-9b5e-4a0b5a1f9770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': ['Dog', 'Cat']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = {'X': test_images}\n",
    "\n",
    "# Note the IP address when running docker on your local is the same as running the code directly on the terminal!\n",
    "response = requests.post('http://127.0.0.1:8080/predict', json=user_input)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9df1d0f-e845-4b17-b3a5-7f89ff12ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                COMMAND                  CREATED          STATUS         PORTS                    NAMES\n",
      "38275df4d27d   cats_v_dogs:latest   \"/bin/sh -c 'python â€¦\"   11 seconds ago   Up 9 seconds   0.0.0.0:8080->8080/tcp   cats_v_dogs\n"
     ]
    }
   ],
   "source": [
    "# To check all running and stopped docker containers\n",
    "! docker ps --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850e942a-48c9-44d0-b213-b75f386d17a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats_v_dogs\n"
     ]
    }
   ],
   "source": [
    "# To stop the running docker container using its name\n",
    "! docker stop cats_v_dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f1559a-50cf-45ac-ba7c-e9d8842fe287",
   "metadata": {},
   "source": [
    "### 7.2 To GCP Cloud Run\n",
    "- Remember to install and init [gcloud CLI](https://cloud.google.com/sdk/docs/install) before running this code\n",
    "\n",
    "```\n",
    "gcloud run deploy cats-v-dogs --source . --region us-west1\n",
    "```\n",
    "\n",
    "- Get the IP address from the URL parameter\n",
    "![](../images/GCP_cloud_run.png)\n",
    "\n",
    "- GCP Cloud run by default only allocates 512MiB Memory to your app. This is mostly not sufficient for Tensorflow models, so you can edit the deployed app to increase the Memory to 1Gib\n",
    "\n",
    "![](../images/GCP_cloud_run_edit.png)\n",
    "![](../images/GCP_cloud_run_edit_2.png)\n",
    "\n",
    "- GCP Cloud run is incredibly cheap, even [free for modest usage](https://cloud.google.com/products/calculator#id=b6498bda-2e9a-4d14-adb6-bf3915c7812f). \n",
    "- Still if you want to clean up all the GCP resources you created so that you dont pay anything. You need to delete the resources from the below 2 GCP services\n",
    "    1. Cloud Run\n",
    "    1. Artifact Registry (stores the docker image on GCP). Look inside `cloud-run-source-deploy` directory\n",
    "    1. Cloud Storage. Delete the cloud storage bucket ending with `_cloudbuild`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d355b7ac-de4f-424a-89cd-d1dc694eb62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': ['Dog', 'Cat']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the IP address when running the model in Google Cloud Run is the URL parameter\n",
    "response = requests.post('https://cats-v-dogs-a4rmk57awq-uw.a.run.app/predict', json=user_input)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450715c5-28eb-4453-b01c-a71e21a81316",
   "metadata": {},
   "source": [
    "### 7.3 To AWS Fargate \n",
    "- Follow the very well written instructions from [this Medium Post](https://towardsdatascience.com/deploy-pycaret-and-streamlit-app-using-aws-fargate-serverless-infrastructure-8b7d7c0584c2#36ea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea654bd9-b88b-40b3-876f-971b34532cec",
   "metadata": {},
   "source": [
    "### 7.4 To a Kubernetes (K8S) Cluster\n",
    "- [Kubernetes](https://kubernetes.io/) is one of the MOST scalable way to deploy a Docker container in production. It can scale to support millions of requests per second. It's what's used in most big technology companies that have high internet traffic. But, managing a Kubernetes cluster is notoriously hard and requires a team of trained people to manage effectively.\n",
    "- For most DS use cases, we don't need to worry about managing a K8S cluster. But if you even want to play around with K8S by deploying your app, you can use the below steps.\n",
    "- Steps taken from GKE documentation\n",
    "\n",
    "#### Deploy our Docker container to GKE\n",
    "1. Search `Kubernetes Engine` on GCP\n",
    "1. Click Workloads.\n",
    "1. Click Deploy.\n",
    "1. In the Edit container section, select Existing container image.\n",
    "1. In the Image path field, click Select.\n",
    "1. In the Select container image pane, select the flask app image we created for Cloud Run.\n",
    "1. Click Select.\n",
    "1. Click Done.\n",
    "1. In the Environment variables click Add Environment Variable and enter the below values\n",
    "    - Key 1: PORT\n",
    "    - Value 1: 8080\n",
    "1. Click Continue.\n",
    "1. In the Configuration section, \n",
    "    - Update the Application name\n",
    "    - under Labels, enter app for Key and cats-v-dogs for Value.\n",
    "1. Under the Configuration section, click the View YAML button under Configuration YAML. This opens a YAML configuration file representing the two Kubernetes API resources about to be deployed into your cluster. Nothing to do here.\n",
    "1. Click Close.\n",
    "1. Click Deploy. When the Deployment Pods are ready, the Deployment details page opens.\n",
    "1. Under Managed pods, note the three running Pods for the cats-v-dogs Deployment.\n",
    "\n",
    "#### Expose a sample app to the internet\n",
    "1. Click Workloads.\n",
    "1. Click on cats-v-dogs in the Name column.\n",
    "1. From the Deployment details page, click the Actions > Expose button.\n",
    "1. In the Expose dialog, under the Port Mapping section, set\n",
    "    - Target port to 8080.\n",
    "    - Service type drop-down list to Load balancer.\n",
    "1. Click Expose to create a Kubernetes Service for cats-v-dogs. When the Load Balancer is ready, the Service details page opens.\n",
    "1. Copy the External endpoints address\n",
    "\n",
    "ðŸŽ‰ Success\n",
    "You have successfully deployed a containerized web application to a K8S cluster on GCP!\n",
    "\n",
    "#### Cleanup\n",
    "1. Delete the Service from Services & Ingress\n",
    "1. Delete the cluster from Clusters\n",
    "1. Delete your container image from Artifact Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1dcdec-2418-4774-bfe9-55bd7d2233e4",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- You now have packaged your model as a Docker container and deployed as a real time endpoint on your local machine, GCP Cloud Run and AWS Fargate!\n",
    "- Using Docker is one of THE BEST ways to \"deploy\" a model\n",
    "- Pros:\n",
    "    - Each model is self-contained with all its dependencies and no chance of conflicts\n",
    "    - Very robust cloud services like GCP Cloud Run and AWS Fargate that allow you to deploy the model in a \"serverless\" fashion. [Serverless](https://en.wikipedia.org/wiki/Serverless_computing) is all the rage these days as you only need to take care of the code and the cloud provider will handle all the hardware without any hassle for you!\n",
    "    - No more \"It works on my machine cliche\"! Docker ensures you build once and run anywhere!\n",
    "- Cons:\n",
    "    - Not much except you need to learn Docker and Linux commands\n",
    "    - And a bit difficult to debug when building more complex applications. Though ML model deployments in Docker is relatively straightforward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24de3ff-b7f8-4ccc-a909-d8695999fa21",
   "metadata": {},
   "source": [
    "# Test your knowledge\n",
    "1. Try to package the ham vs spam TFIDF + SklearnNLP classifier model from [5.06-lesson-nlp-ii](../../5.06-lesson-nlp-ii/solution-code/solution-code.ipynb) as a Flask API with Docker.\n",
    "1. Deploy the app on GCP Cloud Run\n",
    "1. Easily sell access to your API on [RapidAPI](https://rapidapi.com/)!!! Check out [Leo's Name-Gender prediction API](https://rapidapi.com/stephenleo87-DGFI1at-XQ/api/name-gender1/)\n",
    "\n",
    "# Easy Steps to become a Millionaire\n",
    "1. Invent a fancy API\n",
    "1. Wrap it into a Docker container\n",
    "1. Host it in GCP Cloud Run\n",
    "1. Publish it on Rapid API \n",
    "1. Become a Millionaire!\n",
    "\n",
    "![](../images/make-it-rain-meme.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86922900-d8f8-4ff6-ad18-21a83d6fd2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
