{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Modeling\n",
    "\n",
    "> Authors: Matt Brems, Joseph Nelson, Justin Pounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install scipy statsmodels --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# We are required to do this in order to avoid \"FutureWarning\" issues.\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/global_land_temps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Temperature Data\n",
    "> We have [average temperature data](https://data.world/data-society/global-climate-change-data) for the globe from 1750 to 2015.\n",
    "- `date`: the month the data was measured.\n",
    "- `avg_temp`: the average global temperature (in degreed Celsius)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avg_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1752-10-01</td>\n",
       "      <td>7.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1752-11-01</td>\n",
       "      <td>7.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1752-12-01</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1753-01-01</td>\n",
       "      <td>2.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1753-02-01</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  avg_temp\n",
       "0  1752-10-01     7.839\n",
       "1  1752-11-01     7.335\n",
       "2  1752-12-01     5.086\n",
       "3  1753-01-01     2.039\n",
       "4  1753-02-01     0.715"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "set_index() missing 1 required positional argument: 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fc6b3009e4d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Set index to be the date column as a DatetimeIndex.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Drop the date column from our data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: set_index() missing 1 required positional argument: 'keys'"
     ]
    }
   ],
   "source": [
    "# Set index to be the date column as a DatetimeIndex.\n",
    "df.set_index()\n",
    "\n",
    "# Drop the date column from our data.\n",
    "df.drop()\n",
    "\n",
    "# Confirm.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code modified from code written by Matthew Garton.\n",
    "\n",
    "def plot_series(df, cols=None, title='Title', xlab=None, ylab=None, steps=1):\n",
    "    \n",
    "    # Set figure size to be (18, 9).\n",
    "    plt.figure(figsize=(18,9))\n",
    "    \n",
    "    # Iterate through each column name.\n",
    "    for col in cols:\n",
    "            \n",
    "        # Generate a line plot of the column name.\n",
    "        # You only have to specify Y, since our\n",
    "        # index will be a datetime index.\n",
    "        plt.plot(df[col])\n",
    "        \n",
    "    # Generate title and labels.\n",
    "    plt.title(title, fontsize=26)\n",
    "    plt.xlabel(xlab, fontsize=20)\n",
    "    plt.ylabel(ylab, fontsize=20)\n",
    "    \n",
    "    # Enlarge tick marks.\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.xticks(df.index[0::steps], fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a time plot of our data.\n",
    "plot_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What Pandas function may be helpful here?</summary>\n",
    "\n",
    "- We'll use `.resample()`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a time plot of our data.\n",
    "plot_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite df.\n",
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Check: How would you describe this data?</summary>\n",
    "    \n",
    "- **Trend**: The mean is increasing over time and it looks like it speeds up toward the end of the 1960s.\n",
    "- **Seasonality**: There are fluctuations, but it's tough to see if there are fluctuations on a fixed and known frequency.\n",
    "- **Autocorrelation**: The data are correlated with one another.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA Model\n",
    "\n",
    "In order to fit an ARIMA model, we need to specify three parameters: $p$, $d$, and $q$.\n",
    "- We've already described how we'll find values of $p$ and $q$!\n",
    "\n",
    "### Parameter $d$: How much do we difference?\n",
    "\n",
    "$d$ is known as the **differencing parameter**. This controls how much we \"difference\" our time series by. _(We difference to meet an assumption - we'll talk about this in a minute!)_\n",
    "\n",
    "Differencing our time series means that instead of fitting a model that predicts our time series $Y_t$ directly, we'll fit a model to $Y'_t$ or $Y''_t$:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "Y'_t &=& Y_t - Y_{t-1} \\\\\n",
    "Y''_t &=& Y'_t - Y'_{t-1} = Y_t - 2Y_{t-1} + Y_{t-2}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "So if I wanted to fit a model, my \"new\" output variable I'm trying to predict would be $Y'_t$ or $Y''_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first 5 values of our series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first 5 values of our series, differenced once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first 5 values of our series, differenced twice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first_diff_temp and second_diff_temp\n",
    "# columns in df.\n",
    "df['first_diff_temp'] = \n",
    "df['second_diff_temp'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Why would we difference?](https://otexts.com/fpp2/stationarity.html) Well, there is one assumption that is **required** for nearly every time series model: **stationarity**.\n",
    "- If our time series is stationary, then we do not need to difference and let $d=0$.\n",
    "- If our time series is not stationary, then we difference either once ($d=1$) or twice ($d=2$). Differenced data often is stationary, so we difference our data, then model that!\n",
    "\n",
    "#### What is stationarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed.\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 200 steps in time from 0 to 15.\n",
    "t = np.linspace(0, 15, 200)\n",
    "\n",
    "# Generate a white noise process with Normally distributed noise.\n",
    "y = 5 * np.random.normal(0, 2, 200)\n",
    "\n",
    "# Generate plot.\n",
    "plt.title('A stationary time series!', fontsize=15)\n",
    "plt.plot(t, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informally, stationarity means that there **aren't systematic changes in our time series over time**.\n",
    "- Our mean stays the same. (There is no trend.)\n",
    "- The autocorrelation between $Y_t$ and $Y_{t-k}$ depends only on the size of our lag $k$. (There is no seasonality.)\n",
    "- A [white noise process](https://stats.stackexchange.com/questions/7070/what-is-a-white-noise-process) is a common example of a stationary time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Is our data stationary?</summary>\n",
    "    \n",
    "- No! The mean is not constant over time. It looks like the mean increases over time.\n",
    "- It looks like the fluctuations are more spread out in early years and get closer moving into later years.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature data.\n",
    "plot_series(df,\n",
    "            ['avg_temp'],\n",
    "            title = \"Average Temperature (in Celsius)\",\n",
    "            steps = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, why do we difference? \n",
    "- Differencing allows us to get a stationary time series out of a non-stationary time series.\n",
    "- This means that we'll be able to fit an ARIMA model to the **differenced** data!\n",
    "\n",
    "We'll start with a difference of $d = 1$ and iterate upward until we find a value of $d$ that makes our time series stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine temperature, differenced once.\n",
    "\n",
    "plot_series(df, ['first_diff_temp'], title = \"First-Order Differenced Data\", steps = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine temperature, differenced twice.\n",
    "\n",
    "plot_series(df, ['second_diff_temp'], title = \"Second-Order Differenced Data\", steps = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we know if we let $d=1$ or $d=2$?\n",
    "\n",
    "#### Checking for Stationarity: the Augmented Dickey-Fuller Test\n",
    "\n",
    "The [augmented Dickey-Fuller test](https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test) is a hypothesis test that tests for stationarity. We assume that our data are not stationary. With enough evidence, we may accept that our data are stationary.\n",
    "\n",
    "Specifically, the test is as follows:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "&H_0:& \\text{not stationary} \\\\\n",
    "&H_A:& \\text{stationary}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Would a small $p$-value or a large $p$-value give us evidence that our time series is stationary?</summary>\n",
    "\n",
    "- A small $p$-value would give us evidence to reject the null hypothesis, meaning we accept that our time series is stationary.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Augmented Dickey-Fuller test.\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Run ADF test on original (non-differenced!) data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code written by Joseph Nelson.\n",
    "\n",
    "def interpret_dftest(dftest):\n",
    "    dfoutput = pd.Series(dftest[0:2], index=['Test Statistic','p-value'])\n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run ADF test on original (non-differenced!) data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>At alpha of 0.01, how would we interpret this $p$-value? </summary>\n",
    "    \n",
    "- Remember that we compare our $p$-value to $\\alpha$, which is usually set at 0.10, 0.05, or 0.01. We'll use $\\alpha = 0.01$. Because $p = 0.0498$, it is larger than $\\alpha$. Thus, we cannot accept that our series `avg_temp` is stationary.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In order to achieve stationarity, we need to difference!\n",
    "\n",
    "We'll start with a difference of $d = 1$ to see if the time series `first_diff_temp` is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ADF test on our once-differenced data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Are our data, after a first-order difference, stationary?</summary>\n",
    "\n",
    "- Yes! This is stationary.\n",
    "- With a $p$-value of well below 0.05, we would reject $H_0$ and thus **accept that our first-order differenced data are stationary**.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rather than modeling $Y_t$ directly, we'll model $Y'_t = Y_t - Y_{t-1}$.\n",
    "- If we generate plots moving forward, then we should generate plots of the **differenced** time series, not the original time series!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit an ARIMA model.\n",
    "\n",
    "There are three hyperparameters we need to get values for when fitting an ARIMA model.\n",
    "1. Determine a value of $d$ using the Augmented Dickey-Fuller test.\n",
    "2. Then, determine values of $p$ and $q$ through GridSearching.\n",
    "\n",
    "An $ARIMA(p, d, q)$ model is specified by:\n",
    "- how many differences $d$ we need to calculate in order to achieve stationarity.\n",
    "- how many lags $p$ we regress $Y_t^{(d)}$ on.\n",
    "- how many errors $q$ we regress $Y_t^{(d)}$ on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Check: Recall that $AR$ incorporates information from long-term trends and $MA$ incorporates information from sudden shocks. What are some examples where we might see both long-term trends and sudden fluctuations in our time series data? </summary>\n",
    "\n",
    "- Stock price data. Stocks increase and decrease over time, but news or other stock changes may have sudden effects on prices. (Similar logic applies to gas or oil prices.)\n",
    "- Public transportation ridership. While public transportation may see slow changes over time, marketing campaigns, changes in price, or accidents may have a sudden, unforeseen shock on ridership.\n",
    "- Temperature data over time!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on our values of $p$, $d$, and $q$, we might refer to these models by slightly different names.\n",
    "\n",
    "- If $d=0$ and $q=0$, an AR(p) model is specified by how many lags $p$ we regress $Y_t$ on.\n",
    "- If $d=0$ and $p=0$, an MA(q) model is specified by how many errors $q$ we regress $Y_t$ on.\n",
    "- If $d=0$, an ARMA(p, q) model is specified by how many lags $p$ and how many errors $q$ we regress $Y_t$ on.\n",
    "\n",
    "| p | d | q |          Model         |\n",
    "|:-:|:-:|:-:|:----------------------:|\n",
    "| 1 | 0 | 0 |  ARIMA(1,0,0) = AR(1)  |\n",
    "| 0 | 0 | 1 |  ARIMA(0,0,1) = MA(1)  |\n",
    "| 1 | 0 | 1 | ARIMA(1,0,1) = ARMA(1,1) |\n",
    "| 1 | 1 | 1 |      ARIMA(1,1,1)      |\n",
    "| 1 | 1 | 0 |      ARIMA(1,1,0)      |\n",
    "| 0 | 1 | 1 |      ARIMA(0,1,1)      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train-test split.\n",
    "y_train, y_test = train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ARIMA model.\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual GridSearch\n",
    "\n",
    "Our strategy is this:\n",
    "- Let's start AIC at some really, really big number and call it `best_aic`.\n",
    "- Create variables `best_p` and `best_q` to store our best values of $p$ and $q$.\n",
    "- Create a nested `for` loop to iterate over our possible values of $p$ and $q$.\n",
    "    - At every combination of $p$ and $q$, fit an ARIMA model.\n",
    "    - If the ARIMA model has a better (lower) AIC than `best_aic`, then let's overwrite `best_aic`, `best_p`, and `best_q` with the values of AIC, $p$, and $q$ that our better model is using!\n",
    "    - If the ARIMA model has a worse (higher) AIC than `best_aic`, do nothing.\n",
    "- At the end of the `for` loop, tell us which values of $p$ and $q$ give us the best model (lowest AIC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What should our main concerns be about a manual GridSearch process?</summary>\n",
    "\n",
    "- The amount of time it takes to fit our models!\n",
    "- Cross-validation is also more complicated with time series data; you can check out more [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) and [here](https://machinelearningmastery.com/backtest-machine-learning-models-time-series-forecasting/).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is the purpose of try and except statements?</summary>\n",
    "\n",
    "- If our code encounters an error, then it will automatically stop. Sometimes this is good (so we can debug) but sometimes this isn't desirable!\n",
    "- `try` and `except` statements allow us to \"try\" to do something and, if there's an error, we can just `pass` it so that our code doesn't stop running.\n",
    "- This isn't always a good thing... errors are usually telling us that something is wrong. But we're going to hack our answer here so that we can check all values of $p$ and $q$ and just not run the model if some values of $p$ and $q$ are invalid.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting AIC, p, and q.\n",
    "best_aic = \n",
    "best_p = \n",
    "best_q = \n",
    "\n",
    "# Use nested for loop to iterate over values of p and q.\n",
    "\n",
    "        \n",
    "        # Insert try and except statements.\n",
    "        try:\n",
    "            \n",
    "            # Fitting an ARIMA(p, 1, q) model.\n",
    "            print(f'Attempting ARIMA({p}, 1, {q})')\n",
    "            \n",
    "            # Instantiate ARIMA model.\n",
    "            arima = \n",
    "            \n",
    "            \n",
    "            # Fit ARIMA model.\n",
    "            model = \n",
    "\n",
    "            # Print out AIC for ARIMA(p, 1, q) model.\n",
    "            print(f'The AIC for ARIMA({p},1,{q}) is: {model.aic}')\n",
    "\n",
    "            # Is my current model's AIC better than our best_aic?\n",
    "            if \n",
    "                \n",
    "                # If so, let's overwrite best_aic, best_p, and best_q.\n",
    "                best_aic = \n",
    "                best_p = \n",
    "                best_q = \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "print()\n",
    "print()\n",
    "print('MODEL FINISHED!')\n",
    "print(f'Our model that minimizes AIC on the training data is the ARIMA({best_p},1,{best_q}).')\n",
    "print(f'This model has an AIC of {best_aic}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finding coefficients for an MA model is difficult, because the model requires us to regress on errors, but we don't actually observe these errors. The algorithm for fitting this is complicated and is well beyond the scope of this lesson. [Check more out here](https://www.it.uu.se/research/publications/reports/2006-022/2006-022-nc.pdf). We're using `try` and `except` statements so Python errors don't cause us to stop our model-fitting process!\n",
    "\n",
    "The model we want to fit is an $ARIMA(3,1,3)$ model. That would look like this:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "Y^{(1)}_t &=& AR(3) + MA(3) \\\\\n",
    "(Y_t - Y_{t-1}) &=& \\beta_0 + \\beta_1(Y_{t-1} - Y_{t-2}) + \\beta_2(Y_{t-2} - Y_{t-3}) + \\beta_3(Y_{t-3} - Y_{t-4}) + w_1\\varepsilon_{t-1} + w_2\\varepsilon_{t-2} + w_3\\varepsilon_{t-3} + \\varepsilon_t \\\\\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate best model.\n",
    "arima = \n",
    "\n",
    "# Fit ARIMA model.\n",
    "model = \n",
    "\n",
    "# Generate predictions based on test set.\n",
    "preds = \n",
    "\n",
    "# Plot data.\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Plot training data.\n",
    "plt.plot(y_train.index, pd.DataFrame(y_train), color = 'blue')\n",
    "\n",
    "# Plot testing data.\n",
    "plt.plot(y_test.index, pd.DataFrame(y_test), color = 'orange')\n",
    "\n",
    "# Plot predicted test values.\n",
    "plt.plot(y_test.index, preds, color = 'green')\n",
    "\n",
    "plt.title(label = 'Once-Differenced Global Mean Temperature with ARIMA(3, 1, 3) Predictions', fontsize=16)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What do these predicted values represent?</summary>\n",
    "\n",
    "- These predicted values represent $Y'_t$, which is the once-differenced mean temperature data.\n",
    "- The first observation represents the \"change in average temperature\" in 1752.\n",
    "- The second observation represents the \"change in average temperature\" in 1753.\n",
    "- And so on.\n",
    "- If you want to \"undo\" the predicted values to forecast forward, you can take the original $Y$ value at time $t-1$ and add that to $Y'_t$.\n",
    "\n",
    "$$Y'_t = Y_t - Y_{t-1} \\Rightarrow Y_t = Y'_t + Y_{t-1}$$\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "- ARIMA models are among the most common approaches to time series modeling.\n",
    "- Highly flexible; it can model time series with varying characteristics.\n",
    "    - It takes information from both long-term trends and sudden shocks!\n",
    "- Can easily be extended into more advanced models.\n",
    "    - Seasonal ARIMA.\n",
    "    - ARIMA with eXogenous Predictors. (Independent X variables.)\n",
    "    - Vector ARIMA models. (Multiple Y variables simultaneously.)\n",
    "- Tends to perform well with moderate amounts of data, but may be outperformed by deep learning methods (RNN) with lots of data. (Side note: It can be hard to get lots of time series data!)\n",
    "- ARIMA models are best suited for short-term forecasts, but very quickly will start predicting the mean. Some of the extensions to ARIMA models can handle this better.\n",
    "\n",
    "**Forecasting time series is exceptionally difficult to do well!** We're using the past to predict the future, and there aren't guarantees that the future is necessarily going to be reflective of the past. There's more uncertainty in time series than we'd see in \"traditional\" model-building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interview Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What are examples of time series data?</summary>\n",
    "\n",
    "_(Answers will vary.)_\n",
    "- Any data that is gathered over time is considered time series data.\n",
    "- Examples include an individual's maximum heart rate per minute, average temperature per hour, number of units sold per day, amount of rainfall per month, and GDP per quarter.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What are some disadvantages to time series analysis methods?</summary>\n",
    "\n",
    "_(Answers will vary.)_\n",
    "- Forecasting into the future is difficult! There are more sources of uncertainty than in traditional, non-temporal machine learning.\n",
    "- The amount of data gathered over time is often smaller than the amount of data in non-temporal machine learning.\n",
    "- Forecasts may only be meaningful/informative for a few time periods.\n",
    "- [Significant changes](gov/pmc/articles/PMC5464762/) may cause certain periods of data to be irrelevant/less relevant to solving problem. (e.g. data prior to Great Recession may not be impactful when forecasting economic data after 2009, data prior to COVID may not be meaningful when predicting consumer behavior after May 2020.)\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
