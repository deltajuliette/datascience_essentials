{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Introduction to Web Scraping and Spiders With Scrapy\n",
    "\n",
    "_Authors: Dave Yerrington (SF), Sam Stack(DC)_\n",
    "\n",
    "_Modified for DSI-EAST-2 by Justin Pounders_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Decipher the structure and content of HTML\n",
    "- Use Beautiful Soup to parse HTML\n",
    "- Use XPath to select HTML elements\n",
    "- Practice using Scrapy to get data from Craigslist\n",
    "- Walk through the construction of a spider built using Scrapy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "\n",
    "**What is HTML?**\n",
    "\n",
    "One of the largest sources of data in the world is all around us — the web. Most people consume the web in some form every day. One of the most powerful Python tool sets we'll learn allows us to **extract and normalize data from unstructured sources such as _web pages_**.  \n",
    "\n",
    "**If you can see it, it can be scraped, mined, and put into a DataFrame.**\n",
    "\n",
    "Before we begin the actual process of web scraping with Python, it's important to cover the basic constructs that describe HTML as unstructured data. \n",
    "\n",
    "We'll then cover a powerful selection technique called **XPath** and look at a basic workflow using a framework called [Scrapy](http://www.scrapy.org) _(which is officially described as an open source and collaborative framework for extracting the data from websites)_ However, many websites have implemented limitations on scrapping so Scrapy may not work on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='html'></a>\n",
    "\n",
    "## Hypertext Markup Language (HTML)\n",
    "\n",
    "---\n",
    "\n",
    "In the HTML document object model (DOM) we introduced in previous lesson, **everything is a node**:\n",
    " * The document itself is a _document node_.\n",
    " * All HTML elements are _element nodes_.\n",
    " * All HTML attributes are _attribute nodes_.\n",
    " * Text inside HTML elements are _text nodes_.\n",
    " * Comments are _comment nodes_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='elements'></a>\n",
    "### Elements\n",
    "Elements begin and end with **opening and closing \"tags\",** which are defined by namespaced, encapsulated strings. These namespaces, which ***begin and end the elements, must be the same***. \n",
    "\n",
    "```html\n",
    "<title>I am a title.</title>\n",
    "<p>I am a paragraph.</p>\n",
    "<strong>I am bold.</strong>\n",
    "```\n",
    "\n",
    "When you have several different titles or paragraphs on a single page, you can assign **ID values to namespaces to make more unique reference points**. IDs are also useful for ***labelling nested elements*** as we will see next below.\n",
    "```html\n",
    "<title id ='title_1'>I am the first title.</title>\n",
    "<p id ='para_1'>I am the first paragraph.</p>\n",
    "<title id ='title_2'>I am the second title.</title>\n",
    "<p id ='para_2'>I am the second paragraph.</p>\n",
    "```\n",
    "\n",
    "\n",
    "**Elements can have parents and children.**\n",
    "It's important to remember that an element can be **both a parent and a child** — whether an element is referred to as a parent or child depends on the specific element you're referencing.\n",
    "\n",
    "\n",
    "```html\n",
    "<body id = 'parent'>\n",
    "    <div id = 'child_1'>I am the child of 'parent.'\n",
    "        <div id = 'child_2'>I am the child of 'child_1.'\n",
    "            <div id = 'child_3'>I am the child of 'child_2.'\n",
    "                <div id = 'child_4'>I am the child of 'child_3.'</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "```\n",
    "**or**\n",
    "```html\n",
    "<body id = 'parent'>\n",
    "    <div id = 'child_1'>I am the parent of 'child_2.'\n",
    "        <div id = 'child_2'>I am the parent of 'child_3.'\n",
    "            <div id = 'child_3'> I am the parent of 'child_4.'\n",
    "                <div id = 'child_4'>I am not a parent. </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='attributes'></a>\n",
    "### Attributes\n",
    "\n",
    "HTML elements can also have attributes. They describe the **properties and characteristics of elements**. Some affect how the element behaves or looks in terms of the output rendered by the browser.\n",
    "\n",
    "The most common element is an anchor element `<a>` with its most important attribute being an `href` attribute, which tells the browser where to go after it's clicked _(the link's destination)_. An anchor element is typically formatted in bold type and is sometimes underlined as a visual cue to differentiate it.\n",
    "\n",
    "**The markup that describes an `anchor element <a>` with `href` attribute looks like this:**\n",
    "\n",
    "```html\n",
    "<a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">An Awesome Website</a>\n",
    "```\n",
    "\n",
    "**However, this element, once rendered, looks like this:**\n",
    "\n",
    "[An Awesome Website](https://www.youtube.com/watch?v=dQw4w9WgXcQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='element-hierarchy'></a>\n",
    "### Element Hierarchy \n",
    "_(DOM)_\n",
    "\n",
    "![Nodes](http://www.computerhope.com/jargon/d/dom1.jpg)\n",
    "\n",
    "**Literally represented as:**\n",
    "\n",
    "```html\n",
    "<html>\n",
    "    \n",
    "    <head>\n",
    "        <title>Example</title>\n",
    "    </head>\n",
    "    \n",
    "    <body>\n",
    "        <h1>Example Page</h1>\n",
    "        <p>This is an example page.</p>\n",
    "    </body>\n",
    "    \n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='html-resources'></a>\n",
    "### Additional HTML Resources\n",
    "\n",
    "Read all about the different elements supported by modern browsers:\n",
    " * [HTML5 cheat sheet](http://websitesetup.org/html5-cheat-sheet/).\n",
    " * [Mozilla HTML element reference](https://developer.mozilla.org/en-US/docs/Web/HTML/Element).\n",
    " * [HTML5 visual cheat sheet](http://www.unitedleather.biz/PDF/HTML5-Visual-Cheat-Sheet1.pdf).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practical'></a>\n",
    "\n",
    "## Using Requests and Beautiful Soup to Extract Information From a Web Page\n",
    "\n",
    "---\n",
    "\n",
    "**Beautiful Soup is a Python library that's useful for pulling data out of HTML and XML files**. It works with many parsers, such as XPath, and can be executed in an IDE, meaning it can be easier to work with when first extracting information from HTML.\n",
    "\n",
    "First, make sure that the required packages are installed: \n",
    "\n",
    "```bash\n",
    "# Beautiful Soup (in command prompt):\n",
    "> conda install beautifulsoup4\n",
    "> conda install lxml\n",
    "\n",
    "# Or if conda doesn't work (in jupyter):\n",
    "> pip install beautifulsoup4\n",
    "> pip install lxml # lxml provides simple, powerful API for parsing XML and HTML in Python. Parsing - simply means converting a program into an internal format. Like, pandas read_csv converts a csv file into a pandas dataframe\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkout sample.html from directory, '../' goes back one directory from solution code-->skip to run on starter_code,\n",
    "# since sample.html file is on the same directory level as starter_code\n",
    "soup = BeautifulSoup(open(\"../sample.html\"), \"lxml\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title>Hello, World!</title>\n",
       "</head>\n",
       "<body>\n",
       "<h1>Header 1</h1>\n",
       "<h2>Header 2</h2>\n",
       "<p>This is a paragraph</p>\n",
       "<a href=\"https://www.google.com/\">Google it!</a>\n",
       "<h3>What's in a div?</h3>\n",
       "<div class=\"divvy-it-up\" id=\"foobar\">\n",
       "<p id=\"layer1\">I'm in a div.  Yeah!</p>\n",
       "<div>\n",
       "<p id=\"layer2\">I'm in a div, too!</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"todo\">\n",
       "<ul>\n",
       "<li> Take out trash</li>\n",
       "<li> Walk dog</li>\n",
       "</ul>\n",
       "</div>\n",
       "<div class=\"something\">\n",
       "<ol>\n",
       "<li>One</li>\n",
       "<li>Two</li>\n",
       "</ol>\n",
       "</div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.extract()# extract html document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Hello, World!</title>\n",
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "# more self-explanatory methods to print specific html elements\n",
    "print(soup.title)\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Two\n"
     ]
    }
   ],
   "source": [
    "olist = soup.find('ol') # find ordered list from html doc\n",
    "# find_all() method looks through a tag’s descendants and retrieves all descendants that match your filters\n",
    "for list_item in olist.find_all('li'): # finding + extracting elements within 'ol' \n",
    "    print(list_item.text) # .text finds the text from the given tag, 'li'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Additional reference](https://stackoverflow.com/questions/59780916/what-is-the-difference-between-find-and-find-all-in-beautiful-soup-python) on `find()` vs `find_all()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.google.com/\">Google it!</a>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's use find_all to get the url link within, 1st we can specify the anchor element 'a'\n",
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.google.com/\">Google it!</a>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unpack the output from within list\n",
    "soup.find_all('a')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.google.com/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally, pass additional filter\n",
    "soup.find_all('a')[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"divvy-it-up\" id=\"foobar\">\n",
       " <p id=\"layer1\">I'm in a div.  Yeah!</p>\n",
       " <div>\n",
       " <p id=\"layer2\">I'm in a div, too!</p>\n",
       " </div>\n",
       " </div>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another example to extract what's within the paragraph id=\"layer2\", within body-->div class=\"divvy-it-up\"\n",
    "div_results = soup.body.find_all('div', {'class':'divvy-it-up'})\n",
    "div_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"layer2\">I'm in a div, too!</p>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_results[0].find_all('p', {'id':'layer2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I like to think of this HTML parsing as starting at the top and peeling off the layers of the HTML file layer by layer until we get what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's buy a car!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/craigslist.jpg)\n",
    "\n",
    "Suppose we want to buy this one: https://atlanta.craigslist.org/atl/ctd/d/miami-2016-toyota-tacoma-double-cab/7408971613.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "### 1) Fetch the content by URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code:  200\n",
      "\n",
      "First part of HTML document fetched as string:\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "    \n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\">\n",
      "\t<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\">\n",
      "\t<meta property=\"og:site_name\" content=\"craigslist\">\n",
      "\t<meta name=\"twitter:card\" content=\"preview\">\n",
      "\t<meta property=\"og:title\" content=\"2016 Toyota Tacoma Double Cab - Call Now! - cars &amp; trucks - by...\">\n",
      "\t<meta name=\"description\" content=\"2016 Toyota Tacoma Double Cab TRD Sport Pickup 4D 6 ft - $15,950.00 Call us today! 2016 Toyota Tacoma Double Cab For Sale by Elite Motor Cars of Miami LLC Vehicle Description for this Toyota Tacoma...\">\n",
      "\t<meta property=\"og:description\" content=\"2016 Toyota Tacoma Double Cab \n"
     ]
    }
   ],
   "source": [
    "import requests # http library for python\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Target web page with 1 car listing:\n",
    "url = \"https://atlanta.craigslist.org/atl/ctd/d/miami-2016-toyota-tacoma-double-cab/7408971613.html\"\n",
    "\n",
    "# Establishing the connection to the web page using the .get() method:\n",
    "response = requests.get(url)\n",
    "\n",
    "# You can use status codes to understand how the target server responds to your request.\n",
    "# Ex., 200 = OK, 400 = Bad Request, 403 = Forbidden, 404 = Not Found.\n",
    "print('Status Code: ',response.status_code)\n",
    "\n",
    "# Pull the HTML string out of requests and convert it to a Python string.\n",
    "html = response.text\n",
    "\n",
    "# The first 700 characters of the content.\n",
    "print(\"\\nFirst part of HTML document fetched as string:\\n\")\n",
    "print(html[:700])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information on [request status codes](http://www.restapitutorial.com/httpstatuscodes.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "### 2) Parse the HTML document with Beautiful Soup.\n",
    "\n",
    "This step allows us to access specific elements of the document by XPath expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'lxml') # parsing the html document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n",
       "<meta content=\"width=device-width,initial-scale=1\" name=\"viewport\"/>\n",
       "<meta content=\"craigslist\" property=\"og:site_name\"/>\n",
       "<meta content=\"preview\" name=\"twitter:card\"/>\n",
       "<meta content=\"2016 Toyota Tacoma Double Cab - Call Now! - cars &amp; trucks - by...\" property=\"og:title\"/>\n",
       "<meta content=\"2016 Toyota Tacoma Double Cab TRD Sport Pickup 4D 6 ft - $15,950.00 Call us today! 2016 Toyota Tacoma Double Cab For Sale by Elite Motor Cars of Miami LLC Vehicle Description for this Toyota Tacoma...\" name=\"description\"/>\n",
       "<meta content=\"2016 Toyota Tacoma Double Cab TRD Sport Pickup 4D 6 ft - $15,950.00 Call us today! 2016 Toyota Tacoma Double Cab For Sale by Elite Motor Cars of Miami LLC Vehicle Description for this Toyota Tacoma...\" property=\"og:description\"/>\n",
       "<meta content=\"https://images.craigslist.org/00g0g_88Ey8KXYStuz_0ak06T_600x450.jpg\" property=\"og:image\"/>\n",
       "<meta content=\"https://atlanta.craigslist.org/atl/ctd/d/miami-2016-toyota-tacoma-double-cab/7408971613.html\" property=\"og:url\"/>\n",
       "<meta content=\"article\" property=\"og:type\"/>\n",
       "<meta content=\"noarchive,nofollow,unavailable_after: 16-Dec-21 20:07:43 EST\" name=\"robots\"/>\n",
       "<meta content=\"25.813000;-80.232000\" name=\"geo.position\"/>\n",
       "<meta content=\"25.813000, -80.232000\" name=\"ICBM\"/>\n",
       "<meta content=\"Miami\" name=\"geo.placename\"/>\n",
       "<meta content=\"US-GA\" name=\"geo.region\"/>\n",
       "<title>2016 Toyota Tacoma Double Cab - Call Now! - cars &amp; trucks - by...</title>\n",
       "<link href=\"https://atlanta.craigslist.org/atl/ctd/d/miami-2016-toyota-tacoma-double-cab/7408971613.html\" rel=\"canonical\"/>\n",
       "<script id=\"ld_breadcrumb_data\" type=\"application/ld+json\">\n",
       "    {\"@context\":\"https://schema.org\",\"itemListElement\":[{\"item\":{\"name\":\"atlanta.craigslist.org\",\"@id\":\"https://atlanta.craigslist.org\"},\"position\":1,\"@type\":\"ListItem\"},{\"item\":{\"name\":\"atlanta\",\"@id\":\"https://atlanta.craigslist.org/atl/\"},\"position\":2,\"@type\":\"ListItem\"},{\"item\":{\"name\":\"for sale\",\"@id\":\"https://atlanta.craigslist.org/d/for-sale/search/atl/sss\"},\"position\":3,\"@type\":\"ListItem\"},{\"item\":{\"name\":\"cars & trucks - by dealer\",\"@id\":\"https://atlanta.craigslist.org/d/cars-trucks-by-dealer/search/atl/ctd\"},\"position\":4,\"@type\":\"ListItem\"},{\"item\":{\"name\":\"2016 Toyota Tacoma Double Cab - Call Now!\",\"@id\":\"https://atlanta.craigslist.org/atl/ctd/d/miami-2016-toyota-tacoma-double-cab/7408971613.html\"},\"position\":5,\"@type\":\"ListItem\"}],\"@type\":\"BreadcrumbList\"}\n",
       "</script>\n",
       "<style type=\"text/css\">\n",
       "        body {\n",
       "            font-family: sans-serif;\n",
       "        }\n",
       "\n",
       "        #no-js,\n",
       "        #unsupported-browser {\n",
       "            position: fixed;\n",
       "            z-index: 10000;\n",
       "\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            right: 0;\n",
       "            margin: 0;\n",
       "            padding: 0;\n",
       "            border: 0;\n",
       "            background: transparent;\n",
       "        }\n",
       "\n",
       "        #no-js p,\n",
       "        #unsupported-browser p {\n",
       "            color: black;\n",
       "            background-color: #FA8787;\n",
       "            opacity: 0.8;\n",
       "            text-align: center;\n",
       "            margin: 0;\n",
       "            border: 0;\n",
       "            padding: 1em;\n",
       "        }\n",
       "\n",
       "        #unsupported-browser {\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        .unsupported-browser #unsupported-browser {\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        .no-js header,\n",
       "        .no-js form,\n",
       "        .no-js .tryapp,\n",
       "        .no-js .tsb,\n",
       "        .unsupported-browser header,\n",
       "        .unsupported-browser form,\n",
       "        .unsupported-browser .tryapp,\n",
       "        .unsupported-browser .tsb {\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        #curtain {\n",
       "            display: none;\n",
       "            position: fixed;\n",
       "            z-index: 9000;\n",
       "            top: 0;\n",
       "            bottom: 0;\n",
       "            left: 0;\n",
       "            right: 0;\n",
       "            margin: 0;\n",
       "            padding: 0;\n",
       "            border: 0;\n",
       "            background: transparent;\n",
       "        }\n",
       "\n",
       "        .show-curtain #curtain {\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        #curtain .cover,\n",
       "        #curtain .content {\n",
       "            position: absolute;\n",
       "            display: block;\n",
       "            top: 0;\n",
       "            bottom: 0;\n",
       "            left: 0;\n",
       "            right: 0;\n",
       "            margin: 0;\n",
       "            padding: 0;\n",
       "            border: 0;\n",
       "        }\n",
       "\n",
       "        #curtain .cover {\n",
       "            z-index: 1;\n",
       "            background-color: white;\n",
       "        }\n",
       "\n",
       "        .show-curtain #curtain .cover {\n",
       "            opacity: 0.5;\n",
       "        }\n",
       "\n",
       "        .show-curtain.clear #curtain .cover {\n",
       "            opacity: 0;\n",
       "        }\n",
       "\n",
       "        .show-curtain.opaque #curtain .cover {\n",
       "            opacity: 1;\n",
       "        }\n",
       "\n",
       "        #curtain .content {\n",
       "            z-index: 2;\n",
       "            background: transparent;\n",
       "            color: #00E;\n",
       "\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            justify-content: center;\n",
       "            align-items: center;\n",
       "        }\n",
       "\n",
       "        @keyframes rotate {\n",
       "            from {\n",
       "                transform: rotate(0deg);\n",
       "            }\n",
       "            to {\n",
       "                transform: rotate(359deg);\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .pacify #curtain .icom- {\n",
       "            font-size: 3em;\n",
       "            animation: rotate 2s infinite linear;\n",
       "        }\n",
       "\n",
       "        .pacify #curtain .icom-:after {\n",
       "            content: \"\\eb23\";\n",
       "        }\n",
       "\n",
       "        #curtain .text {\n",
       "            display: none;\n",
       "            font-size: 2em;\n",
       "        }\n",
       "\n",
       "        .loading #curtain .text.loading,\n",
       "        .reading #curtain .text.reading,\n",
       "        .writing #curtain .text.writing,\n",
       "        .saving #curtain .text.saving,\n",
       "        .searching #curtain .text.searching,\n",
       "        .unrecoverable #curtain .text.unrecoverable,\n",
       "        .message #curtain .text.message {\n",
       "            display: block;\n",
       "        }\n",
       "    </style>\n",
       "<script src=\"https://www.craigslist.org/static/www/030feed3cf43bf94976c889a1a0ceb5cdd7ebafa.js\"></script>\n",
       "<script>\n",
       "         window.cl.init(\n",
       "             'https://www.craigslist.org/static/www/',\n",
       "             '',\n",
       "             'www',\n",
       "             'posting',\n",
       "             {\n",
       "countOfTotalText: \"image {count} of {total}\",\n",
       "defaultLocale: \"en_US\",\n",
       "imageConfig: {\"1\":{\"hostname\":\"https://images.craigslist.org\",\"sizes\":[\"50x50c\",\"300x300\",\"600x450\",\"1200x900\"]},\"4\":{\"hostname\":\"https://images.craigslist.org\",\"sizes\":[\"50x50c\",\"300x300\",\"600x450\",\"1200x900\"]},\"0\":{\"hostname\":\"https://images.craigslist.org\",\"sizes\":[\"50x50c\",\"300x300\",\"600x450\"]},\"3\":{\"hostname\":\"https://images.craigslist.org\",\"sizes\":[\"50x50c\",\"300x300\",\"600x450\",\"1200x900\"]},\"2\":{\"hostname\":\"https://images.craigslist.org\",\"sizes\":[\"50x50c\",\"300x300\",\"600x450\",\"1200x900\"]}},\n",
       "maptileBaseUrl: \"//map{s}.craigslist.org/t09/{z}/{x}/{y}.png\",\n",
       "pID: 7408971613\n",
       "},\n",
       "             0\n",
       "         );\n",
       "     </script>\n",
       "</head>\n",
       "<body class=\"no-js show-curtain opaque posting\">\n",
       "<iframe id=\"cl-local-storage\" src=\"https://www.craigslist.org/static/www/localStorage-092e9f9e2f09450529e744902aa7cdb3a5cc868d.html\" style=\"display:none;\"></iframe>\n",
       "<div id=\"curtain\">\n",
       "<div class=\"cover\"></div>\n",
       "<div class=\"content\">\n",
       "<div class=\"icom-\"></div>\n",
       "<div class=\"text loading\">loading</div>\n",
       "<div class=\"text reading\">reading</div>\n",
       "<div class=\"text writing\">writing</div>\n",
       "<div class=\"text saving\">saving</div>\n",
       "<div class=\"text searching\">searching</div>\n",
       "<div class=\"text unrecoverable\">\n",
       "                There was an error loading the page; please try to\n",
       "                <a href=\"#\" id=\"cl-unrecoverable-hard-refresh\" onclick=\"location.reload(true);\">refresh the page.</a>\n",
       "</div>\n",
       "<div class=\"text message\"></div>\n",
       "</div>\n",
       "</div>\n",
       "<noscript id=\"no-js\"><div>\n",
       "<p>We've detected that JavaScript is not enabled in your browser.</p>\n",
       "<p>You must enable JavaScript to use craigslist.</p>\n",
       "</div></noscript>\n",
       "<div id=\"unsupported-browser\">\n",
       "<p>We've detected you are using a browser that is missing critical features.</p>\n",
       "<p>Please visit craigslist from a modern browser.</p>\n",
       "</div>\n",
       "<section class=\"page-container\">\n",
       "<div class=\"bglogo\"></div>\n",
       "<div class=\"tryapp\">\n",
       "    try the craigslist app »\n",
       "    <a class=\"appstorebtn\" href=\"https://play.google.com/store/apps/details?id=org.craigslist.CraigslistMobile\">\n",
       "        Android\n",
       "    </a>\n",
       "<a class=\"appstorebtn\" href=\"https://apps.apple.com/us/app/craigslist/id1336642410\">\n",
       "        iOS\n",
       "    </a>\n",
       "</div>\n",
       "<header class=\"global-header wide\">\n",
       "<a class=\"header-logo\" href=\"/\" name=\"logoLink\">CL</a>\n",
       "<nav class=\"breadcrumbs-container\">\n",
       "<ul class=\"breadcrumbs\">\n",
       "<li class=\"crumb area\">\n",
       "<p>\n",
       "<a href=\"/\">atlanta</a>\n",
       "<span class=\"breadcrumb-arrow\">&gt;</span>\n",
       "</p>\n",
       "</li>\n",
       "<li class=\"crumb subarea\">\n",
       "<p>\n",
       "<a href=\"/atl/\">atlanta</a>\n",
       "<span class=\"breadcrumb-arrow\">&gt;</span>\n",
       "</p>\n",
       "</li>\n",
       "<li class=\"crumb section\">\n",
       "<p>\n",
       "<a href=\"/search/atl/sss\">for sale</a>\n",
       "<span class=\"breadcrumb-arrow\">&gt;</span>\n",
       "</p>\n",
       "</li>\n",
       "<li class=\"crumb category\">\n",
       "<p>\n",
       "<a href=\"/search/atl/ctd\">cars &amp; trucks - by dealer</a>\n",
       "</p>\n",
       "</li>\n",
       "</ul>\n",
       "</nav>\n",
       "<div class=\"userlinks\">\n",
       "<ul class=\"user-actions\">\n",
       "<li class=\"user post\">\n",
       "<a href=\"https://post.craigslist.org/c/atl\">post</a>\n",
       "</li>\n",
       "<li class=\"user account\">\n",
       "<a href=\"https://accounts.craigslist.org/login/home\">account</a>\n",
       "</li>\n",
       "</ul>\n",
       "<ul class=\"user-favs-discards\">\n",
       "<li class=\"user\">\n",
       "<div class=\"favorites\">\n",
       "<a class=\"favlink\" href=\"#\"><span aria-hidden=\"true\" class=\"icon icon-star fav\"></span><span class=\"fav-number\"></span><span class=\"fav-label\"> favorites</span></a>\n",
       "</div>\n",
       "</li>\n",
       "<li class=\"user discards\">\n",
       "<div class=\"to-banish-page\">\n",
       "<a class=\"to-banish-page-link\" href=\"#\">\n",
       "<span aria-hidden=\"true\" class=\"icon icon-trash red\"></span>\n",
       "<span class=\"banished_count\"></span>\n",
       "<span class=\"discards-label\"> hidden</span>\n",
       "</a>\n",
       "</div>\n",
       "</li>\n",
       "</ul>\n",
       "</div>\n",
       "</header>\n",
       "<header class=\"global-header narrow\">\n",
       "<a class=\"header-logo\" href=\"/\">CL</a>\n",
       "<nav class=\"breadcrumbs-container\">\n",
       "<div class=\"breadcrumbs\">\n",
       "\n",
       "atlanta            &gt;\n",
       "\n",
       "cars &amp; trucks - by dealer    </div>\n",
       "</nav>\n",
       "<span class=\"linklike show-wide-header\">...</span>\n",
       "</header>\n",
       "<section class=\"body\">\n",
       "<header class=\"dateReplyBar\">\n",
       "<div class=\"prevnext-sec\">\n",
       "<div class=\"prevnext js-only\">\n",
       "<a class=\"prev\">◀  prev </a>\n",
       "<a class=\"backup\" title=\"back to search\">▲</a>\n",
       "<a class=\"next\"> next ▶ </a>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"reply-button-row\">\n",
       "<div class=\"actions-combo\">\n",
       "<button class=\"reply-button js-only\" data-href=\"/reply/atl/ctd/7408971613/__SERVICE_ID__\" role=\"button\">\n",
       "      reply\n",
       "    </button>\n",
       "<div class=\"reply-info js-only\"></div>\n",
       "<div class=\"fave-unfave action\">\n",
       "<div class=\"fave\" role=\"button\" title=\"add to favorites\">\n",
       "<div aria-hidden=\"true\" class=\"icon icon-star\"></div>\n",
       "<div class=\"action-label\">favorite</div>\n",
       "</div>\n",
       "<div class=\"unfave\" role=\"button\" title=\"remove from favorites\">\n",
       "<div aria-hidden=\"true\" class=\"icon icon-star fav\"></div>\n",
       "<div class=\"action-label\">favorite</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"banish-unbanish action\">\n",
       "<div class=\"banish\" data-url=\"https://post.craigslist.org/flag\" role=\"button\" title=\"hide this posting\">\n",
       "<div aria-hidden=\"true\" class=\"icon icon-trash\"></div>\n",
       "<div class=\"action-label\">hide</div>\n",
       "</div>\n",
       "<div class=\"unbanish\" data-url=\"https://post.craigslist.org/flag\" role=\"button\" title=\"restore this posting\">\n",
       "<div aria-hidden=\"true\" class=\"icon icon-trash red\"></div>\n",
       "<div class=\"action-label\">unhide</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"flag-action action\">\n",
       "<div class=\"flag\" data-url=\"https://post.craigslist.org/flag\" role=\"button\" title=\"flag as prohibited / spam / miscategorized\">\n",
       "<div aria-hidden=\"true\" class=\"flagIcon\">\n",
       "<span class=\"white-flag\">⚐</span>\n",
       "<span class=\"black-flag\">⚑</span>\n",
       "</div>\n",
       "<div class=\"action-label\">\n",
       "                flag\n",
       "            </div>\n",
       "</div>\n",
       "<div class=\"unflag\">\n",
       "<div aria-hidden=\"true\" class=\"flagIcon\">⚑</div>\n",
       "<a class=\"action-label\" href=\"https://www.craigslist.org/about/help/flags_and_community_moderation\" title=\"thanks for flagging!\">\n",
       "                flagged\n",
       "            </a>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"action share-action\">\n",
       "<div class=\"share\" id=\"sharebutton-container\"></div>\n",
       "</div>\n",
       "</div>\n",
       "<p class=\"postinginfo reveal\" id=\"display-date\">\n",
       "                    Posted\n",
       "                    <time class=\"date timeago\" datetime=\"2021-11-16T20:07:46-0500\">\n",
       "                        2021-11-16 20:07\n",
       "                    </time>\n",
       "</p>\n",
       "<p class=\"print-information print-contact\">\n",
       "                Contact Information: <span class=\"print-email\"></span> <span class=\"print-phone\"></span>\n",
       "</p>\n",
       "<a href=\"#\" id=\"printme\">print</a>\n",
       "</div>\n",
       "</header>\n",
       "<h1 class=\"postingtitle\">\n",
       "<span class=\"postingtitletext\">\n",
       "<span id=\"titletextonly\">2016 Toyota Tacoma Double Cab - Call Now!</span> - <span class=\"price\">$15950.00</span><small> (Miami, FL)</small> </span>\n",
       "</h1>\n",
       "<section class=\"userbody\">\n",
       "<figure class=\"iw multiimage\">\n",
       "<div class=\"gallery\">\n",
       "<span class=\"slider-back arrow\">&lt;</span>\n",
       "<span class=\"slider-info\">image 1 of 22</span>\n",
       "<span class=\"slider-forward arrow\">&gt;</span>\n",
       "<div class=\"swipe\">\n",
       "<div class=\"swipe-wrap\">\n",
       "<div class=\"slide first visible\" data-imgid=\"88Ey8KXYStuz_0ak06T\" id=\"1_image_88Ey8KXYStuz_0ak06T\">\n",
       "<img alt=\"1\" src=\"https://images.craigslist.org/00g0g_88Ey8KXYStuz_0ak06T_600x450.jpg\" title=\"1\"/>\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"aaPbMGLaETwz_0ak06T\" id=\"2_image_aaPbMGLaETwz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"6WurMx74uWVz_0ak06T\" id=\"3_image_6WurMx74uWVz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"KtzAJFY3wbz_0ak06T\" id=\"4_image_KtzAJFY3wbz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"1RfdclU1k57z_0ak06T\" id=\"5_image_1RfdclU1k57z_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"7XuJIT7kuYrz_0ak06T\" id=\"6_image_7XuJIT7kuYrz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"b45TWGHAAoLz_0ak06T\" id=\"7_image_b45TWGHAAoLz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"5FQEWfnqjBoz_0ak06T\" id=\"8_image_5FQEWfnqjBoz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"7pZPVPpYuxgz_0ak06T\" id=\"9_image_7pZPVPpYuxgz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"7kAwB6GGescz_0ak06T\" id=\"10_image_7kAwB6GGescz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"jcSy1zSJNS9z_0ak06T\" id=\"11_image_jcSy1zSJNS9z_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"ht0ctW0GRT4z_0ak06T\" id=\"12_image_ht0ctW0GRT4z_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"8ufBY6UwX2Sz_0ak06T\" id=\"13_image_8ufBY6UwX2Sz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"etQCjQYVbDcz_0ak06T\" id=\"14_image_etQCjQYVbDcz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"c6Ktx2KictGz_0ak06T\" id=\"15_image_c6Ktx2KictGz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"jN2N1A4rFzez_0ak06T\" id=\"16_image_jN2N1A4rFzez_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"dOEODSR3bawz_0ak06T\" id=\"17_image_dOEODSR3bawz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"6dEa4giiQiHz_0ak06T\" id=\"18_image_6dEa4giiQiHz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"93hDlMc3PEVz_0ak06T\" id=\"19_image_93hDlMc3PEVz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"diR3OWIsuVz_0ak06T\" id=\"20_image_diR3OWIsuVz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"iZLdXYnmhXFz_0ak06T\" id=\"21_image_iZLdXYnmhXFz_0ak06T\">\n",
       "</div>\n",
       "<div class=\"slide\" data-imgid=\"ilNeEaQThzIz_0ak06T\" id=\"22_image_ilNeEaQThzIz_0ak06T\">\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div id=\"thumbs\"><a class=\"thumb\" data-imgid=\"88Ey8KXYStuz_0ak06T\" href=\"https://images.craigslist.org/00g0g_88Ey8KXYStuz_0ak06T_600x450.jpg\" id=\"1_thumb_88Ey8KXYStuz_0ak06T\" title=\"1\"><img alt=\"1\" class=\"selected\" src=\"https://images.craigslist.org/00g0g_88Ey8KXYStuz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"aaPbMGLaETwz_0ak06T\" href=\"https://images.craigslist.org/00w0w_aaPbMGLaETwz_0ak06T_600x450.jpg\" id=\"2_thumb_aaPbMGLaETwz_0ak06T\" title=\"2\"><img alt=\"2\" src=\"https://images.craigslist.org/00w0w_aaPbMGLaETwz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"6WurMx74uWVz_0ak06T\" href=\"https://images.craigslist.org/00O0O_6WurMx74uWVz_0ak06T_600x450.jpg\" id=\"3_thumb_6WurMx74uWVz_0ak06T\" title=\"3\"><img alt=\"3\" src=\"https://images.craigslist.org/00O0O_6WurMx74uWVz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"KtzAJFY3wbz_0ak06T\" href=\"https://images.craigslist.org/00d0d_KtzAJFY3wbz_0ak06T_600x450.jpg\" id=\"4_thumb_KtzAJFY3wbz_0ak06T\" title=\"4\"><img alt=\"4\" src=\"https://images.craigslist.org/00d0d_KtzAJFY3wbz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"1RfdclU1k57z_0ak06T\" href=\"https://images.craigslist.org/00L0L_1RfdclU1k57z_0ak06T_600x450.jpg\" id=\"5_thumb_1RfdclU1k57z_0ak06T\" title=\"5\"><img alt=\"5\" src=\"https://images.craigslist.org/00L0L_1RfdclU1k57z_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"7XuJIT7kuYrz_0ak06T\" href=\"https://images.craigslist.org/00p0p_7XuJIT7kuYrz_0ak06T_600x450.jpg\" id=\"6_thumb_7XuJIT7kuYrz_0ak06T\" title=\"6\"><img alt=\"6\" src=\"https://images.craigslist.org/00p0p_7XuJIT7kuYrz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"b45TWGHAAoLz_0ak06T\" href=\"https://images.craigslist.org/00E0E_b45TWGHAAoLz_0ak06T_600x450.jpg\" id=\"7_thumb_b45TWGHAAoLz_0ak06T\" title=\"7\"><img alt=\"7\" src=\"https://images.craigslist.org/00E0E_b45TWGHAAoLz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"5FQEWfnqjBoz_0ak06T\" href=\"https://images.craigslist.org/00K0K_5FQEWfnqjBoz_0ak06T_600x450.jpg\" id=\"8_thumb_5FQEWfnqjBoz_0ak06T\" title=\"8\"><img alt=\"8\" src=\"https://images.craigslist.org/00K0K_5FQEWfnqjBoz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"7pZPVPpYuxgz_0ak06T\" href=\"https://images.craigslist.org/01414_7pZPVPpYuxgz_0ak06T_600x450.jpg\" id=\"9_thumb_7pZPVPpYuxgz_0ak06T\" title=\"9\"><img alt=\"9\" src=\"https://images.craigslist.org/01414_7pZPVPpYuxgz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"7kAwB6GGescz_0ak06T\" href=\"https://images.craigslist.org/00606_7kAwB6GGescz_0ak06T_600x450.jpg\" id=\"10_thumb_7kAwB6GGescz_0ak06T\" title=\"10\"><img alt=\"10\" src=\"https://images.craigslist.org/00606_7kAwB6GGescz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"jcSy1zSJNS9z_0ak06T\" href=\"https://images.craigslist.org/00M0M_jcSy1zSJNS9z_0ak06T_600x450.jpg\" id=\"11_thumb_jcSy1zSJNS9z_0ak06T\" title=\"11\"><img alt=\"11\" src=\"https://images.craigslist.org/00M0M_jcSy1zSJNS9z_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"ht0ctW0GRT4z_0ak06T\" href=\"https://images.craigslist.org/00808_ht0ctW0GRT4z_0ak06T_600x450.jpg\" id=\"12_thumb_ht0ctW0GRT4z_0ak06T\" title=\"12\"><img alt=\"12\" src=\"https://images.craigslist.org/00808_ht0ctW0GRT4z_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"8ufBY6UwX2Sz_0ak06T\" href=\"https://images.craigslist.org/00O0O_8ufBY6UwX2Sz_0ak06T_600x450.jpg\" id=\"13_thumb_8ufBY6UwX2Sz_0ak06T\" title=\"13\"><img alt=\"13\" src=\"https://images.craigslist.org/00O0O_8ufBY6UwX2Sz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"etQCjQYVbDcz_0ak06T\" href=\"https://images.craigslist.org/00000_etQCjQYVbDcz_0ak06T_600x450.jpg\" id=\"14_thumb_etQCjQYVbDcz_0ak06T\" title=\"14\"><img alt=\"14\" src=\"https://images.craigslist.org/00000_etQCjQYVbDcz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"c6Ktx2KictGz_0ak06T\" href=\"https://images.craigslist.org/00j0j_c6Ktx2KictGz_0ak06T_600x450.jpg\" id=\"15_thumb_c6Ktx2KictGz_0ak06T\" title=\"15\"><img alt=\"15\" src=\"https://images.craigslist.org/00j0j_c6Ktx2KictGz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"jN2N1A4rFzez_0ak06T\" href=\"https://images.craigslist.org/01111_jN2N1A4rFzez_0ak06T_600x450.jpg\" id=\"16_thumb_jN2N1A4rFzez_0ak06T\" title=\"16\"><img alt=\"16\" src=\"https://images.craigslist.org/01111_jN2N1A4rFzez_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"dOEODSR3bawz_0ak06T\" href=\"https://images.craigslist.org/00R0R_dOEODSR3bawz_0ak06T_600x450.jpg\" id=\"17_thumb_dOEODSR3bawz_0ak06T\" title=\"17\"><img alt=\"17\" src=\"https://images.craigslist.org/00R0R_dOEODSR3bawz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"6dEa4giiQiHz_0ak06T\" href=\"https://images.craigslist.org/00z0z_6dEa4giiQiHz_0ak06T_600x450.jpg\" id=\"18_thumb_6dEa4giiQiHz_0ak06T\" title=\"18\"><img alt=\"18\" src=\"https://images.craigslist.org/00z0z_6dEa4giiQiHz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"93hDlMc3PEVz_0ak06T\" href=\"https://images.craigslist.org/00606_93hDlMc3PEVz_0ak06T_600x450.jpg\" id=\"19_thumb_93hDlMc3PEVz_0ak06T\" title=\"19\"><img alt=\"19\" src=\"https://images.craigslist.org/00606_93hDlMc3PEVz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"diR3OWIsuVz_0ak06T\" href=\"https://images.craigslist.org/01515_diR3OWIsuVz_0ak06T_600x450.jpg\" id=\"20_thumb_diR3OWIsuVz_0ak06T\" title=\"20\"><img alt=\"20\" src=\"https://images.craigslist.org/01515_diR3OWIsuVz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"iZLdXYnmhXFz_0ak06T\" href=\"https://images.craigslist.org/00a0a_iZLdXYnmhXFz_0ak06T_600x450.jpg\" id=\"21_thumb_iZLdXYnmhXFz_0ak06T\" title=\"21\"><img alt=\"21\" src=\"https://images.craigslist.org/00a0a_iZLdXYnmhXFz_0ak06T_50x50c.jpg\"/></a><a class=\"thumb\" data-imgid=\"ilNeEaQThzIz_0ak06T\" href=\"https://images.craigslist.org/00E0E_ilNeEaQThzIz_0ak06T_600x450.jpg\" id=\"22_thumb_ilNeEaQThzIz_0ak06T\" title=\"22\"><img alt=\"22\" src=\"https://images.craigslist.org/00E0E_ilNeEaQThzIz_0ak06T_50x50c.jpg\"/></a></div>\n",
       "<script type=\"text/javascript\"><!--\n",
       "var imgList = [{\"shortid\":\"88Ey8KXYStuz_0ak06T\",\"url\":\"https://images.craigslist.org/00g0g_88Ey8KXYStuz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00g0g_88Ey8KXYStuz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00g0g_88Ey8KXYStuz_0ak06T\"},{\"shortid\":\"aaPbMGLaETwz_0ak06T\",\"url\":\"https://images.craigslist.org/00w0w_aaPbMGLaETwz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00w0w_aaPbMGLaETwz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00w0w_aaPbMGLaETwz_0ak06T\"},{\"shortid\":\"6WurMx74uWVz_0ak06T\",\"url\":\"https://images.craigslist.org/00O0O_6WurMx74uWVz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00O0O_6WurMx74uWVz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00O0O_6WurMx74uWVz_0ak06T\"},{\"shortid\":\"KtzAJFY3wbz_0ak06T\",\"url\":\"https://images.craigslist.org/00d0d_KtzAJFY3wbz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00d0d_KtzAJFY3wbz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00d0d_KtzAJFY3wbz_0ak06T\"},{\"shortid\":\"1RfdclU1k57z_0ak06T\",\"url\":\"https://images.craigslist.org/00L0L_1RfdclU1k57z_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00L0L_1RfdclU1k57z_0ak06T_50x50c.jpg\",\"imgid\":\"3:00L0L_1RfdclU1k57z_0ak06T\"},{\"shortid\":\"7XuJIT7kuYrz_0ak06T\",\"url\":\"https://images.craigslist.org/00p0p_7XuJIT7kuYrz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00p0p_7XuJIT7kuYrz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00p0p_7XuJIT7kuYrz_0ak06T\"},{\"shortid\":\"b45TWGHAAoLz_0ak06T\",\"url\":\"https://images.craigslist.org/00E0E_b45TWGHAAoLz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00E0E_b45TWGHAAoLz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00E0E_b45TWGHAAoLz_0ak06T\"},{\"shortid\":\"5FQEWfnqjBoz_0ak06T\",\"url\":\"https://images.craigslist.org/00K0K_5FQEWfnqjBoz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00K0K_5FQEWfnqjBoz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00K0K_5FQEWfnqjBoz_0ak06T\"},{\"shortid\":\"7pZPVPpYuxgz_0ak06T\",\"url\":\"https://images.craigslist.org/01414_7pZPVPpYuxgz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/01414_7pZPVPpYuxgz_0ak06T_50x50c.jpg\",\"imgid\":\"3:01414_7pZPVPpYuxgz_0ak06T\"},{\"shortid\":\"7kAwB6GGescz_0ak06T\",\"url\":\"https://images.craigslist.org/00606_7kAwB6GGescz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00606_7kAwB6GGescz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00606_7kAwB6GGescz_0ak06T\"},{\"shortid\":\"jcSy1zSJNS9z_0ak06T\",\"url\":\"https://images.craigslist.org/00M0M_jcSy1zSJNS9z_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00M0M_jcSy1zSJNS9z_0ak06T_50x50c.jpg\",\"imgid\":\"3:00M0M_jcSy1zSJNS9z_0ak06T\"},{\"shortid\":\"ht0ctW0GRT4z_0ak06T\",\"url\":\"https://images.craigslist.org/00808_ht0ctW0GRT4z_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00808_ht0ctW0GRT4z_0ak06T_50x50c.jpg\",\"imgid\":\"3:00808_ht0ctW0GRT4z_0ak06T\"},{\"shortid\":\"8ufBY6UwX2Sz_0ak06T\",\"url\":\"https://images.craigslist.org/00O0O_8ufBY6UwX2Sz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00O0O_8ufBY6UwX2Sz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00O0O_8ufBY6UwX2Sz_0ak06T\"},{\"shortid\":\"etQCjQYVbDcz_0ak06T\",\"url\":\"https://images.craigslist.org/00000_etQCjQYVbDcz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00000_etQCjQYVbDcz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00000_etQCjQYVbDcz_0ak06T\"},{\"shortid\":\"c6Ktx2KictGz_0ak06T\",\"url\":\"https://images.craigslist.org/00j0j_c6Ktx2KictGz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00j0j_c6Ktx2KictGz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00j0j_c6Ktx2KictGz_0ak06T\"},{\"shortid\":\"jN2N1A4rFzez_0ak06T\",\"url\":\"https://images.craigslist.org/01111_jN2N1A4rFzez_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/01111_jN2N1A4rFzez_0ak06T_50x50c.jpg\",\"imgid\":\"3:01111_jN2N1A4rFzez_0ak06T\"},{\"shortid\":\"dOEODSR3bawz_0ak06T\",\"url\":\"https://images.craigslist.org/00R0R_dOEODSR3bawz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00R0R_dOEODSR3bawz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00R0R_dOEODSR3bawz_0ak06T\"},{\"shortid\":\"6dEa4giiQiHz_0ak06T\",\"url\":\"https://images.craigslist.org/00z0z_6dEa4giiQiHz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00z0z_6dEa4giiQiHz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00z0z_6dEa4giiQiHz_0ak06T\"},{\"shortid\":\"93hDlMc3PEVz_0ak06T\",\"url\":\"https://images.craigslist.org/00606_93hDlMc3PEVz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00606_93hDlMc3PEVz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00606_93hDlMc3PEVz_0ak06T\"},{\"shortid\":\"diR3OWIsuVz_0ak06T\",\"url\":\"https://images.craigslist.org/01515_diR3OWIsuVz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/01515_diR3OWIsuVz_0ak06T_50x50c.jpg\",\"imgid\":\"3:01515_diR3OWIsuVz_0ak06T\"},{\"shortid\":\"iZLdXYnmhXFz_0ak06T\",\"url\":\"https://images.craigslist.org/00a0a_iZLdXYnmhXFz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00a0a_iZLdXYnmhXFz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00a0a_iZLdXYnmhXFz_0ak06T\"},{\"shortid\":\"ilNeEaQThzIz_0ak06T\",\"url\":\"https://images.craigslist.org/00E0E_ilNeEaQThzIz_0ak06T_600x450.jpg\",\"thumb\":\"https://images.craigslist.org/00E0E_ilNeEaQThzIz_0ak06T_50x50c.jpg\",\"imgid\":\"3:00E0E_ilNeEaQThzIz_0ak06T\"}];\n",
       "--></script>\n",
       "</figure>\n",
       "<div class=\"mapAndAttrs\">\n",
       "<div class=\"mapbox\">\n",
       "<div class=\"viewposting\" data-accuracy=\"22\" data-latitude=\"25.813000\" data-longitude=\"-80.232000\" id=\"map\"></div>\n",
       "</div>\n",
       "<p class=\"attrgroup\">\n",
       "<span><b>2016 Toyota Tacoma Double Cab</b></span>\n",
       "<br/>\n",
       "</p>\n",
       "<p class=\"attrgroup\">\n",
       "<span>VIN: <b>3TMBZ5DN1GM001005</b></span>\n",
       "<br/>\n",
       "<span>cylinders: <b>6 cylinders</b></span>\n",
       "<br/>\n",
       "<span>fuel: <b>gas</b></span>\n",
       "<br/>\n",
       "<span>odometer: <b>64958</b></span>\n",
       "<br/>\n",
       "<span>paint color: <b>orange</b></span>\n",
       "<br/>\n",
       "<span>title status: <b>salvage</b></span>\n",
       "<br/>\n",
       "<span>transmission: <b>automatic</b></span>\n",
       "<br/>\n",
       "<span>type: <b>pickup</b></span>\n",
       "<br/>\n",
       "</p>\n",
       "</div>\n",
       "<section id=\"postingbody\">\n",
       "<div class=\"print-information print-qrcode-container\">\n",
       "<p class=\"print-qrcode-label\">QR Code Link to This Post</p>\n",
       "<div class=\"print-qrcode\" data-location=\"https://atlanta.craigslist.org/atl/ctd/d/miami-2016-toyota-tacoma-double-cab/7408971613.html\"></div>\n",
       "</div>\n",
       "<p><b>2016 Toyota Tacoma Double Cab TRD Sport Pickup 4D 6 ft - $15,950.00</b></p><p><br/>Call us today!  <b>(786) 460-1412</b><br/><br/><b>2016 Toyota Tacoma Double Cab</b> For Sale by Elite Motor Cars of Miami LLC</p><hr/><p><b>Vehicle Description for this Toyota Tacoma Double Cab</b><b><br/></b><br/>As -Is, Junk Title, Airbags Deployed, no trades, No financing, Call for more information, Located in Miami, FL<b></b></p><hr/><p><b>Vehicle Details for this Toyota Tacoma Double Cab</b></p><p></p><p>Price: $15,950.00<br/>Year: 2016<br/>Make: <b>Toyota</b><br/>Model: <b>Tacoma Double Cab<br/></b>Trim: <b>TRD Sport Pickup 4D 6 ft</b><br/>Odometer: 64958 miles<br/>Engine: V6, 3.5 Liter<br/>Transmission: Automatic, 6-Spd<br/>Color: ORANGE</p><p><b>Vehicle Options</b><br/></p><ul><li>V6, 3.5 Liter</li><li>Automatic, 6-Spd</li><li>2WD</li><li>Hill Start Assist Control</li><li>Traction Control</li><li>Stability Control</li><li>ABS (4-Wheel)</li><li>Anti-Theft System</li><li>Keyless Entry</li><li>Keyless Start</li><li>Air Conditioning</li><li>Sliding Rear Window</li><li>Power Windows</li><li>Power Door Locks</li><li>Cruise Control</li><li>Power Steering</li><li>Tilt &amp; Telescoping Wheel</li><li>AM/FM/HD Radio</li><li>CD/MP3 (Single Disc)</li><li>JBL Premium Sound</li><li>SiriusXM Satellilte</li><li>Navigation System</li><li>Bluetooth Wireless</li><li>Entune Premium Audio</li><li>Backup Camera</li><li>Dual Air Bags</li><li>Side Air Bags</li><li>F&amp;R Head Curtain Air Bags</li><li>Knee Air Bags</li><li>Daytime Running Lights</li><li>Fog Lights</li><li>Rear Spoiler</li><li>Towing Pkg</li><li>Alloy Wheels</li></ul><hr/><p><b>About Us</b><br/></p><p><b>Elite Motor Cars of Miami LLC</b><br/>5700 NW 27th Ave, Miami, FL, 33142<br/></p><p><i>We specialize in selling and exporting damaged and repairable vehicles. We offer both clean title vehicles and salvaged title vehicles from auction, insurance vehicle theft recovery and repossession for sale and export.<br/><br/></i><i>We can Arrange shipping for you worldwide</i>  - Give us a call for a shipping quote </p><p>Call NOW to reserve this <b>Toyota Tacoma Double Cab</b>! <b>(786) 460-1412</b><br/><br/>(786) 460-1412<br/></p><hr/><p><b>Vehicle Options</b><br/>V6, 3.5 Liter, Automatic, 6-Spd, 2WD, Hill Start Assist Control, Traction Control, Stability Control, ABS (4-Wheel), Anti-Theft System, Keyless Entry, Keyless Start, Air Conditioning, Sliding Rear Window, Power Windows, Power Door Locks, Cruise Control, Power Steering, Tilt &amp; Telescoping Wheel, AM/FM/HD Radio, CD/MP3 (Single Disc), JBL Premium Sound, SiriusXM Satellilte, Navigation System, Bluetooth Wireless, Entune Premium Audio, Backup Camera, Dual Air Bags, Side Air Bags, F&amp;R Head Curtain Air Bags, Knee Air Bags, Daytime Running Lights, Fog Lights, Rear Spoiler, Towing Pkg, Alloy Wheels,  Pickup Pickup 6  4 2WD V6, 3.5 Liter ORANGE Gasoline GRAY Automatic, 6-Spd<br/><br/>Disclaimer: All vehicles are sold in the condition described (As-Is) and are  subject to prior sale. </p><p>We reserve the right to make changes without notice, and are not responsible for errors or omissions.</p><p>All prices exclude government fees and taxes, any finance charges, and any emissions test charge</p><br/> <br/>Powered By DealerCenter    </section>\n",
       "<ul class=\"notices\">\n",
       "<li>do NOT contact me with unsolicited services or offers</li>\n",
       "</ul>\n",
       "<div class=\"postinginfos\">\n",
       "<p class=\"postinginfo\">post id: 7408971613</p>\n",
       "<p class=\"postinginfo reveal\">posted: <time class=\"date timeago\" datetime=\"2021-11-16T20:07:46-0500\">2021-11-16 20:07</time></p>\n",
       "<p class=\"postinginfo\">\n",
       "<a class=\"bestof-link\" href=\"https://post.craigslist.org/flag\" title=\"nominate for best-of-CL\">\n",
       "<span class=\"bestof-icon\">♥ </span><span class=\"bestof-text\">best of</span>\n",
       "</a> <sup>[<a href=\"https://www.craigslist.org/about/best-of-craigslist\">?</a>]</sup>\n",
       "</p>\n",
       "</div>\n",
       "<div class=\"print-information print-pics\"></div>\n",
       "</section>\n",
       "<div class=\"psa-box\">\n",
       "<aside class=\"tsb\">\n",
       "<ul>\n",
       "<li><a href=\"https://www.craigslist.org/about/safety\">safety tips</a>\n",
       "</li><li><a href=\"https://www.craigslist.org/about/prohibited\">prohibited items</a>\n",
       "</li><li><a href=\"https://www.craigslist.org/about/recalled_items\">product recalls</a>\n",
       "</li><li><a href=\"https://www.craigslist.org/about/scams\">avoiding scams</a>\n",
       "</li></ul>\n",
       "</aside>\n",
       "</div>\n",
       "<div class=\"avoid-scams\">\n",
       "<aside class=\"tsb\">\n",
       "<p>\n",
       "<a href=\"https://www.craigslist.org/about/scams\">Avoid scams, deal locally</a>\n",
       "<em>Beware wiring (e.g. Western Union), cashier checks, money orders, shipping.</em>\n",
       "</p>\n",
       "</aside>\n",
       "</div>\n",
       "</section>\n",
       "<footer>\n",
       "<ul class=\"clfooter\">\n",
       "<li>© 2021 <span class=\"desktop\">craigslist</span><span class=\"mobile\">CL</span></li>\n",
       "<li><a href=\"https://www.craigslist.org/about/help/\">help</a></li>\n",
       "<li><a href=\"https://www.craigslist.org/about/scams\">safety</a></li>\n",
       "<li class=\"desktop\"><a href=\"https://www.craigslist.org/about/privacy.policy\">privacy</a><sup class=\"neu\">new</sup></li>\n",
       "<li class=\"desktop\"><a href=\"https://forums.craigslist.org/?forumID=8\">feedback</a></li>\n",
       "<li><a href=\"https://www.craigslist.org/about/terms.of.use\">terms</a></li>\n",
       "<li><a href=\"https://www.craigslist.org/about/\">about</a></li>\n",
       "<li class=\"fsel desktop linklike\" data-mode=\"mobile\">mobile</li>\n",
       "<li class=\"fsel mobile linklike\" data-mode=\"regular\">desktop</li>\n",
       "</ul>\n",
       "</footer>\n",
       "</section>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapped output from url\n",
    "soup.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>2016 Toyota Tacoma Double Cab - Call Now! - cars &amp; trucks - by...</title>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Singular element:\n",
    "soup.html.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 Toyota Tacoma Double Cab - Call Now! - cars & trucks - by...\n"
     ]
    }
   ],
   "source": [
    "# Just the \"text\" between the tags: (notice the <title> tags get dropped)\n",
    "print(soup.html.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"header-logo\" href=\"/\" name=\"logoLink\">CL</a>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find single or multiple elements.\n",
    "# First parameter:\n",
    "element = soup.find_all(\"a\", {\"class\": \"header-logo\"}) # find header-logo in the \"soup.html\" output\n",
    "element[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leo's Advice on Scrapping\n",
    "- It's always advisable to right click the item you want to extract in the webpage and click Inspect.\n",
    "- In the window that opens up, you can directly see the tag, the class, etc of the item you want as shown below. The item you selected is already highlighted\n",
    "- It's then super simple to write the `soup.findAll()` function as shown in the next cell\n",
    "\n",
    "\n",
    "\n",
    "![](../assets/inspect.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$15950.00'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_search = soup.findAll('span', {\"class\": \"price\"}) # find price in the \"soup.html\" output\n",
    "price_search[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "### 3) Let's try to create a dataframe with ALL car listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# update our url to obtain ALL car listings in ATL:\n",
    "response = requests.get(\"https://atlanta.craigslist.org/search/cto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.text, \"lxml\") # repeat step2 from above\n",
    "result_list = soup.find_all('div', {'class':'result-info'}) # explore from url-->right click on a car listing-->inspect\n",
    "print(len(result_list)) # confirm number of listings per page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '1998 FORD ECONOLINE E250', 'price': 3000, 'hood': ' Atlanta city of atlanta '}\n"
     ]
    }
   ],
   "source": [
    "# extracting only car name (text), price and hood details per listing to pass into dataframe\n",
    "results = []\n",
    "for result in result_list: # loop over each car listing\n",
    "    car = {} # empty dict to house text, price, hood per car listing\n",
    "    car['text'] = result.find('a', {'class':'result-title hdrlnk'}).text # use inspect on url to cross-check\n",
    "    car['price'] = int(result.find('span', {'class':'result-price'}).text.replace('$','').replace(',',''))\n",
    "    hood = result.find('span', {'class':'result-hood'})\n",
    "    car['hood'] = hood.text.replace('(','').replace(')','') if hood else None # null if there is no hood information\n",
    "    results.append(car)\n",
    "    \n",
    "print(results[0]) # print 1st car listing to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>price</th>\n",
       "      <th>hood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998 FORD ECONOLINE E250</td>\n",
       "      <td>3000</td>\n",
       "      <td>Atlanta city of atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H1 Hummer</td>\n",
       "      <td>25000</td>\n",
       "      <td>Oxford city of atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006 FORD POLICE INTERCEPTOR</td>\n",
       "      <td>4900</td>\n",
       "      <td>Marietta city of atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009 Ford Crown Victoria Police Interceptor</td>\n",
       "      <td>6000</td>\n",
       "      <td>Marietta city of atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004 Nissan frontier</td>\n",
       "      <td>3900</td>\n",
       "      <td>Stockbridge city of atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>F150</td>\n",
       "      <td>3000</td>\n",
       "      <td>Stone mountain otp east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2014 Kia Soul +</td>\n",
       "      <td>8995</td>\n",
       "      <td>Lilburn otp east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2005 NISSAN UD 2300 LP DIESEL 75K MILES</td>\n",
       "      <td>18500</td>\n",
       "      <td>Duluth city of atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2013 Volkswagen Passat SE</td>\n",
       "      <td>13500</td>\n",
       "      <td>Brookhaven city of atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2008 DODGE RAM 1500  4x4  4 DOORS</td>\n",
       "      <td>8600</td>\n",
       "      <td>Duluth city of atlanta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text  price  \\\n",
       "0                       1998 FORD ECONOLINE E250   3000   \n",
       "1                                      H1 Hummer  25000   \n",
       "2                   2006 FORD POLICE INTERCEPTOR   4900   \n",
       "3    2009 Ford Crown Victoria Police Interceptor   6000   \n",
       "4                           2004 Nissan frontier   3900   \n",
       "..                                           ...    ...   \n",
       "115                                         F150   3000   \n",
       "116                              2014 Kia Soul +   8995   \n",
       "117      2005 NISSAN UD 2300 LP DIESEL 75K MILES  18500   \n",
       "118                    2013 Volkswagen Passat SE  13500   \n",
       "119            2008 DODGE RAM 1500  4x4  4 DOORS   8600   \n",
       "\n",
       "                              hood  \n",
       "0         Atlanta city of atlanta   \n",
       "1          Oxford city of atlanta   \n",
       "2        Marietta city of atlanta   \n",
       "3        Marietta city of atlanta   \n",
       "4     Stockbridge city of atlanta   \n",
       "..                             ...  \n",
       "115       Stone mountain otp east   \n",
       "116              Lilburn otp east   \n",
       "117        Duluth city of atlanta   \n",
       "118    Brookhaven city of atlanta   \n",
       "119        Duluth city of atlanta   \n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Practice**\n",
    "\n",
    "- How would you get the next 120 results?\n",
    "    - One probable solution has been shown below, to loop over all pages \n",
    "- How would you get the text associated with a particular car?\n",
    "    - Self-practice to modify from above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=0\n",
      "Max results: 2997\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=120\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=240\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=360\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=480\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=600\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=720\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=840\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=960\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1080\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1200\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1320\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1440\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1560\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1680\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1800\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1920\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=2040\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=2160\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=2280\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=2400\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=2520\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=2640\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=2760\n",
      "https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s=2880\n"
     ]
    }
   ],
   "source": [
    "# to automate ALL listings on the link:\n",
    "num_results = 0\n",
    "results = []\n",
    "\n",
    "while True:\n",
    "    # Update the URL for each page\n",
    "    url = f'https://atlanta.craigslist.org/d/cars-trucks-by-owner/search/cto?s={num_results}' # url updates every 120 listings(click next to confirm)\n",
    "    print(url)\n",
    "    \n",
    "    response = requests.get(url).text\n",
    "    soup = BeautifulSoup(response, \"lxml\")\n",
    "    \n",
    "    if num_results==0:\n",
    "        # For the first page, find the total number of results\n",
    "        max_results=int(soup.find('span', {'class':'totalcount'}).text)\n",
    "        print(f'Max results: {max_results}')\n",
    "    \n",
    "    # Find all postings\n",
    "    result_list = soup.find_all('div', {'class':'result-info'})\n",
    "    \n",
    "    # Iterate over each posting to find text, price and hood\n",
    "    for result in result_list:\n",
    "        car = {}\n",
    "        car['text'] = result.find('a', {'class':'result-title hdrlnk'}).text\n",
    "        car['price'] = int(result.find('span', {'class':'result-price'}).text.replace('$','').replace(',',''))\n",
    "        hood = result.find('span', {'class':'result-hood'})\n",
    "        car['hood'] = hood.text.replace('(','').replace(')','') if hood else None\n",
    "        results.append(car)\n",
    "    \n",
    "    # Increment to the next page\n",
    "    num_results=num_results+120\n",
    "    \n",
    "    # Break the loop if the next page is out of the max number of listings\n",
    "    if num_results>=max_results:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='xpath'></a>\n",
    "\n",
    "## What is XPath?\n",
    "\n",
    "---\n",
    "\n",
    "![](../assets/obama_wiki.png)\n",
    "\n",
    "Understanding how to identify elements and attributes within HTML documents gives us the ability to write simple expressions that create structured data, like we saw above, from a webpage to dataframe. \n",
    "\n",
    "We can think of **XPath like a _query language_ for HTML**.\n",
    "\n",
    "To simplify this process, we'll be using the Chrome extension XPath Helper. It's not necessary but highly recommended when building XPath expressions.\n",
    "\n",
    "[XPath Helper](https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl?hl=en).\n",
    "\n",
    "XPath expressions can select elements, element attributes, and element text. These selections can apply to a single item or multiple items. Generally, if you're not specific enough, you'll end up selecting multiple elements.\n",
    "\n",
    "\n",
    "<a id='multiple-selections'></a>\n",
    "### Multiple Selections\n",
    "\n",
    "***Multiple selections*** are useful for capturing search results or any repeating element. For instance, the _titles_ from apartment listing search results on Craigslist.\n",
    "\n",
    "\n",
    "**URL**\n",
    "\n",
    "[http://sfbay.craigslist.org/search/sfc/apa](http://sfbay.craigslist.org/search/sfc/apa)\n",
    "\n",
    "\n",
    "**Example HTML Markup** _(varies depending on listing changes, but is a fragment of what we can see from \"inspect\" window of an apartment listing)_\n",
    "```html\n",
    "...\n",
    "<a href=\"https://sfbay.craigslist.org/sfc/apa/d/san-francisco-spacious-top-floor-bdr/7394875800.html\" data-id=\"7394875800\" class=\"result-title hdrlnk\" id=\"postid_7394875800\">/:/:/:/:/: Spacious top floor 1 Bdr Apartment /:/:/:/:/:</a>\n",
    "...\n",
    "```\n",
    "\n",
    "**XPath:: Multiple Titles** _Copy this into the XPath Helper Query box (Ctrl + Shift + X is a shortcut to open the query box while still on apartments listing chrome page)_:\n",
    "```\n",
    "//a[@class='result-title hdrlnk']\n",
    "```\n",
    "\n",
    "**Returns (All Ad Titles on page)**\n",
    "```\n",
    "/:/:/:/:/: Spacious top floor 1 Bdr Apartment /:/:/:/:/:\n",
    "Edwardian Charm, Modern Convenience, Spacious 2 BR Apt\n",
    "2Bedrooms / 1 Bath $2,000\n",
    "Beautifully maintained and updated Pac Heights condo - 2 Bed 2 Bath\n",
    "etc...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='singular-selections'></a>\n",
    "\n",
    "### Singular Selections\n",
    "\n",
    "***Singular selections*** are necessary when you want to grab specific, unique text within elements. Here's an example of a details page on Craigslist:\n",
    "\n",
    "\n",
    "**HTML Markup**\n",
    "\n",
    "```html\n",
    "<div class=\"postinginfos\">\n",
    "    <p class=\"postinginfo\">post id: 5400585892</p>\n",
    "    <p class=\"postinginfo\">posted: <time datetime=\"2016-01-12T23:23:19-0800\" class=\"xh-highlight\">2016-01-12 11:23pm</time></p>\n",
    "    <p class=\"postinginfo\"><a href=\"https://accounts.craigslist.org/eaf?postingID=5400585892\" class=\"tsb\">email to friend</a></p>\n",
    "    <p class=\"postinginfo\"><a class=\"bestof-link\" data-flag=\"9\" href=\"https://post.craigslist.org/flag?flagCode=9&amp;postingID=5400585892\" title=\"nominate for best-of-CL\"><span class=\"bestof-icon\">♥ </span><span class=\"bestof-text\">best of</span></a> <sup>[<a href=\"http://www.craigslist.org/about/best-of-craigslist\">?</a>]</sup>    </p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "**XPath: Single Item** --> *gets 2nd p class='postinginfo', value inside time tag*\n",
    "\n",
    "```\n",
    "//p[@class='postinginfo'][2]/time \n",
    "```\n",
    "**Returns (Time of Posting or Age of Post)**\n",
    "```\n",
    "2016-01-12 11:23pm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scrapy'></a>\n",
    "\n",
    "## A Simple Example Using Scrapy and XPath\n",
    "\n",
    "---\n",
    "\n",
    "Below is an example of how to get information out of fake HTML using the XPath capabilities of the **Scrapy** package. You'll likely need to install the Scrapy package using `conda install scrapy`.   \n",
    "\n",
    "**Note:** `conda install` will install the necessary dependent packages needed for Scrapy; `pip install` will **not**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `selector` class from the Scrapy library to help us construct our query.\n",
    "\n",
    "`Selector` classes take the HTML target as an argument and can then utilize several query types to extract information. In this case, we'll specify `XPath`, as our query, which will then utilize XPath language. \n",
    "\n",
    "Just like with writing Python scripts, there are several ways you can access the exact same information in HTML. Let's try a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "\n",
    "# HTML structure string:\n",
    "HTML = \"\"\"\n",
    "<body>\n",
    "<div class=\"postinginfos\">\n",
    "    <p class=\"postinginfo\">post id: 5400585892</p>\n",
    "    <p class=\"postinginfo\">posted: <time datetime=\"2016-01-12T23:23:19-0800\" class=\"xh-highlight\">2016-01-12 11:23pm</time></p>\n",
    "    <p class=\"postinginfo\"><a href=\"https://accounts.craigslist.org/eaf?postingID=5400585892\" class=\"tsb\">email to friend</a></p>\n",
    "    <p class=\"postinginfo\"><a class=\"bestof-link\" data-flag=\"9\" href=\"https://post.craigslist.org/flag?flagCode=9&amp;postingID=5400585892\" title=\"nominate for best-of-CL\"><span class=\"bestof-icon\">♥ </span><span class=\"bestof-text\">best of</span></a> <sup>[<a href=\"http://www.craigslist.org/about/best-of-craigslist\">?</a>]</sup>    </p>\n",
    "</div>\n",
    "</body>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best of']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1: Use the exact class name to get its associated text.\n",
    "best = Selector(text=HTML).xpath(\"//span[@class='bestof-text']/text()\").extract()\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best of']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2: Use the contains() function to extract any text that includes the text 'best of.'\n",
    "best = Selector(text=HTML).xpath(\"//span[contains(text(), 'best of')]/text()\").extract()\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Selector xpath=\"/html/body/div/p/a[@class='bestof-link']\" data='<a class=\"bestof-link\" data-flag=\"9\" ...'>]\n",
      "['best of']\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Grabs the entire HTML post where class='bestof-link'.\n",
    "best =  Selector(text=HTML).xpath(\"/html/body/div/p/a[@class='bestof-link']\")\n",
    "# Parse the first grabbed chunk of the text for the specific element with class='bestof-text'.\n",
    "print(best)\n",
    "\n",
    "nested_best =  best.xpath(\"./span[@class='bestof-text']/text()\").extract()\n",
    "print(nested_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**: _Option 3 will probably be the most common because there's a good chance you'll want to grab information from several child elements that exist within one parent element._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Where's Waldo?](https://waldo.fandom.com/wiki/Waldo) — XPath Edition\n",
    "\n",
    "In this example, we'll find Waldo together. Find Waldo as:\n",
    "\n",
    "- An element.\n",
    "- An attribute.\n",
    "- A text element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        \n",
    "        <ul id=\"waldo\">\n",
    "            <li class=\"waldo\">\n",
    "                <span> yo I'm not here</span>\n",
    "            </li>\n",
    "            <li class=\"waldo\">Height:  ???</li>\n",
    "            <li class=\"waldo\">Weight:  ???</li>\n",
    "            <li class=\"waldo\">Last Location:  ???</li>\n",
    "            <li class=\"nerds\">\n",
    "                <div class=\"alpha\">Bill Gates</div>\n",
    "                <div class=\"alpha\">Zuckerberg</div>\n",
    "                <div class=\"beta\">Theil</div>\n",
    "                <div class=\"animal\">Parker</div>\n",
    "            </li>\n",
    "        </ul>\n",
    "        \n",
    "        <ul id=\"tim\">\n",
    "            <li class=\"tdawg\">\n",
    "                <span>yo im here</span>\n",
    "            </li>\n",
    "        </ul>\n",
    "        <li>stuff</li>\n",
    "        <li>stuff2</li>\n",
    "        \n",
    "        <div id=\"cooldiv\">\n",
    "            <span class=\"dsi-rocks\">\n",
    "               YO!\n",
    "            </span>\n",
    "        </div>\n",
    "        \n",
    "        \n",
    "        <waldo>Waldo</waldo>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the **element** 'Waldo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Waldo']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text contents of the element Waldo using the syntax we saw previously-->returns 'element' within <waldo> tags\n",
    "Selector(text=HTML).xpath('/html/body/waldo/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the **attribute(s)** 'Waldo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the asterisk character `*` as a placeholder for \"**All possible**.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<ul id=\"waldo\">\\n            <li class=\"waldo\">\\n                <span> yo I\\'m not here</span>\\n            </li>\\n            <li class=\"waldo\">Height:  ???</li>\\n            <li class=\"waldo\">Weight:  ???</li>\\n            <li class=\"waldo\">Last Location:  ???</li>\\n            <li class=\"nerds\">\\n                <div class=\"alpha\">Bill Gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">Parker</div>\\n            </li>\\n        </ul>\\n        \\n        <ul id=\"tim\">\\n            <li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>\\n        </ul>\\n        <li>stuff</li>\\n        <li>stuff2</li>\\n        \\n        <div id=\"cooldiv\">\\n            <span class=\"dsi-rocks\">\\n               YO!\\n            </span>\\n        </div>\\n        \\n        \\n        <waldo>Waldo</waldo>\\n    </body>\\n</html>\\n',\n",
       " '<li class=\"waldo\">\\n                <span> yo I\\'m not here</span>\\n            </li>\\n            <li class=\"waldo\">Height:  ???</li>\\n            <li class=\"waldo\">Weight:  ???</li>\\n            <li class=\"waldo\">Last Location:  ???</li>\\n            <li class=\"nerds\">\\n                <div class=\"alpha\">Bill Gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">Parker</div>\\n            </li>\\n        </ul>\\n        \\n        <ul id=\"tim\">\\n            <li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>\\n        </ul>\\n        <li>stuff</li>\\n        <li>stuff2</li>\\n        \\n        <div id=\"cooldiv\">\\n            <span class=\"dsi-rocks\">\\n               YO!\\n            </span>\\n        </div>\\n        \\n        \\n        <waldo>Waldo</waldo>\\n    </body>\\n</html>\\n',\n",
       " '<li class=\"waldo\">Height:  ???</li>\\n            <li class=\"waldo\">Weight:  ???</li>\\n            <li class=\"waldo\">Last Location:  ???</li>\\n            <li class=\"nerds\">\\n                <div class=\"alpha\">Bill Gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">Parker</div>\\n            </li>\\n        </ul>\\n        \\n        <ul id=\"tim\">\\n            <li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>\\n        </ul>\\n        <li>stuff</li>\\n        <li>stuff2</li>\\n        \\n        <div id=\"cooldiv\">\\n            <span class=\"dsi-rocks\">\\n               YO!\\n            </span>\\n        </div>\\n        \\n        \\n        <waldo>Waldo</waldo>\\n    </body>\\n</html>\\n',\n",
       " '<li class=\"waldo\">Weight:  ???</li>\\n            <li class=\"waldo\">Last Location:  ???</li>\\n            <li class=\"nerds\">\\n                <div class=\"alpha\">Bill Gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">Parker</div>\\n            </li>\\n        </ul>\\n        \\n        <ul id=\"tim\">\\n            <li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>\\n        </ul>\\n        <li>stuff</li>\\n        <li>stuff2</li>\\n        \\n        <div id=\"cooldiv\">\\n            <span class=\"dsi-rocks\">\\n               YO!\\n            </span>\\n        </div>\\n        \\n        \\n        <waldo>Waldo</waldo>\\n    </body>\\n</html>\\n',\n",
       " '<li class=\"waldo\">Last Location:  ???</li>\\n            <li class=\"nerds\">\\n                <div class=\"alpha\">Bill Gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">Parker</div>\\n            </li>\\n        </ul>\\n        \\n        <ul id=\"tim\">\\n            <li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>\\n        </ul>\\n        <li>stuff</li>\\n        <li>stuff2</li>\\n        \\n        <div id=\"cooldiv\">\\n            <span class=\"dsi-rocks\">\\n               YO!\\n            </span>\\n        </div>\\n        \\n        \\n        <waldo>Waldo</waldo>\\n    </body>\\n</html>\\n']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contents of \"all attributes\" named Waldo:\n",
    "Selector(text=HTML).xpath('//*[@*=\"waldo\"]').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<li class=\"waldo\">\\n                <span> yo I\\'m not here</span>\\n            </li>\\n            <li class=\"waldo\">Height:  ???</li>\\n            <li class=\"waldo\">Weight:  ???</li>\\n            <li class=\"waldo\">Last Location:  ???</li>\\n            <li class=\"nerds\">\\n                <div class=\"alpha\">Bill Gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">Parker</div>\\n            </li>\\n        </ul>\\n        \\n        <ul id=\"tim\">\\n            <li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>\\n        </ul>\\n        <li>stuff</li>\\n        <li>stuff2</li>\\n        \\n        <div id=\"cooldiv\">\\n            <span class=\"dsi-rocks\">\\n               YO!\\n            </span>\\n        </div>\\n        \\n        \\n        <waldo>Waldo</waldo>\\n    </body>\\n</html>\\n',\n",
       " '<li class=\"waldo\">Height:  ???</li>\\n            <li class=\"waldo\">Weight:  ???</li>\\n            <li class=\"waldo\">Last Location:  ???</li>\\n            <li class=\"nerds\">\\n                <div class=\"alpha\">Bill Gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">Parker</div>\\n            </li>\\n        </ul>\\n        \\n        <ul id=\"tim\">\\n            <li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>\\n        </ul>\\n        <li>stuff</li>\\n        <li>stuff2</li>\\n        \\n        <div id=\"cooldiv\">\\n            <span class=\"dsi-rocks\">\\n               YO!\\n            </span>\\n        </div>\\n        \\n        \\n        <waldo>Waldo</waldo>\\n    </body>\\n</html>\\n',\n",
       " '<li class=\"waldo\">Weight:  ???</li>\\n            <li class=\"waldo\">Last Location:  ???</li>\\n            <li class=\"nerds\">\\n                <div class=\"alpha\">Bill Gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">Parker</div>\\n            </li>\\n        </ul>\\n        \\n        <ul id=\"tim\">\\n            <li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>\\n        </ul>\\n        <li>stuff</li>\\n        <li>stuff2</li>\\n        \\n        <div id=\"cooldiv\">\\n            <span class=\"dsi-rocks\">\\n               YO!\\n            </span>\\n        </div>\\n        \\n        \\n        <waldo>Waldo</waldo>\\n    </body>\\n</html>\\n',\n",
       " '<li class=\"waldo\">Last Location:  ???</li>\\n            <li class=\"nerds\">\\n                <div class=\"alpha\">Bill Gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">Parker</div>\\n            </li>\\n        </ul>\\n        \\n        <ul id=\"tim\">\\n            <li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>\\n        </ul>\\n        <li>stuff</li>\\n        <li>stuff2</li>\\n        \\n        <div id=\"cooldiv\">\\n            <span class=\"dsi-rocks\">\\n               YO!\\n            </span>\\n        </div>\\n        \\n        \\n        <waldo>Waldo</waldo>\\n    </body>\\n</html>\\n']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contents of \"all class attributes\" named Waldo:\n",
    "Selector(text=HTML).xpath('//*[@class=\"waldo\"]').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the **text element** 'Waldo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<waldo>Waldo</waldo>\\n    </body>\\n</html>\\n']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets everything around the text element Waldo:\n",
    "Selector(text=HTML).xpath(\"//*[text()='Waldo']\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Personally, I only use beautiful soup. it's been able to solve most of my web scrapping needs so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scrapy'></a>\n",
    "<a scrapy-spiders></a>\n",
    "## What is a Scrapy Spider? \n",
    "<mark style=\"background-color: lightgray\">_[BONUS knowledge. Not required for Lab. The craigslist webpage has has restrictions in place to prevent crawling, thus we're unable to retrieve content post following below steps]_</mark>\n",
    "\n",
    "---\n",
    "\n",
    "> *\"[Scrapy](http://scrapy.org/) is an application framework for writing web spiders that \"crawl\" around websites and extract data from them.\"*\n",
    "\n",
    "Below we'll walk through the creation of a **spider** using Scrapy. Spiders are automated processes that will crawl through a web page or web pages to collect information.\n",
    "\n",
    "> **Note:** This code should be written in a script outside of Jupyter.\n",
    "\n",
    "<a id='scrapy-project'></a>\n",
    "### 1) Create a new Scrapy project.\n",
    "\n",
    "In your terminal, `cd` into a directory where you want to create your spider's folder. We recommend the desktop for easy access to the files.\n",
    "> `scrapy startproject craigslist`\n",
    "\n",
    "**It should create an output that looks like this:**\n",
    "\n",
    "```\n",
    "New Scrapy project 'craigslist', using template directory '/Users/jmpounders/anaconda3/lib/python3.6/site-packages/scrapy/templates/project', created in:\n",
    "    /Users/jmpounders/dsi-east-2/scrapy/craigslist\n",
    "\n",
    "You can start your first spider with:\n",
    "    cd craigslist\n",
    "    scrapy genspider example example.com\n",
    "```\n",
    "\n",
    "**That command generates a set of project files:**\n",
    "\n",
    "```\n",
    "├── craigslist\n",
    "│   ├── __init__.py\n",
    "│   ├── __pycache__\n",
    "│   ├── items.py\n",
    "│   ├── middlewares.py\n",
    "│   ├── pipelines.py\n",
    "│   ├── settings.py\n",
    "│   └── spiders\n",
    "│       ├── __init__.py\n",
    "│       └── __pycache__\n",
    "└── scrapy.cfg\n",
    "```\n",
    "\n",
    "Generally, these are our files. We'll go into more detail on these soon.\n",
    "\n",
    " * **`scrapy.cfg`:** The project's configuration file.\n",
    " * **`craigslist/`:** The project’s Python module — you’ll import your code from here later.\n",
    " * **`craigslist/items.py`:** The project’s items file.\n",
    " * **`craigslist/pipelines.py`:** The project’s pipelines file.\n",
    " * **`craigslist/settings.py`:** The project’s settings file.\n",
    " * **`craigslist/spiders/`:** A directory where you’ll store your spiders.\n",
    " \n",
    "Please also add this line to your `craigslist/settings.py` file (at the last line) before continuing:\n",
    " \n",
    " ```\n",
    " DOWNLOAD_HANDLERS = {'s3': None,}\n",
    " ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "<a id='define-item'></a>\n",
    "### 2) Define an \"item.\"\n",
    "\n",
    "When we define an **item**, we're telling our new application **what it will be collecting**. In essence, an item is an entity that has attributes (\"title,\" \"description,\" \"price,\" etc.) that are descriptive and relate to elements on pages we'll be scraping.  \n",
    "\n",
    "In more precise terms, this is a model (for those who are familiar with object-relational mapping or relational database terms). Don't worry if this is a foreign concept.  The main idea is to understand that a model has attributes that closely resemble or relate to elements on our target web page(s).\n",
    "\n",
    "**Paste this inside `items.py`:** \n",
    "```python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Define here the models for your scraped items.\n",
    "#\n",
    "# See documentation in:\n",
    "# http://doc.scrapy.org/en/latest/topics/items.html\n",
    "\n",
    "import scrapy\n",
    "\n",
    "class CraigslistItem(scrapy.Item):\n",
    "    # Define the fields for your item here like:\n",
    "    # name = scrapy.Field()\n",
    "    title = scrapy.Field()\n",
    "    link = scrapy.Field()\n",
    "    price = scrapy.Field()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='spider-crawl'></a>\n",
    "### 3) A spider that crawls.\n",
    "\n",
    "An item is a model that resembles data on a web page. A spider is something that crawls pages and uses our item model to get and hold items for us.\n",
    "\n",
    "**Scrapy spiders are Python classes. Let's write our first file, called `craigslist_spider.py`, and put it in our `/spiders` directory.**\n",
    "\n",
    "```python\n",
    "import scrapy\n",
    "\n",
    "class CraigslistSpider(scrapy.Spider):\n",
    "    name = \"craigslist\"\n",
    "    allowed_domains = [\"craigslist.org\"]\n",
    "    start_urls = [\n",
    "        \"https://atlanta.craigslist.org/search/cto\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        filename = response.url.split(\"/\")[-2]\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)\n",
    "```\n",
    "\n",
    "**Next, let's dive in and crawl from our `/craigslist/craigslist` directory.**\n",
    "\n",
    "Type below in command prompt, from inside the `/craigslist/craigslist` directory:\n",
    "```\n",
    "> scrapy crawl craigslist\n",
    "```\n",
    "\n",
    "**What just happened?**\n",
    " * Our application requested the URLs from the `start_urls` class attribute.\n",
    " * It parsed over the content containing the HTML markup of each request URL.\n",
    " * What else?\n",
    " \n",
    "```python\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.body)\n",
    "```\n",
    "\n",
    "It saved a file in our base project directory. It should be named based on the end of the URL. In our case, it should create a file called \"sfc.\" This is taken directly from the Scrapy docs and its only point is to illustrate the workflow so far. It's nice to have a reference to our HTML file.  \n",
    "\n",
    "There might be some errors listed when we crawl, but they are fine for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "<a id='xpath-spider'></a>\n",
    "### 4) XPath and parsing with our spider.\n",
    "\n",
    "So far, we've defined the fields we'll get, some URLs to fetch, and saved some content to a file. Now, it's about to get interesting.\n",
    "\n",
    "**We should let our spider know about the item model we created earlier. In the head of the `craigslist/craigslist/spiders/craigslist_spider.py`, let's add a new import.**\n",
    "\n",
    "```python\n",
    "from craigslist.items import CraigslistItem\n",
    "```\n",
    "\n",
    "> **Check:** Why won't it work otherwise?\n",
    "\n",
    "<br><br><br>\n",
    "**Let's replace our `parse()` method to find some data from our Craigslist spider response and map them to our item model, `CraigslistItem`.**\n",
    "\n",
    "\n",
    "```python\n",
    "def parse(self, response): # Define parse() function. \n",
    "    items = [] # Element for storing scraped information.\n",
    "\thxs = Selector(response) # Selector allows us to grab HTML from the response (target website).\n",
    "\tfor sel in hxs.xpath(\"//li[@class='result-row']/p\"): # Because we're using XPath language, we need to specify that the paragraphs we're trying to isolate are expressed via XPath.\n",
    "\t\titem = CraigslistItem()\n",
    "        item['title'] =  sel.xpath(\"a/text()\").extract() # Title text from the 'a' element. \n",
    "\t\titem['link']  =  sel.xpath(\"a/@href\").extract() # Href/URL from the 'a' element. \n",
    "\t\titem['price'] =  sel.xpath('span/span[@class=\"result-price\"]/text()').extract()[0]\n",
    "                # Price from the result price class nested in a few span elements.\n",
    "        items.append(item)\n",
    "\treturn items # Shows scraped information as terminal output.\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='save-examine'></a>\n",
    "### 5) Save and examine our scraped data.\n",
    "\n",
    "By default, we can save our crawled data in a CSV format. To save our data, we just need to pass a few optional parameters to our crawl call:\n",
    "\n",
    "<blockquote>\n",
    "```\n",
    "> scrapy crawl craigslist -o items.csv -t csv\n",
    "```\n",
    "</blockquote>\n",
    "\n",
    "It's always good to iteratively check the data when developing a spider to make sure the set is close to what we want. \n",
    "\n",
    "> *Pro tip: The longer your iterations are between checks, the harder it's going to be to understand what's not working and fix bugs.*\n",
    "\n",
    "You should now have a file called '`items.csv`' in the directory from which you ran the `scrapy crawl` command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='addendum'></a>\n",
    "## Addendum: Leveraging XPath to Get More Results\n",
    "\n",
    "---\n",
    "\n",
    "Generally, a workflow that's useful in this context is to load the page in your Chrome browser, check out the page using the XPath Helper plugin, and, from that, derive your own XPath expressions based on the output.\n",
    "\n",
    "`text()` selects only the **text of a given element (_between the tags_)**, and `@attribute_name` is used to select **attributes**.\n",
    "\n",
    "**Example of `text()`:**\n",
    "\n",
    "```\n",
    "<h1>Darwin - The Evolution Of An Exhibition</h1>\n",
    "```\n",
    "\n",
    "The XPath selector for this:\n",
    "\n",
    "```\n",
    "//h1/text()\n",
    "```\n",
    "\n",
    "**Example of `attributes`:**\n",
    "\n",
    "Consider the below description contained inside a `<div>` tag with `id=\"description\"`:\n",
    "\n",
    "```\n",
    "<h2>Description:</h2>\n",
    "\n",
    "<div id=\"description\">\n",
    "Short documentary made for the Plymouth City Museum and Art Gallery regarding the set up of an exhibit about Charles Darwin in conjunction with the 200th anniversary of his birth.\n",
    "</div>\n",
    "...\n",
    "```\n",
    "\n",
    "The XPath selector for this:\n",
    "```\n",
    "//div[@id='description']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='follow-links'></a>\n",
    "### Following Links for More Results\n",
    "\n",
    "One hundred results is pretty good, but what if we want more? We need to follow the \"next\" links and find new pages to grab. Using the **`parse()`** method of our spider class, we need to return another type of object.\n",
    "\n",
    "See [Stack Overflow](https://stackoverflow.com/questions/30152261/make-scrapy-follow-links-and-collect-data) for details!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
