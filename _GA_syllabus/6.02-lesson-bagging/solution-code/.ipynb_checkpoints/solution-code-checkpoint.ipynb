{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Bootstrapping and Bagging\n",
    "\n",
    "### Learning Objectives\n",
    "- Define ensemble model.\n",
    "- Name three advantages of using ensemble models.\n",
    "- Define and execute bootstrapping.\n",
    "- Fit and evaluate bagged decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import Bagging Classifier.\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We'll be using the `Heart.csv` from the [ISLR Website](https://www.statlearning.com/). There's a copy in this repo under `./datasets/Heart.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  \\\n",
       "0           1   63    1       typical     145   233    1        2    150   \n",
       "1           2   67    1  asymptomatic     160   286    0        2    108   \n",
       "2           3   67    1  asymptomatic     120   229    0        2    129   \n",
       "3           4   37    1    nonanginal     130   250    0        0    187   \n",
       "4           5   41    0    nontypical     130   204    0        2    172   \n",
       "\n",
       "   ExAng  Oldpeak  Slope   Ca        Thal  AHD  \n",
       "0      0      2.3      3  0.0       fixed   No  \n",
       "1      1      1.5      2  3.0      normal  Yes  \n",
       "2      1      2.6      2  2.0  reversable  Yes  \n",
       "3      0      3.5      3  0.0      normal   No  \n",
       "4      0      1.4      1  0.0      normal   No  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the Heart .csv data.\n",
    "df = pd.read_csv('../datasets/Heart.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Model Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>ChestPain_nonanginal</th>\n",
       "      <th>ChestPain_nontypical</th>\n",
       "      <th>ChestPain_typical</th>\n",
       "      <th>Thal_normal</th>\n",
       "      <th>Thal_reversable</th>\n",
       "      <th>AHD_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  Slope   Ca  \\\n",
       "0   63    1     145   233    1        2    150      0      2.3      3  0.0   \n",
       "1   67    1     160   286    0        2    108      1      1.5      2  3.0   \n",
       "2   67    1     120   229    0        2    129      1      2.6      2  2.0   \n",
       "3   37    1     130   250    0        0    187      0      3.5      3  0.0   \n",
       "4   41    0     130   204    0        2    172      0      1.4      1  0.0   \n",
       "\n",
       "   ChestPain_nonanginal  ChestPain_nontypical  ChestPain_typical  Thal_normal  \\\n",
       "0                     0                     0                  1            0   \n",
       "1                     0                     0                  0            1   \n",
       "2                     0                     0                  0            0   \n",
       "3                     1                     0                  0            1   \n",
       "4                     0                     1                  0            1   \n",
       "\n",
       "   Thal_reversable  AHD_Yes  \n",
       "0                0        0  \n",
       "1                0        1  \n",
       "2                1        1  \n",
       "3                0        0  \n",
       "4                0        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the `Unnamed: 0` column.\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Drop NAs.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Create dummies for categorical cols: `ChestPain`, `Thal`, and `AHD` columns. Be sure to set `drop_first=True` to take 1st value as baseline reference.\n",
    "df = pd.get_dummies(df, columns=['ChestPain', 'Thal', 'AHD'], drop_first=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target column will be `AHD_Yes`: \n",
    "- **1** means the patient has heart disease\n",
    "- **0** means they aren't diagnosed with heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y for model.\n",
    "X = df.drop('AHD_Yes', axis='columns')\n",
    "y = df['AHD_Yes']\n",
    "\n",
    "# Split data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.538721\n",
       "1    0.461279\n",
       "Name: AHD_Yes, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the accuracy of our baseline model? \n",
    "# The baseline accuracy is the percentage of the majority class, regardless of whether it is 1 or 0. \n",
    "# It serves as the benchmark for our model to beat.\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What does a false positive mean in this context?</summary>\n",
    "    \n",
    "- A false positive indicates someone is **falsely** predicted as being in the **positive** class. <br>\n",
    "- This is someone we incorrectly think has heart disease. <br>\n",
    "- Incorrectly predicting someone to have heart disease is bad... but it _might_ be worse to incorrectly predict that someone is healthy! In other words, in this context, it is MORE of a problem for our model to predict high FNs.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate `DecisionTreeClassifier` object.\n",
    "tree = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: The role of randomness\n",
    "\n",
    "The algorithms that fit tree-based methods involve randomness, which means it's important to specify a `random_state` if you want to reproduce your results. This is always a good idea.\n",
    "- Changing `random_state` from 42 to 43 reduces our model's test performance by ***6%!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and score on the training data.\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score on the testing data.\n",
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> Where do decision trees tend to fall on the Bias/Variance spectrum?</summary>\n",
    "    \n",
    "- Decision trees very easily **overfit**. <br>\n",
    "- They tend to suffer from **high error due to variance**.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "\n",
    "Bootstrapping is a powerful idea used frequently across statistics and data science.\n",
    "- One common use for bootstrapping is to use computers and random number generation to generate confidence intervals or execute hypothesis tests for us, instead of relying on the Central Limit Theorem and memorized formulas.\n",
    "- We'll use it later to improve the performance of our decision tree models!\n",
    "\n",
    "\n",
    "#### What is the motivation behind bootstrapping?\n",
    "In a perfect world, we would have access to the full population of data instead of a sample of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Why is it unrealistic to assume we have access to the full population of data?</summary>\n",
    "    \n",
    "- It would take too much time. <br>\n",
    "- It would cost too much money. <br>\n",
    "- Logistical challenges.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a few words, bootstrapping is <span style=\"color:blue\">**random resampling with replacement**</span>.\n",
    "\n",
    "<span style=\"color:blue\"><b>The idea is this:</b></span>\n",
    "\n",
    "- Take your original sample of data, with sample size $n$.\n",
    "- Take many sub-samples (say $B$) of size $n$ from your sample **with replacement** (The same data point can be picked multiple times). These are called <span style=\"color:blue\">**bootstrapped samples**</span>.\n",
    "- You have now generated $B$ bootstrapped samples, where each sample is of size $n$!\n",
    "\n",
    "<img src=\"../assets/bootstrap.png\" alt=\"drawing\" width=\"550\"/>\n",
    "\n",
    "- Instead of building one model on our original sample, we will now build one model on each bootstrapped sample, giving us $B$ models in total!\n",
    "- Experience tells us that combining the models from our bootstrapped samples will be closer to what we'd see from the population than to just get one model from our original sample.\n",
    "\n",
    "This sets up the idea of an **ensemble model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Why do you think we want to take a sample of size n?</summary>\n",
    "    \n",
    "- Because we want our estimators to be fit on data of the <b>same size!</b> <br>\n",
    "- If our original data had a sample size of 1,000, but we fit decision trees to samples of size 50, the decision trees fit to samples of size 50 will probably look very, very different from decision trees fit on a sample of size 1,000.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Why do you think we want to sample with replacement?</summary>\n",
    "    \n",
    "- If we didn't sample with replacement, we'd just get identical samples of size $n$. (That is, copies of our original data!) <br>\n",
    "- With replacement, the same data point can be picked multiple times randomly. This makes each sample to be slightly different from each other. <br>\n",
    "- Eg: If our original data is [1,2,3,4,5] and we sample 3 times with replacement, we could get 3 samples that look like this: <br>\n",
    "- Sample1: [1,3,3,4,5] (2 is not picked but 3 is picked twice) <br>\n",
    "- Sample2: [1,2,3,4,2] (5 is not picked but 2 is picked twice) <br>\n",
    "- Sample3: [4,2,3,4,5] (1 is not picked but 4 is picked twice) <br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are generating one bootstrapped sample in `pandas`:\n",
    "We can use dataframe sample as below to Return a random sample of items [link](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>ChestPain_nonanginal</th>\n",
       "      <th>ChestPain_nontypical</th>\n",
       "      <th>ChestPain_typical</th>\n",
       "      <th>Thal_normal</th>\n",
       "      <th>Thal_reversable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  Slope   Ca  \\\n",
       "59    51    1     125   213    0        2    125      1      1.4      1  1.0   \n",
       "234   54    0     160   201    0        0    163      0      0.0      1  1.0   \n",
       "50    41    0     105   198    0        0    168      0      0.0      1  1.0   \n",
       "117   35    0     138   183    0        0    182      0      1.4      1  0.0   \n",
       "10    57    1     140   192    0        0    148      0      0.4      2  0.0   \n",
       "..   ...  ...     ...   ...  ...      ...    ...    ...      ...    ...  ...   \n",
       "80    45    1     104   208    0        2    148      1      3.0      2  0.0   \n",
       "28    43    1     150   247    0        0    171      0      1.5      1  0.0   \n",
       "91    62    0     160   164    0        2    145      0      6.2      3  3.0   \n",
       "140   59    1     140   221    0        0    164      1      0.0      1  0.0   \n",
       "228   54    1     110   206    0        2    108      1      0.0      2  1.0   \n",
       "\n",
       "     ChestPain_nonanginal  ChestPain_nontypical  ChestPain_typical  \\\n",
       "59                      0                     0                  1   \n",
       "234                     1                     0                  0   \n",
       "50                      0                     1                  0   \n",
       "117                     0                     0                  0   \n",
       "10                      0                     0                  0   \n",
       "..                    ...                   ...                ...   \n",
       "80                      0                     0                  0   \n",
       "28                      0                     0                  0   \n",
       "91                      0                     0                  0   \n",
       "140                     0                     1                  0   \n",
       "228                     0                     0                  0   \n",
       "\n",
       "     Thal_normal  Thal_reversable  \n",
       "59             1                0  \n",
       "234            1                0  \n",
       "50             1                0  \n",
       "117            1                0  \n",
       "10             0                0  \n",
       "..           ...              ...  \n",
       "80             1                0  \n",
       "28             1                0  \n",
       "91             0                1  \n",
       "140            1                0  \n",
       "228            1                0  \n",
       "\n",
       "[222 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate one bootstrapped sample of size n (same length as X_train) from X_train.\n",
    "print(len(X_train))\n",
    "\n",
    "X_train.sample(n = len(X_train), replace = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize 3 bootstrapped samples similar to above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/E057788/opt/anaconda3/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/E057788/opt/anaconda3/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/E057788/opt/anaconda3/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot cholesterol level for each bootstrapped sample. Note the slightly different distributions\n",
    "for i in range(3):\n",
    "    sns.distplot(X_train.sample(n = len(X_train), replace = True)['Chol']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Ensemble Methods\n",
    "We can list out the different types of models we've built thus far:\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- $k$-Nearest Neighbors\n",
    "- Naive Bayes Classification\n",
    "\n",
    "If we want to use any of these models, we follow the same type of process.\n",
    "1. Based on our problem, we identify which model to use. (Is our problem classification or regression? Do we want an interpretable model?)\n",
    "2. Fit the model using the training data.\n",
    "3. Use the fit model to generate predictions.\n",
    "4. Evaluate our model's performance and, if necessary, return to step 2 and make changes.\n",
    "\n",
    "So far, we've always had exactly one model. Today, however, we're going to talk about **ensemble methods**. \n",
    "\n",
    "Mentally, you should think about this as if we build multiple models and then aggregate their results in some way. We can also think of this concept somewhat along the same lines as *cross-validation* technique done during a single model evaluation, just that with ensembling, we're taking it to the next level ***across-models***.\n",
    "\n",
    "## Why would we build an \"ensemble model?\"\n",
    "\n",
    "Our goal is to estimate $f$, the true function. (Think about $f$ as the **true process** that dictates housing prices)\n",
    "\n",
    "The *true function* is a mathematical equation that relates our feature variables with our response. \n",
    "\n",
    "We can come up with different models $m_1$, $m_2$, and so on to get as close to $f$ as possible. (Think about $m_1$ as the model **you** built to predict $f$, think of $m_2$ as a different model your **neighbor** built to predict $f$, and so on.)\n",
    "\n",
    "### (BONUS) Three Benefits: Statistical, Computational, Representational\n",
    "- The **statistical** benefit to ensemble methods: By building one model, our predictions are almost certainly going to be wrong. Predictions from one model might overestimate housing prices; predictions from another model might underestimate housing prices. By \"averaging\" predictions from multiple models, we'll see that we can often cancel our errors out and get closer to the true function $f$.\n",
    "- The **computational** benefit to ensemble methods: It might be impossible to develop one model that globally optimizes our objective function. (Remember that CART reach locally-optimal solutions that aren't guaranteed to be the globally-optimal solution.) In these cases, it may be **impossible** for one CART to arrive at the true function $f$. However, generating many different models and averaging their predictions may allow us to get results that are closer to the global optimum than any individual model.\n",
    "- The **representational** benefit to ensemble methods: Even if we had all the data and all the computer power in the world, it might be impossible for one model to **exactly** equal $f$. For example, a linear regression model can never model a relationship where a one-unit change in $X$ is associated with some *different* change in $Y$ based on the value of $X$. All models have some shortcomings. (See [the no free lunch theorems](https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization).) While individual models have shortcomings, by creating multiple models and aggregating their predictions, we can actually create predictions that represent something that one model cannot ever represent.\n",
    "\n",
    "We can summarize this as the **wisdom of the crowd**.\n",
    "\n",
    "## Wisdom of the Crowd: Ask the audience in \"Who wants to be a Millionaire\"\n",
    "- Each person in the audience gives one prediction. The aggregation here is a simple majority vote. The class that has the most votes is most likely the right answer. In this case \"C\"\n",
    "\n",
    "![](../assets/millionaire.jpeg)\n",
    "\n",
    "[*Image source*](http://travispenery.blogspot.com/2013/05/watching-telly-what-is-wrong-with-who.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble models\n",
    "\n",
    "We can use the \"wisdom of the crowd\" idea by creating several models and then aggregating their results in some way.\n",
    "\n",
    "Types of ensemble models:\n",
    "- Bagging\n",
    "- Boosting\n",
    "- [Stacking](https://www.geeksforgeeks.org/stacking-in-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging: Bootstrap Aggregating\n",
    "\n",
    "Decision trees are powerful machine learning models. However, decision trees have some limitations. In particular, trees that are grown very deep tend to learn highly irregular patterns (a.k.a. they overfit their training sets). \n",
    "\n",
    "Bagging (bootstrap aggregating) mitigates this problem by exposing different trees to different sub-samples of the training set.\n",
    "\n",
    "The process for creating bagged decision trees is as follows:\n",
    "1. From the original data of size $n$, bootstrap $B$ samples each of size $n$ (with replacement!).\n",
    "2. Build a decision tree on each bootstrapped sample.\n",
    "3. Make predictions by passing a test observation through all $B$ trees and developing one aggregate prediction for that observation.\n",
    "\n",
    "![](../assets/Ensemble.png)\n",
    "\n",
    "### What do you mean by \"aggregate prediction?\"\n",
    "As with all of our modeling techniques, we want to make sure that we can come up with **one final prediction** for each observation.\n",
    "\n",
    "Suppose we want to predict whether or not a Reddit post is going to go viral, where `1` indicates viral and `0` indicates non-viral. We build 100 decision trees. Given a new Reddit post labeled `X_test`, we pass the features in `X_test` into all 100 decision trees.\n",
    "- 70 of the trees predict that the post in `X_test` will go viral.\n",
    "- 30 of the trees predict that the post in `X_test` will not go viral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What might you expect .predict(X_test) to output?</summary>\n",
    "\n",
    "- `.predict(X_test)` should output a 1, predicting that the post will go viral.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What might you expect .predict_proba(X_test) to output?</summary>\n",
    "\n",
    "- `.predict_proba(X_test)` should output [0.3 0.7], indicating the probability of the post going viral is 70% and the probability of the post not going viral to be 30%. <br>\n",
    "- This is exactly analogous to our \"Who wants to be a millionaire\" example image above!\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier, *manual way*, using a `for` loop\n",
    "\n",
    "In the cell below, we'll create an ensemble of trees - we'll train each tree on a separate **bootstrapped** sample of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tree 1</th>\n",
       "      <th>Tree 2</th>\n",
       "      <th>Tree 3</th>\n",
       "      <th>Tree 4</th>\n",
       "      <th>Tree 5</th>\n",
       "      <th>Tree 6</th>\n",
       "      <th>Tree 7</th>\n",
       "      <th>Tree 8</th>\n",
       "      <th>Tree 9</th>\n",
       "      <th>Tree 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tree 1  Tree 2  Tree 3  Tree 4  Tree 5  Tree 6  Tree 7  Tree 8  Tree 9  \\\n",
       "113       1       1       1       0       1       1       0       1       1   \n",
       "195       0       1       1       1       0       0       0       1       0   \n",
       "64        1       0       0       1       1       1       1       1       1   \n",
       "27        1       0       1       0       0       0       1       0       0   \n",
       "245       0       0       0       0       0       1       1       0       0   \n",
       "\n",
       "     Tree 10  \n",
       "113        1  \n",
       "195        0  \n",
       "64         1  \n",
       "27         0  \n",
       "245        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dataframe.\n",
    "predictions = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# Generate ten decision trees.\n",
    "for i in range(1, 11):\n",
    "    \n",
    "    # Bootstrap X data.\n",
    "    # Don't add a random seed as we want different sample set everytime!\n",
    "    X_sample = X_train.sample(n = len(X_train), replace=True)\n",
    "    \n",
    "    # Get y data that matches the X data. We need both X and y to create our model per usual process.\n",
    "    y_sample = y_train[X_sample.index] # we'll chk downstream on how this worked\n",
    "    \n",
    "    # Instantiate decision tree classifier.\n",
    "    t = DecisionTreeClassifier()\n",
    "    \n",
    "    # Fit to our sample data.\n",
    "    t.fit(X_sample, y_sample)\n",
    "    \n",
    "    # Put predictions in dataframe.\n",
    "    predictions[f'Tree {i}'] = t.predict(X_test)\n",
    "\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([222,  39, 125, 114, 131,  35,  60,  78,  83, 156,\n",
       "            ...\n",
       "            171,  17, 189,  91,   0,  47,   2,  24, 261, 139],\n",
       "           dtype='int64', length=222)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.index # gets out all indexes corresponding to the X_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222    0\n",
       "39     0\n",
       "125    0\n",
       "114    1\n",
       "131    0\n",
       "      ..\n",
       "47     1\n",
       "2      1\n",
       "24     1\n",
       "261    1\n",
       "139    0\n",
       "Name: AHD_Yes, Length: 222, dtype: uint8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[X_sample.index] # gets out all y_train data corresponding to the X_samples' indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113    0.8\n",
       "195    0.4\n",
       "64     0.8\n",
       "27     0.3\n",
       "245    0.2\n",
       "      ... \n",
       "93     0.3\n",
       "133    0.0\n",
       "33     0.4\n",
       "20     0.5\n",
       "76     1.0\n",
       "Length: 75, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate aggregated predicted probabilities across all DT columns as probs.\n",
    "probs = predictions.mean(axis='columns')\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8533333333333334"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check accuracy metric extrapolating any mean prediction > 0.5 to class 1\n",
    "accuracy_score(y_test, (probs > .5).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier using `sklearn`\n",
    "\n",
    "[BaggingClassifier Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)\n",
    "\n",
    "In the cell below, create and score instance of `BaggingClassifier` on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7733333333333333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate BaggingClassifier.\n",
    "# The number of base estimators in the ensemble is 10 by default, so we don't need to explicitly declare this below.\n",
    "# Now we set a random state so that my 10 random samples are the same as your 10 random samples. \n",
    "# But each sample_1 is still different from sample_2\n",
    "bag = BaggingClassifier(random_state = 42)\n",
    "\n",
    "# Fit BaggingClassifier.\n",
    "bag.fit(X_train, y_train)\n",
    "\n",
    "# Score BaggingClassifier.\n",
    "bag.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interview Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is bootstrapping?</summary>\n",
    "\n",
    "- Bootstrapping is random resampling with replacement.\n",
    "- We bootstrap when fitting bagged decision trees so that we can fit multiple decision trees on slightly different sets of data. Bagged decision trees tend to outperform single decision trees.\n",
    "- Bootstrapping can also be used to conduct hypothesis tests and generate confidence intervals directly from resampled data.\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
