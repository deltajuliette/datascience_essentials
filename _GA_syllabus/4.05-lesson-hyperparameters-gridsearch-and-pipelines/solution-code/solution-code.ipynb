{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Hyperparameters, GridSearch, and Pipelines\n",
    "\n",
    "_Authors: Kiefer Katovich, David Yerrington, Matt Brems, Noelle Brown_\n",
    "\n",
    "---\n",
    "\n",
    "![](https://snag.gy/aYcCt2.jpg)\n",
    "\n",
    "### Learning Objectives\n",
    "- Describe what the terms hyperparameters, GridSearch, and pipeline mean.\n",
    "- Apply `sklearn`'s `GridSearchCV` object.\n",
    "- Use attributes of the GridSearch object.\n",
    "- Describe the pitfalls of searching large hyperparameter spaces.\n",
    "- Build pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traditional mandate of imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>lifeMale</th>\n",
       "      <th>lifeFemale</th>\n",
       "      <th>infantMortality</th>\n",
       "      <th>GDPperCapita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>154</td>\n",
       "      <td>2848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Europe</td>\n",
       "      <td>68.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>32</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Africa</td>\n",
       "      <td>67.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>44</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Africa</td>\n",
       "      <td>44.9</td>\n",
       "      <td>48.1</td>\n",
       "      <td>124</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>America</td>\n",
       "      <td>69.6</td>\n",
       "      <td>76.8</td>\n",
       "      <td>22</td>\n",
       "      <td>8055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country   region  lifeMale  lifeFemale  infantMortality  GDPperCapita\n",
       "0  Afghanistan     Asia      45.0        46.0              154          2848\n",
       "1      Albania   Europe      68.0        74.0               32           863\n",
       "2      Algeria   Africa      67.5        70.3               44          1531\n",
       "3       Angola   Africa      44.9        48.1              124           355\n",
       "4    Argentina  America      69.6        76.8               22          8055"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data.\n",
    "data = pd.read_csv('../data/UNdata.csv')\n",
    "print(data.shape)\n",
    "# Examine first five rows.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## United Nations Data\n",
    "Understanding the dataset:\n",
    "- `country`: the name of the nation\n",
    "- `region`: the region of the world (Africa, America, Asia, Europe, Oceania)\n",
    "- `lifeMale`: the life expectancy of males\n",
    "- `lifeFemale`: the life expectancy of females\n",
    "- `infantMortality`: the infant mortality rate (generally reported per 1,000 live births)\n",
    "- `GDPperCapita`: the Gross Domestic Product per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188 entries, 0 to 187\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   country          188 non-null    object \n",
      " 1   region           188 non-null    object \n",
      " 2   lifeMale         188 non-null    float64\n",
      " 3   lifeFemale       188 non-null    float64\n",
      " 4   infantMortality  188 non-null    int64  \n",
      " 5   GDPperCapita     188 non-null    int64  \n",
      "dtypes: float64(2), int64(2), object(2)\n",
      "memory usage: 8.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values & data types.--> verified to be all good!\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>lifeMale</th>\n",
       "      <th>lifeFemale</th>\n",
       "      <th>infantMortality</th>\n",
       "      <th>GDPperCapita</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>Asia</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>154</td>\n",
       "      <td>2848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>Europe</td>\n",
       "      <td>68.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>32</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>Africa</td>\n",
       "      <td>67.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>44</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>Africa</td>\n",
       "      <td>44.9</td>\n",
       "      <td>48.1</td>\n",
       "      <td>124</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>America</td>\n",
       "      <td>69.6</td>\n",
       "      <td>76.8</td>\n",
       "      <td>22</td>\n",
       "      <td>8055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              region  lifeMale  lifeFemale  infantMortality  GDPperCapita\n",
       "country                                                                  \n",
       "Afghanistan     Asia      45.0        46.0              154          2848\n",
       "Albania       Europe      68.0        74.0               32           863\n",
       "Algeria       Africa      67.5        70.3               44          1531\n",
       "Angola        Africa      44.9        48.1              124           355\n",
       "Argentina    America      69.6        76.8               22          8055"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set country to be the index. (we'll see why we are doing this later, further down)\n",
    "data.set_index('country', inplace = True)\n",
    "data.head() # we see the output replaces the numerical indices with country col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lifeMale</th>\n",
       "      <th>lifeFemale</th>\n",
       "      <th>infantMortality</th>\n",
       "      <th>GDPperCapita</th>\n",
       "      <th>region_America</th>\n",
       "      <th>region_Asia</th>\n",
       "      <th>region_Europe</th>\n",
       "      <th>region_Oceania</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>154</td>\n",
       "      <td>2848</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>68.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>32</td>\n",
       "      <td>863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>67.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>44</td>\n",
       "      <td>1531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>44.9</td>\n",
       "      <td>48.1</td>\n",
       "      <td>124</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>69.6</td>\n",
       "      <td>76.8</td>\n",
       "      <td>22</td>\n",
       "      <td>8055</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lifeMale  lifeFemale  infantMortality  GDPperCapita  \\\n",
       "country                                                            \n",
       "Afghanistan      45.0        46.0              154          2848   \n",
       "Albania          68.0        74.0               32           863   \n",
       "Algeria          67.5        70.3               44          1531   \n",
       "Angola           44.9        48.1              124           355   \n",
       "Argentina        69.6        76.8               22          8055   \n",
       "\n",
       "             region_America  region_Asia  region_Europe  region_Oceania  \n",
       "country                                                                  \n",
       "Afghanistan               0            1              0               0  \n",
       "Albania                   0            0              1               0  \n",
       "Algeria                   0            0              0               0  \n",
       "Angola                    0            0              0               0  \n",
       "Argentina                 1            0              0               0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy the other categorical variable: region.\n",
    "data = pd.get_dummies(data, columns=['region'], drop_first=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is our reference category for this dummy variable?</summary>\n",
    "\n",
    "- Africa!\n",
    "- There is no dummy variable for Africa in our data, meaning that all dummy variables would be interpreted **relative to Africa**.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create $Y$ variable\n",
    "- Let's formulate our problem as trying to predict where females have higher life expectancy than males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lifeMale</th>\n",
       "      <th>lifeFemale</th>\n",
       "      <th>infantMortality</th>\n",
       "      <th>GDPperCapita</th>\n",
       "      <th>region_America</th>\n",
       "      <th>region_Asia</th>\n",
       "      <th>region_Europe</th>\n",
       "      <th>region_Oceania</th>\n",
       "      <th>females_are_strong_as_hell</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>154</td>\n",
       "      <td>2848</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>68.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>32</td>\n",
       "      <td>863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lifeMale  lifeFemale  infantMortality  GDPperCapita  \\\n",
       "country                                                            \n",
       "Afghanistan      45.0        46.0              154          2848   \n",
       "Albania          68.0        74.0               32           863   \n",
       "\n",
       "             region_America  region_Asia  region_Europe  region_Oceania  \\\n",
       "country                                                                   \n",
       "Afghanistan               0            1              0               0   \n",
       "Albania                   0            0              1               0   \n",
       "\n",
       "             females_are_strong_as_hell  \n",
       "country                                  \n",
       "Afghanistan                           1  \n",
       "Albania                               1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column with 1 if the female life expectancy is greater\n",
    "# than the male life expectancy otherwise 0\n",
    "data['females_are_strong_as_hell'] = (data['lifeFemale'] > data['lifeMale']).astype(int)\n",
    "data.head(2)\n",
    "# The column name is a reference to the \n",
    "# Netflix series \"The Unbreakable Kimmy Schmidt.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Afghanistan    True\n",
       "Albania        True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by doing the .astype(int), we are making use of the True=integer 1 property in Python\n",
    "(data['lifeFemale'] > data['lifeMale']).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.989362\n",
       "0    0.010638\n",
       "Name: females_are_strong_as_hell, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What should we check next?\n",
    "data['females_are_strong_as_hell'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Do you have any concerns about the above?</summary>\n",
    "    \n",
    "- Our classes are severely <b>unbalanced</b>.<br>\n",
    "- We should check out our tools for handling unbalanced classes. (e.g. moving our classification threshold, implement stratified $k$-fold cross-validation)<br>\n",
    "- Given the relatively low sample size and the small number of the observations in the minority category here, it is unlikely that our model would be able to predict that a nation has a higher male life expectancy.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.569149\n",
       "1    0.430851\n",
       "Name: females_are_strong_as_hell, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column with 1 if the female life expectancy is 5,\n",
    "# or more years longer than the male life expectancy.\n",
    "data['females_are_strong_as_hell'] = (data['lifeFemale'] >= (data['lifeMale'] + 5)).astype(int)\n",
    "\n",
    "# Check the class balance now.\n",
    "data['females_are_strong_as_hell'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modified Task: We are interested in predicting whether or not the female life expectancy of a nation is _at least five years_ greater than the male life expectancy.** This is a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up X and y.\n",
    "X = data.drop(['females_are_strong_as_hell', 'lifeMale', 'lifeFemale'], axis = 'columns') # axis = 1 or 'columns', drops cols\n",
    "y = data['females_are_strong_as_hell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into training and testing sets.\n",
    "# set a custom test size of 33% for model evaluation. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.568\n",
      "1    0.432\n",
      "Name: females_are_strong_as_hell, dtype: float64\n",
      "0    0.571429\n",
      "1    0.428571\n",
      "Name: females_are_strong_as_hell, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# What did stratify = y do? --> replicates similar distribution of the classes pre-train/test split\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Before we build a k-Nearest Neighbors model, what do we need to do? Why?</summary>\n",
    "    \n",
    "- <b>Standardize</b> our data! <br>\n",
    "- If we *don't* standardize our data, then features that have larger spreads (e.g. higher ranges or higher standard deviations) will have a disproportionate influence on our model.<br>\n",
    "- If all of your variables are already on the same scale, then scaling is not necessary.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate.\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Fit and transform train.\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "\n",
    "# Transform test.\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Default kNN\n",
    "\n",
    "Below we fit a default `KNeighborsClassifier` to predict `y`. ([Here is the documentation.](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is the default number of neighbors used in kNN?</summary>\n",
    "    \n",
    "    - 5. (stated in the sklearn documentation)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate.\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Fit on train.\n",
    "knn.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate (predict and return 'accuracy' score).\n",
    "knn.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What score is this?</summary>\n",
    "\n",
    "- The default score: Accuracy. Calculated as the number of correct predictions / total predictions\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.571429\n",
       "1    0.428571\n",
       "Name: females_are_strong_as_hell, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate against the baseline.\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As a general note of caution:** typically, when dealing with datasets with imbanced response classes, `Accuracy` may not be the best metric to make model conclusions. Because we might have a highly accurate model with more `True Negatives`, but less `True Positives`. We are aiming usually to have higher `True Positives` or `class 1` accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>On the other hand, let's think if selecting the default number of neighbors: $k$ = 5 a good choice? Is it the best choice?</summary>\n",
    "\n",
    "- We don't know!\n",
    "- $k$ is a hyperparameter.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are \"hyperparameters?\"\n",
    "\n",
    "Models often have **built-in quantities** that we can use to ***fine-tune our results***. Like: \n",
    "- What value of $k$ do we select?\n",
    "- What distance metric do we select?\n",
    "- Do we use LASSO or Ridge regularization?\n",
    "- What value of $\\alpha$ or $C$ do we use?\n",
    "\n",
    "These are quantities our model **cannot learn**...but they **influence** the way our model learns and we as Data Scientists can **decide on these ourselves** to better our model! _(Though, it is worth noting that with the advancements in machine learning, there are now several **Automated Machine Learning** libraries, like [Pycaret](https://pycaret.org/classification1/) that take care of everything including hyperparameter tuning.)_\n",
    "\n",
    "> These are different from statistical parameters, which are quantities a model _can_ learn.\n",
    "\n",
    "However, different values for hyperparameters can result in substantially different models. \n",
    "- Here's a reference resource to [visualize fits for different values of $k$: Fig 5](http://scott.fortmann-roe.com/docs/BiasVariance.html) in $k$-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>We want to find the optimal values for our hyperparameters. How do you think we might do this?</summary>\n",
    "\n",
    "- Try many different values of hyperparameters and see which one performs the best on our data.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for the Best Hyperparameters\n",
    "\n",
    "Our default kNN performs quite poorly on the test data. But what if we changed the number of neighbors? The weighting? The distance metric?\n",
    "\n",
    "These are all hyperparameters of kNN. How would we do this manually? We would need to evaluate on the training data the set of hyperparameters that perform best, and then use that set of hyperparameters to fit the final model and score on the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One method of searching for the optimal set of hyperparameters is called _GridSearching_.**\n",
    "\n",
    "GridSearching gets its name from the fact that we are searching over a **\"grid\" of hyperparameters**. For example, imagine the `n_neighbors` hyperparameter as the columns and `weights` hyperparameter as the rows. This makes a grid. We check the accuracy for all combinations of hyperparameters on the grid.\n",
    "\n",
    "[Where:](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) \n",
    "\n",
    "`n_neighbors`--> no. of nearest neighboring data points to consider based on Euclidean distance\n",
    "\n",
    "`weights`--> weightage to assign for nearest neighboring data points\n",
    "- uniform (default): assign equal weightage to all points\n",
    "- distance: higher weightage for closer points\n",
    "\n",
    "![](../images/grid.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `GridSearchCV`\n",
    "\n",
    "This would be an annoying process to have to do manually. Luckily `sklearn` comes in handy:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "```\n",
    "\n",
    "The `GridSearchCV` has a handful of important arguments:\n",
    "\n",
    "| Argument | Description |\n",
    "| --- | ---|\n",
    "| **`estimator`** | The sklearn instance of the model to fit on |\n",
    "| **`param_grid`** | A dictionary where keys are hyperparameters for the model and values are lists of values to test |\n",
    "| **`cv`** | The number of internal cross-validation folds to run for each set of hyperparameters |\n",
    "| **`n_jobs`** | How many cores to use on your computer to run the folds (-1 means use all cores) |\n",
    "| **`verbose`** | How much output to display (0 is none, 1 is limited, 2 is printouts for every internal fit) |\n",
    "\n",
    "\n",
    "Below is an example for how one might set up the GridSearch for our kNN:\n",
    "\n",
    "```python\n",
    "# declaring the param_grid:\n",
    "knn_parameters = {\n",
    "    'n_neighbors':[2,3], # test for 2 & 3 neighbouring data points\n",
    "    'weights':['uniform','distance'], # test for uniform & distance weights\n",
    "    'p':[1,2] # test distance metric: manhattan & euclidean\n",
    "}\n",
    "# instantiate and fit:\n",
    "knn_gridsearcher = GridSearchCV(KNeighborsClassifier(), knn_parameters, verbose=1)\n",
    "knn_gridsearcher.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "- The above code will run KNN with all the below combinations to find the best combination.\n",
    "- As you can see it it comprehensive, running all possible combinations of the parameters we chose.\n",
    "\n",
    "| n_neighbors | weights | p |\n",
    "| :---: | :---: | :---: |\n",
    "| 2 | 'uniform' | 1 |\n",
    "| 2 | 'uniform' | 2 |\n",
    "| 2 | 'distance' | 1 |\n",
    "| 2 | 'distance' | 2 |\n",
    "| 3 | 'uniform' | 1 |\n",
    "| 3 | 'uniform' | 2 |\n",
    "| 3 | 'distance' | 1 |\n",
    "| 3 | 'distance' | 2 |\n",
    "\n",
    "**Try out the `sklearn` GridSearch below on the training data.** \n",
    "\n",
    "[GridSearchCV documentation for additional reference](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of hyperparameters (param_grid).\n",
    "# The keys MUST match the names of the estimator's arguments!\n",
    "knn_params = {\n",
    "    'n_neighbors': range(1, 51, 10),\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 11, 21, 31, 41]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search using these number of neighbors:\n",
    "list(range(1, 51, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our GridSearchCV object.\n",
    "knn_gridsearch = GridSearchCV(KNeighborsClassifier(), # What is the model we want to fit?\n",
    "                              knn_params, # What is the dictionary of hyperparameters?\n",
    "                              cv=5, # What number of folds in CV will we use?\n",
    "                              verbose=1,\n",
    "                              n_jobs=-1 # Use all CPU cores on your computer to speed up the fit\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "# Fit the GridSearchCV object to the data\n",
    "# After the fit is completed, running score or predict will automatically choose the best model\n",
    "knn_gridsearch.fit(X_train_sc, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Results of the GridSearch\n",
    "\n",
    "Once the GridSearch has fit (this can take awhile!) we can pull out a variety of information and useful objects from the GridSearch object, stored as attributes:\n",
    "\n",
    "| Property | Description |\n",
    "| --- | ---|\n",
    "| **`results.param_grid`** | Displays hyperparameters searched over. |\n",
    "| **`results.best_score_`** | Best mean cross-validated score achieved. |\n",
    "| **`results.best_estimator_`** | Reference to model with best score.  Is usable / callable. |\n",
    "| **`results.best_params_`** | The hyperparameters that have been found to perform with the best score. |\n",
    "| **`results.grid_scores_`** | Display score attributes with corresponding hyperparameters. | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.784"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the score\n",
    "# from documentation: Mean cross-validated score of the best_estimator\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "knn_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the set of hyperparameters that achieved the best score.\n",
    "knn_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the best fit model on the test data.\n",
    "# Best model is automatically chosen\n",
    "knn_gridsearch.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we don't see any difference when we finally check the 'Accuracy' score on the test dataset vs what we had previously using the default n_neighbors (5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see everything!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00188875, 0.0020524 , 0.00126815, 0.00119066, 0.00109744,\n",
       "        0.00111513, 0.00107279, 0.00106249, 0.00104928, 0.00088849]),\n",
       " 'std_fit_time': array([5.18221459e-04, 5.46642624e-04, 1.81948026e-04, 6.42151132e-05,\n",
       "        4.32018149e-05, 9.57829721e-05, 3.49025908e-05, 1.10427868e-04,\n",
       "        1.52939005e-04, 1.07625706e-04]),\n",
       " 'mean_score_time': array([0.0026648 , 0.00343938, 0.00368505, 0.00236712, 0.00336862,\n",
       "        0.00206699, 0.00214744, 0.00205722, 0.00215783, 0.0017406 ]),\n",
       " 'std_score_time': array([2.28214633e-04, 8.67339310e-04, 2.49722724e-03, 1.95783530e-04,\n",
       "        2.28937228e-03, 8.63148491e-05, 1.72248142e-04, 2.89196984e-04,\n",
       "        2.60723404e-04, 3.28052342e-04]),\n",
       " 'param_metric': masked_array(data=['euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_neighbors': masked_array(data=[1, 11, 21, 31, 41, 1, 11, 21, 31, 41],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'metric': 'euclidean', 'n_neighbors': 1},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 11},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 21},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 31},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 41},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 1},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 11},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 21},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 31},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 41}],\n",
       " 'split0_test_score': array([0.76, 0.84, 0.84, 0.76, 0.68, 0.76, 0.84, 0.84, 0.8 , 0.72]),\n",
       " 'split1_test_score': array([0.84, 0.76, 0.84, 0.76, 0.76, 0.84, 0.84, 0.84, 0.76, 0.76]),\n",
       " 'split2_test_score': array([0.92, 0.68, 0.76, 0.56, 0.6 , 0.92, 0.68, 0.76, 0.64, 0.64]),\n",
       " 'split3_test_score': array([0.72, 0.68, 0.72, 0.72, 0.6 , 0.72, 0.64, 0.72, 0.72, 0.68]),\n",
       " 'split4_test_score': array([0.68, 0.68, 0.72, 0.68, 0.64, 0.64, 0.68, 0.72, 0.68, 0.64]),\n",
       " 'mean_test_score': array([0.784, 0.728, 0.776, 0.696, 0.656, 0.776, 0.736, 0.776, 0.72 ,\n",
       "        0.688]),\n",
       " 'std_test_score': array([0.08616264, 0.064     , 0.05425864, 0.07418895, 0.05986652,\n",
       "        0.09666437, 0.08616264, 0.05425864, 0.05656854, 0.04664762]),\n",
       " 'rank_test_score': array([ 1,  6,  2,  8, 10,  2,  5,  2,  7,  9], dtype=int32)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gridsearch.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_metric</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>1</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 1}</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.086163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>21</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 21}</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.054259</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>1</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 1}</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.096664</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>21</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 21}</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.054259</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>11</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 11}</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.086163</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_metric  \\\n",
       "0       0.001889      0.000518         0.002665        0.000228    euclidean   \n",
       "2       0.001268      0.000182         0.003685        0.002497    euclidean   \n",
       "5       0.001115      0.000096         0.002067        0.000086    manhattan   \n",
       "7       0.001062      0.000110         0.002057        0.000289    manhattan   \n",
       "6       0.001073      0.000035         0.002147        0.000172    manhattan   \n",
       "\n",
       "  param_n_neighbors                                      params  \\\n",
       "0                 1   {'metric': 'euclidean', 'n_neighbors': 1}   \n",
       "2                21  {'metric': 'euclidean', 'n_neighbors': 21}   \n",
       "5                 1   {'metric': 'manhattan', 'n_neighbors': 1}   \n",
       "7                21  {'metric': 'manhattan', 'n_neighbors': 21}   \n",
       "6                11  {'metric': 'manhattan', 'n_neighbors': 11}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0               0.76               0.84               0.92               0.72   \n",
       "2               0.84               0.84               0.76               0.72   \n",
       "5               0.76               0.84               0.92               0.72   \n",
       "7               0.84               0.84               0.76               0.72   \n",
       "6               0.84               0.84               0.68               0.64   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.68            0.784        0.086163                1  \n",
       "2               0.72            0.776        0.054259                2  \n",
       "5               0.64            0.776        0.096664                2  \n",
       "7               0.72            0.776        0.054259                2  \n",
       "6               0.68            0.736        0.086163                5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting above to dataframe format and sorting best model first, viewing top 5\n",
    "pd.DataFrame(knn_gridsearch.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualising effect from increasing number of neighbors vs model accuracy\n",
    "gs_df = pd.DataFrame(knn_gridsearch.cv_results_)\n",
    "gs_df = gs_df[gs_df['param_metric'] == 'euclidean']\n",
    "gs_df.plot(x='param_n_neighbors', y='mean_test_score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model score drops as the number of neighbors increase - so it is not a good idea to have significantly large n_neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Word of Caution on GridSearching\n",
    "\n",
    "`sklearn` models often have many hyperparameters with many different possible values. It may be tempting to search over a wide variety of them. In general, this is not wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Why not?</summary>\n",
    "\n",
    "- Remember that GridSearch searches over **all possible combinations of hyperparameters in the parameter dictionary!**\n",
    "    - In the previous GridSearch we just completed, the search happened using a combination of each number of neighbor from the range: [1, 11, 21, 31, 41] + changing distance metric between euclidean and manhattan, that is for neighbor:distance - 1,11,21,31,41:euclidean and 1,11,21,31,41:manhattan\n",
    "        - total search count: number of items in the neighbors * number of items in weights = 5 * 2 = 10.\n",
    "\n",
    "Imagine a more complex parameter dictionary as described here:\n",
    "\n",
    "```python\n",
    "parameter_grid = {\n",
    "    'n_neighbors': range(1, 151),\n",
    "    'weights': ['uniform', 'distance', custom_function],\n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'brute', 'auto'],\n",
    "    'leaf_size': range(1, 152),\n",
    "    'metric': ['minkowski', 'euclidean'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "```\n",
    "\n",
    "**How many different combinations will need to be tested?**\n",
    "\n",
    "| Parameter | Number of Chosen Values |\n",
    "| --- | --- |\n",
    "| **n_neighbors** | 150 |\n",
    "| **weights** | 3 |\n",
    "| **algorithm** | 4 |\n",
    "| **leaf_size** | 151 |\n",
    "| **metric** | 2 |\n",
    "| **p** | 2 |\n",
    "| <br>_150 \\* 3 \\* 4 \\* 151 \\* 2 \\* 2 = n combinations_ <br><br>| _1,087,200_ |\n",
    "\n",
    "If we select `cv = 5`, we would fit 1,087,200 models on five folds, meaning we fit 5,436,000 models!\n",
    "\n",
    "If you're not careful, GridSearching can quickly scale out of hand computationally.\n",
    "\n",
    "> **It is extremely important to understand what the hyperparameters do and think critically about what <i>ranges</i> are useful and relevant to your model!**\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief detour: estimators and transformers.\n",
    "**Estimators** and **transformers** are two types of ***classes*** in `sklearn`.\n",
    "\n",
    "We've seen several examples of each so far.\n",
    "\n",
    "### Scikit-Learn _Estimators_\n",
    "**Estimators** are essentially _models_. They fit this format:\n",
    "\n",
    "```python\n",
    "# Instantiate.\n",
    "model = LinearRegression(params)\n",
    "# Fit.\n",
    "model.fit(X_train, y_train)\n",
    "# Predict.\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "Estimators have a **fit** and **predict** method.\n",
    "\n",
    "### Scikit-Learn _Transformers_\n",
    "**Transformers** are _not models_. They _transform your data_ using similar syntax to estimators. They work like this:\n",
    "\n",
    "```python\n",
    "# Instantiate.\n",
    "ss = StandardScaler(params)\n",
    "# Fit.\n",
    "ss.fit(X_train)\n",
    "# Transform.\n",
    "X_transformed = ss.transform(X_train)\n",
    "```\n",
    "\n",
    "Instead of `fit` and `predict`, they have **fit** and **transform** methods. In fact, since you fit and transform together so often, they have a shortcut:\n",
    "\n",
    "```python\n",
    "ss = StandardScaler(params)\n",
    "X_transformed = ss.fit_transform(X_train)\n",
    "```\n",
    "\n",
    "We've seen a few transformers, including `StandardScaler()` and `PolynomialFeatures()`. There's also `OneHotEncoder()` for dummy encoding and `LabelEncoder()` for factorizing variables. Later we'll see `PCA()`, which is also a transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this relevant?\n",
    "\n",
    "Previously, we applied GridSearch over the kNN Estimator. \n",
    "\n",
    "Check out the [StandardScaler documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Transformers may have hyperparameters as well - **but we can't GridSearch over a transformer**! There's no way to get an accuracy (or other) score from just a transformer, since a ***transformer can't predict***!\n",
    "\n",
    "![](../images/grid.jpg)\n",
    "\n",
    "In addition, the acronym ETL, meaning \"extract, transform, load,\" is a very common one in data science. When we gather data from one or more places, there might be **a lot** of preprocessing going on.\n",
    "\n",
    "Oftentimes, we'll want to apply several transformations to a dataset to standardize all data, *then* build a model. \n",
    "- If you do all of these preprocessing steps independently, your code can be messy and it'll be prone to errors!\n",
    "- It can be challenging to consistently recreate this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "![](../images/pipe.png)\n",
    "\n",
    "Pipelines will allow us to do two things:\n",
    "1. Chain **many transformers together** with a final estimator.\n",
    "2. Allow us to **GridSearch over a transformer's** hyperparameters.\n",
    "\n",
    "- I personally love sklearn's Pipeline and use them a lot in my code.\n",
    "- It helps keep your code neat and organized and allows hyperparameter searches over transformations as well!\n",
    "\n",
    "[sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a StandardScaler + kNN pipeline.\n",
    "pipe = Pipeline([\n",
    "    ('ss', StandardScaler()), # step1: transformation, we're assigning a string 'ss' to associate with scaling\n",
    "    ('knn', KNeighborsClassifier()) # step2: estimation, we're assigning a string 'knn' to associate with knn model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ss', StandardScaler()), ('knn', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit estimator after applying transformations.\n",
    "pipe.fit(X_train, y_train) # notice how we no longer need to fit with X_train_sc since the transformation happ in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate. --> the result is the same as we saw way above with default kNN initiation\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler()), ('knn', KNeighborsClassifier())],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(),\n",
       " 'knn': KNeighborsClassifier(),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'knn__algorithm': 'auto',\n",
       " 'knn__leaf_size': 30,\n",
       " 'knn__metric': 'minkowski',\n",
       " 'knn__metric_params': None,\n",
       " 'knn__n_jobs': None,\n",
       " 'knn__n_neighbors': 5,\n",
       " 'knn__p': 2,\n",
       " 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get params - Get parameters for this estimator. yes, you can GridSearchCV over these!\n",
    "# Notice the naming convention of pipe arguments. similar to GridSearchCV we did above\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a 2nd pipeline object.\n",
    "pipe_2 = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn standard scalar documentation for recap](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary of hyperparameters.\n",
    "pipe_2_params = {'ss__with_mean': [True, False], # iterating over 'how' scaling is done\n",
    "                 'ss__with_std': [True, False], # iterating over 'how' scaling is done\n",
    "                 'knn__p': [1, 2], # iterating over knn distance metric types\n",
    "                 'knn__weights': ['uniform', 'distance'], # iterating over weightage based on distance\n",
    "                 'knn__n_neighbors': [3, 5, 10]} # iterating over number of neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recap GridSearchCV instantiation we did previously:\n",
    "```python\n",
    "# instantiate:\n",
    "knn_gridsearch = GridSearchCV(KNeighborsClassifier(), # What is the model we want to fit?\n",
    "                              knn_params, # What is the dictionary of hyperparameters?\n",
    "                              cv=5, # What number of folds in CV will we use?\n",
    "                              verbose=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our GridSearchCV object.\n",
    "pipe_2_gridsearch = GridSearchCV(pipe_2, # What is the model we want to fit?\n",
    "                                 pipe_2_params, # What is the dictionary of hyperparameters?\n",
    "                                 cv=5, # What number of folds in CV will we use?\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    }
   ],
   "source": [
    "# Fit the GridSearchCV object to the data.\n",
    "pipe_2_gridsearch.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.768"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out best score.\n",
    "# from documentation: Mean cross-validated score of the best_estimator\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "pipe_2_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ss', StandardScaler()),\n",
       "                ('knn',\n",
       "                 KNeighborsClassifier(n_neighbors=3, p=1, weights='distance'))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out best estimator.\n",
    "pipe_2_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.746031746031746"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the best model on the test data.\n",
    "pipe_2_gridsearch.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What would you conclude from this output?</summary>\n",
    "    \n",
    "- Our model performs slightly better when cross-validated on our training data than on our testing data, but the difference is pretty small.<br>\n",
    "- There may be slight overfitting.<br>\n",
    "- GridSearching gets us the best performing model on the training set; we always have to take care to not overfit!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interview Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is the difference between hyperparameters and statistical parameters?</summary>\n",
    "    \n",
    "- Statistical parameters are quantities that a model can learn or estimate. Examples include $\\beta_0$ and $\\beta_1$ in a linear model. <br>\n",
    "- Hyperparameters are quantities our model cannot learn, but affect the fit of our model. Examples include $k$ in $k$-nearest neighbors and $alpha$ in regularization.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (BONUS) RandomizedSearchCV + Visualizing Results\n",
    "\n",
    "When you're exploring a particularly high number of different hyperparameters, it can be advantageous to do a randomized search instead of a GridSearch.\n",
    "\n",
    "`from sklearn.model_selection import RandomizedSearchCV`\n",
    "\n",
    "A good blog post on GridSearch, RandomizedSearch, and visualizing the outputs of these methods [can be found here](https://towardsdatascience.com/using-3d-visualizations-to-tune-hyperparameters-of-ml-models-with-python-ba2885eab2e9).\n",
    "\n",
    "Another good example on RandomizedSearch [here](https://github.com/justmarkham/scikit-learn-tips/blob/master/notebooks/17_randomized_search.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (BONUS) make_pipeline\n",
    "\n",
    "`make_pipeline` does the same thing as `pipeline`, but does not require you to name your steps!\n",
    "\n",
    "`from sklearn.pipeline import make_pipeline`\n",
    "\n",
    "See an explanation of the difference between the two [here](https://github.com/justmarkham/scikit-learn-tips/blob/master/notebooks/12_pipeline_vs_make_pipeline.ipynb) and see an example of it used [here](https://github.com/justmarkham/scikit-learn-tips/blob/master/notebooks/08_pipeline.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (BONUS) Named Steps\n",
    "\n",
    "GridSearch not giving you all of the information you need? Want to see what is happening in the intermediate steps in a pipeline? Use the `named_steps` attribute! An example of how to use this can be found [here](https://github.com/justmarkham/scikit-learn-tips/blob/master/notebooks/13_examine_pipeline_steps.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
