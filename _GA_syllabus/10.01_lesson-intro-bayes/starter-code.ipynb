{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Into to Bayes\n",
    "\n",
    "_Authors: Noelle Brown, Matt Brems_\n",
    "\n",
    "---\n",
    "\n",
    "# Part 1: Bayes Theorem\n",
    "\n",
    "## Problem 1: The Monty Hall Problem\n",
    "\n",
    "The \"Monty Hall Problem” is a famous statistical problem based on the game show \"Let's Make a Deal.\" (Monty Hall was the show’s original host.) \n",
    "\n",
    "If you haven't heard of this game show, no worries. We’ll break down the basics below.\n",
    "\n",
    "\"Let's Make a Deal\" features three doors labeled \"A,\" \"B,\" and \"C.\" As the contestant, you are told that, behind exactly one door, there’s a new car. Behind the other two doors are goats. Your goal is to select the door with the car behind it.\n",
    "\n",
    "<img src=\"./images/goat.jpeg\" style=\"height: 250px\">\n",
    "\n",
    "\n",
    "The game goes as follows:\n",
    "\n",
    "1. You select a door.\n",
    "2. The game show host, knowing which door hides the car, opens one of the doors you didn’t select to reveal a goat. (Important: If you selected a door with a goat, the host picks the other door with a goat. If you started by selecting the door with the car, the host picks from the remaining two doors at random.)\n",
    "3. The host then asks you if you would like to stick with the door you originally picked or switch to the other remaining door."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 1: Stick with our original door\n",
    "\n",
    "We choose Door A, we are shown that there is a goat behind door C.\n",
    "\n",
    "Reminder: Bayes' theorem\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Applied to our problem:\n",
    "\n",
    "$$\n",
    "P(\\text{Car behind A}|\\text{Shown C}) = \\frac{P(\\text{Shown C}|\\text{Car behind A})P(\\text{Car behind A})}{P(\\text{Shown C})}\n",
    "$$\n",
    "\n",
    "First, let's knock out our priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_car_A = \n",
    "p_car_B = \n",
    "p_car_C = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's use the law of total probability to find $P(\\text{Shown C})$.\n",
    "\n",
    "Reminder: Law of Total Probability:\n",
    "\n",
    "$$\n",
    "P(B) = \\sum_{i=1}^{n}P(B|A_{i})P(A_{i})\n",
    "$$\n",
    "\n",
    "Applied to our problem:\n",
    "\n",
    "$$\n",
    "P(\\text{Shown C}) = P(\\text{Shown C} | \\text{Car behind A})*P(\\text{Car behind A}) + P(\\text{Shown C} | \\text{Car behind B})*P(\\text{Car behind B}) + P(\\text{Shown C} | \\text{Car behind C})*P(\\text{Car behind C})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_c_given_a = \n",
    "p_c_given_b = \n",
    "p_c_given_c = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_shown_c ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plugging all of this into Bayes' theorem tells us that the probability that there is a car behind the one we chose (again, we are sticking with our original choice of A here) given that there is a goat behind door C is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 2: Switch doors\n",
    "\n",
    "We choose Door A, we are shown that there is a goat behind door C. Now we switch to door B.\n",
    "\n",
    "Bayes' Theorem applied to our new strategy:\n",
    "\n",
    "$$\n",
    "P(\\text{Car behind B}|\\text{Shown C}) = \\frac{P(\\text{Shown C}|\\text{Car behind B})P(\\text{Car behind B})}{P(\\text{Shown C})}\n",
    "$$\n",
    "\n",
    "We can use what we calculated above.\n",
    "\n",
    "Plugging all of this into Bayes' theorem tells us that the probability that there is a car behind the door we switched to (door B) given that there is a goat behind door C is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What should we do?</summary>\n",
    "\n",
    "Switch! Switching gives us a $\\frac{2}{3}$ chance of winning the car, while sticking with our original choice only leaves us with a $\\frac{1}{3}$ chance of winning!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is still not intuitive, we can think about it in another way.\n",
    "\n",
    "When we pick our original door, we have a $\\frac{1}{3}$ chance of the car being behind the door that you picked and a $\\frac{2}{3}$ chance of the car being behind the doors that you didn't pick.\n",
    "\n",
    "![](./images/first-pick.png)\n",
    "\n",
    "Once we are shown that there is a goat behind door C, swapping doubles our chances of winning! There is *still* a $\\frac{2}{3}$ chance of the car being behind the doors that you didn't pick.\n",
    "\n",
    "![](./images/switch.png)\n",
    "\n",
    "*Images from* [*Mathigon*](https://mathigon.org/course/probability/monty-hall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Cookies!\n",
    "\n",
    "We have two jars of cookies. In the first jar, we have 30 sugar cookies and 10 chocolate chip cookies. In the second jar, we have 20 sugar cookies and 20 chocolate chip cookies.\n",
    "\n",
    "![](./images/cookies.png)\n",
    "\n",
    "Without knowing which is which, we randomly select a jar and pull out a **sugar** cookie. What is the probability that the cookie came from jar 1?\n",
    "\n",
    "[*Source*](http://www.greenteapress.com/thinkbayes/html/thinkbayes002.html)\n",
    "\n",
    "Bayes' theorem applied to this problem:\n",
    "\n",
    "$$\n",
    "P(\\text{Jar 1}|\\text{Sugar Cookie}) = \\frac{P(\\text{Sugar Cookie}|\\text{Jar 1})P(\\text{Jar 1})}{P(\\text{Sugar Cookie})}\n",
    "$$\n",
    "\n",
    "First, let's knock out our priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_jar1 = \n",
    "p_jar2 ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's use the law of total probability to find $P(\\text{Sugar Cookie})$.\n",
    "\n",
    "$$\n",
    "P(\\text{Sugar Cookie}) = P(\\text{Sugar Cookie} | \\text{Jar 1})*P(\\text{Jar 1}) + P(\\text{Sugar Cookie} | \\text{Jar 2})*P(\\text{Jar 2})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sugar_given_jar1 = \n",
    "p_sugar_given_jar2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sugar = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Naïve Bayes\n",
    "\n",
    "Remember when we used Naïve Bayes as a model during our NLP lessons?\n",
    "\n",
    "Now we can see exactly how that works using Bayes' theorem!\n",
    "\n",
    "Let's say we want to classify whether a message is spam or ham (not spam).\n",
    "\n",
    "Assume this is our data of the words we see in our messages and their counts in 10 normal messages:\n",
    "\n",
    "| hello | work | coffee | lunch | money |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 8 | 5 | 3 | 3 | 1 |\n",
    "\n",
    "And this is our data of the words we see in our messages and their counts in 10 spam messages:\n",
    "\n",
    "| hello | work | coffee | lunch | money |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 5 | 2 | 1 | 1 | 9 |\n",
    "\n",
    "We get a new message with the word 'money' in the message. Let's classify it!\n",
    "\n",
    "First, we will find the probability that a new message is spam given that it has the word 'money' in the message.\n",
    "\n",
    "Reminder: Bayes' theorem\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Bayes' Theorem: } P(A|B) &=& \\frac{P(B|A)P(A)}{P(B)}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "- Let $A$ be that a message is spam.\n",
    "- Let $B$ represent that 'money' was used in the message.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "P(\\text{message is spam}|\\text{'money' in message}) &=& \\frac{P(\\text{'money' in message}|\\text{message is spam})P(\\text{message is spam})}{P(\\text{'money' in message})}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam =  \n",
    "p_ham = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(\\text{'money' in message}) = P(\\text{'money' in message}|\\text{spam})*P(\\text{spam}) + P(\\text{'money' in message}|\\text{ham})*P(\\text{ham})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_money_given_spam = \n",
    "p_money_given_ham = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_money = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find the probability that a new message is ham given that it has the word 'money' in the message.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "P(\\text{message is ham}|\\text{'money' in message}) &=& \\frac{P(\\text{'money' in message}|\\text{message is ham})P(\\text{message is ham})}{P(\\text{'money' in message})}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so we would classify this message as spam! \n",
    "\n",
    "It is slightly more complex in an actual Naive Bayes model since we will incorporate all of the words in the message, but all this entails is multiplying the conditional probabilities of each word in the message together with our prior probability (the probability that a message is spam or ham). You can watch a video explanation of this [here](https://statquest.org/naive-bayes-clearly-explained/) (this video was also the inspiration behind this example).\n",
    "\n",
    "Now, let's think about some extra work that we did to compare these two probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>In both of these, we divided by the probability that 'money' was in the message. What would have happened if we didn't do that?</summary>\n",
    "\n",
    "We would have still classified this message as spam! Since we divided by the same denominator in both cases, our answers without dividing by the probability that 'money' was in the message were proportional to our answers when we divided by it!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets up the idea behind Bayesian Inference.\n",
    "\n",
    "---\n",
    "\n",
    "To the slides!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Bayesian Inference\n",
    "\n",
    "This afternoon you will see an example of how to use Bayesian inference to solve a problem. I also encourage you to check out [this blog post](https://towardsdatascience.com/bayesian-inference-intuition-and-example-148fd8fb95d6) which walks through another example of Bayesian inference in Python.\n",
    "\n",
    "You can also play around with [this visualization](https://rpsychologist.com/d3/bayes/) to see how the posterior distribution changes with the prior and likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
