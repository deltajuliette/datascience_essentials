{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "## Gradient Descent Code-Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through how gradient descent works using code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The objective function\n",
    "def f(x):\n",
    "    return -np.log(x) / (1 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivative of the objective function\n",
    "def f_deriv(x):\n",
    "    return -(1 + 1/x - np.log(x)) / (1 + x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what it looks like\n",
    "xs = np.linspace(1, 7, 1000)\n",
    "plt.plot(xs, f(xs));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial value and learning rate\n",
    "x = 1\n",
    "alpha = 1\n",
    "num_steps = 300\n",
    "\n",
    "# Iterate and apply gradient descent\n",
    "x_steps = [x]\n",
    "for i in range(num_steps):\n",
    "    x = x - alpha * f_deriv(x)\n",
    "    x_steps.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_steps)\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('Value of x');\n",
    "# You can see here that the value of x that is optimum is pretty much converging to ~3.5\n",
    "# This aligns with the min value of the plot above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see if we can do OLS by Gradient Descent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233070. 267128. 241282. 222085. 255464. 245706. 223323. 247075. 248164.\n",
      " 218141. 251156. 249216. 268661. 268076. 213447. 230243. 246301. 250276.\n",
      " 251301. 323055. 269418. 269711. 253080. 242028. 236695. 267179. 224543.\n",
      " 232264. 241293. 250637. 297293. 204655. 266725. 209746. 231561. 271779.\n",
      " 256286. 214445. 235694. 264592. 230393. 245329. 256911. 229968. 281879.\n",
      " 253678. 216497. 251729. 238764. 272049. 225150. 236705. 253100. 253315.\n",
      " 234994. 238310. 253501. 231933. 275309. 255100. 204782. 274357. 279443.\n",
      " 268649. 208613. 232315. 273338. 219847. 249876. 264493. 226461. 246809.\n",
      " 184175. 237512. 236949. 215044. 284648. 217397. 246199. 244615. 276825.\n",
      " 218283. 258263. 246205. 228370. 258242. 244981. 235996. 249396. 226294.\n",
      " 242270. 268243. 282720. 221244. 280661. 200958. 244964. 267766. 249620.\n",
      " 228546.]\n"
     ]
    }
   ],
   "source": [
    "# Let's generate a fake linear regression dataset of the form y = beta_0 + beta_1 * x + error\n",
    "# Just to make this more fun, let's use a Poisson distribution for our x!\n",
    "\n",
    "# Our Fake Linear Equation\n",
    "beta_0 = 200_000\n",
    "beta_1 = 1000\n",
    "x = np.random.poisson(45, 100)\n",
    "error = np.round(np.random.normal(0, 20000, 100))\n",
    "\n",
    "# Our Equation\n",
    "y_true = beta_0 + (beta_1 * x) + error\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>233070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>267128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>241282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>222085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>255464.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x    y_true\n",
       "0  42  233070.0\n",
       "1  50  267128.0\n",
       "2  37  241282.0\n",
       "3  47  222085.0\n",
       "4  52  255464.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe\n",
    "df = pd.DataFrame({'x': x, 'y_true': y_true})\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our goal is to fit a model here.\n",
    "- You and I know that our $y$-intercept $\\beta_0$ is 200,000.\n",
    "- You and I know that our slope $\\beta_1$ is 1,000.\n",
    "- However, our computer does not know that. Our computer has to estimate $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ from the data.\n",
    "    - We might say that our **machine** has to... **learn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our workflow:\n",
    "1. Instantiate model.\n",
    "2. Select a learning rate $\\alpha$.\n",
    "3. Select a starting point $\\hat{\\beta}_{1,0}$.\n",
    "4. Calculate the gradient of the loss function.\n",
    "5. Calculate $\\hat{\\beta}_{1,i+1} = \\hat{\\beta}_{1,i} - \\alpha * \\frac{\\partial L}{\\partial \\beta_1}$.\n",
    "6. Check value of $\\left|\\hat{\\beta}_{1,i+1} - \\hat{\\beta}_{1,i}\\right|$.\n",
    "7. Repeat steps 4 through 6 until \"stopping condition\" is met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Instantiate model.\n",
    "\n",
    "Our model takes on the form:\n",
    "$$ Y = \\beta_0 + \\beta_1 X + \\varepsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Select a learning rate $\\alpha$.\n",
    "\n",
    "$$\\alpha = 0.1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Select a starting point.\n",
    "The zero-th iteration of $\\hat{\\beta}_1$ is going to start at, say, 20.\n",
    "$$\\hat{\\beta}_{1,0} = 20$$\n",
    "\n",
    "Two points:\n",
    "- You and I know that the true value of $\\beta_1$ is 1000. We need the computer to figure (machine to learn) that part out!\n",
    "- We're going to pretend like the computer already knows the value for $\\beta_0$. In reality, we'd have to do this for $\\beta_0$ and for $\\beta_1$ at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick any random number, it doesn't matter!\n",
    "beta_1 = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Calculate the gradient of the loss function with respect to parameter $\\beta_1$.\n",
    "\n",
    "The loss function, $L$, is our mean square error.\n",
    "\n",
    "$$L = \\frac{1}{n}\\sum_{i = 1} ^ n (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "$$\\Rightarrow L = \\frac{1}{n}\\sum_{i = 1} ^ n \\left(y_i - \\left(\\hat{\\beta}_0 + \\hat{\\beta}_1x_i\\right)\\right)^2 $$\n",
    "\n",
    "The gradient of this loss function with respect to $\\beta_1$ is:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\beta_1} = {2}\\frac{\\sum_{i=1}^n -x_i\\left(y_i - \\left(\\hat{\\beta}_1x_i + \\hat{\\beta}_0\\right)\\right)}{n} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate gradient of beta_1.\n",
    "def beta_1_gradient(x, y, beta_1, beta_0):\n",
    "    grads = -x * (y - (beta_1*x + beta_0))\n",
    "    return 2 * np.mean(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5. Calculate $\\hat{\\beta}_{1,i+1} = \\hat{\\beta}_{1,i} - \\alpha * \\frac{\\partial L}{\\partial \\beta_1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate new value of beta_1.\n",
    "def update_beta_1(beta_1, alpha, gradient):\n",
    "    beta_1 = beta_1 - alpha * gradient\n",
    "    return beta_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6. Check value of $\\left|\\hat{\\beta}_{1,i+1} - \\hat{\\beta}_{1,i}\\right|$. \n",
    "We want to stop the iterations once the difference is less than a tolerance value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_update(beta_1, updated_beta_1, tolerance = 0.1):\n",
    "    return abs(beta_1 - updated_beta_1) < tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Save final value of $\\hat{\\beta}_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, beta_1 = 0, alpha = 0.01, max_iter = 100):\n",
    "    # Set converged = False.\n",
    "    converged = False\n",
    "    \n",
    "    # Iterate through our observations.\n",
    "    step = 0\n",
    "    while not converged:\n",
    "        \n",
    "        # Calculate gradient.\n",
    "        gradient = beta_1_gradient(x, y, beta_1, 200000)\n",
    "        \n",
    "        # Update beta_1.\n",
    "        updated_beta_1 = update_beta_1(beta_1, alpha, gradient)\n",
    "        \n",
    "        # Check for convergence.\n",
    "        converged = check_update(beta_1, updated_beta_1)\n",
    "        \n",
    "        # Overwrite beta_1.\n",
    "        beta_1 = updated_beta_1\n",
    "        \n",
    "        # Print out current step findings.\n",
    "        print(f'Iteration {step} with beta_1 value of {beta_1}.')\n",
    "        \n",
    "        # If we've converged, let us know!\n",
    "        if converged:\n",
    "            print(f'Our algorithm converged after {step} iterations with a beta_1 value of {beta_1}.')\n",
    "        else:\n",
    "            step += 1\n",
    "            \n",
    "        # If we exceed our step limit, break!\n",
    "        if step > max_iter:\n",
    "            break\n",
    "        \n",
    "    # If we didn't converge by the end of our loop, let us know!\n",
    "    if not converged:\n",
    "        print(\"Our algorithm did not converge, so do not trust the value of beta_1.\")\n",
    "    \n",
    "    # Return beta_1.\n",
    "    return beta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 with beta_1 value of 41435.536400000005.\n",
      "Iteration 1 with beta_1 value of -1644889.1423060796.\n",
      "Iteration 2 with beta_1 value of 67017530.06550508.\n",
      "Iteration 3 with beta_1 value of -2728723925.3027844.\n",
      "Iteration 4 with beta_1 value of 111106040061.21902.\n",
      "Iteration 5 with beta_1 value of -4523926812130.787.\n",
      "Iteration 6 with beta_1 value of 184201632837141.66.\n",
      "Iteration 7 with beta_1 value of -7500174724514217.0.\n",
      "Iteration 8 with beta_1 value of 3.0538611429303245e+17.\n",
      "Iteration 9 with beta_1 value of -1.2434467492892217e+19.\n",
      "Iteration 10 with beta_1 value of 5.06296699801591e+20.\n",
      "Iteration 11 with beta_1 value of -2.0614983985161335e+22.\n",
      "Iteration 12 with beta_1 value of 8.39384425920612e+23.\n",
      "Iteration 13 with beta_1 value of -3.4177383547094743e+25.\n",
      "Iteration 14 with beta_1 value of 1.391607361363766e+27.\n",
      "Iteration 15 with beta_1 value of -5.666235525412072e+28.\n",
      "Iteration 16 with beta_1 value of 2.3071324513530843e+30.\n",
      "Iteration 17 with beta_1 value of -9.393997344823376e+31.\n",
      "Iteration 18 with beta_1 value of 3.8249726868864247e+33.\n",
      "Iteration 19 with beta_1 value of -1.5574217788649202e+35.\n",
      "Iteration 20 with beta_1 value of 6.341385405439872e+36.\n",
      "Iteration 21 with beta_1 value of -2.5820345783037628e+38.\n",
      "Iteration 22 with beta_1 value of 1.0513321833170998e+40.\n",
      "Iteration 23 with beta_1 value of -4.2807302774559026e+41.\n",
      "Iteration 24 with beta_1 value of 1.7429935085322762e+43.\n",
      "Iteration 25 with beta_1 value of -7.096981528561035e+44.\n",
      "Iteration 26 with beta_1 value of 2.8896921629472515e+46.\n",
      "Iteration 27 with beta_1 value of -1.1766017373715583e+48.\n",
      "Iteration 28 with beta_1 value of 4.790792826090524e+49.\n",
      "Iteration 29 with beta_1 value of -1.950676696584932e+51.\n",
      "Iteration 30 with beta_1 value of 7.942609319018798e+52.\n",
      "Iteration 31 with beta_1 value of -3.234008121643523e+54.\n",
      "Iteration 32 with beta_1 value of 1.3167975549058362e+56.\n",
      "Iteration 33 with beta_1 value of -5.361630940261188e+57.\n",
      "Iteration 34 with beta_1 value of 2.1831059932080286e+59.\n",
      "Iteration 35 with beta_1 value of -8.888996334664998e+60.\n",
      "Iteration 36 with beta_1 value of 3.619350415578215e+62.\n",
      "Iteration 37 with beta_1 value of -1.473698147411814e+64.\n",
      "Iteration 38 with beta_1 value of 6.00048622077963e+65.\n",
      "Iteration 39 with beta_1 value of -2.4432299754872837e+67.\n",
      "Iteration 40 with beta_1 value of 9.948148355791077e+68.\n",
      "Iteration 41 with beta_1 value of -4.050607462324164e+70.\n",
      "Iteration 42 with beta_1 value of 1.6492939416494545e+72.\n",
      "Iteration 43 with beta_1 value of -6.715463128092912e+73.\n",
      "Iteration 44 with beta_1 value of 2.734348552791849e+75.\n",
      "Iteration 45 with beta_1 value of -1.1133501689373623e+77.\n",
      "Iteration 46 with beta_1 value of 4.533250149865636e+78.\n",
      "Iteration 47 with beta_1 value of -1.845812530021091e+80.\n",
      "Iteration 48 with beta_1 value of 7.515631794737475e+81.\n",
      "Iteration 49 with beta_1 value of -3.060154829126848e+83.\n",
      "Iteration 50 with beta_1 value of 1.2460093620852368e+85.\n",
      "Iteration 51 with beta_1 value of -5.0734012397897e+86.\n",
      "Iteration 52 with beta_1 value of 2.0657469296076513e+88.\n",
      "Iteration 53 with beta_1 value of -8.411143088222068e+89.\n",
      "Iteration 54 with beta_1 value of 3.424781953517555e+91.\n",
      "Iteration 55 with beta_1 value of -1.3944753175776497e+93.\n",
      "Iteration 56 with beta_1 value of 5.6779130400872674e+94.\n",
      "Iteration 57 with beta_1 value of -2.3118872083584123e+96.\n",
      "Iteration 58 with beta_1 value of 9.413357384017118e+97.\n",
      "Iteration 59 with beta_1 value of -3.83285555276502e+99.\n",
      "Iteration 60 with beta_1 value of 1.5606314611304388e+101.\n",
      "Iteration 61 with beta_1 value of -6.354454332914029e+102.\n",
      "Iteration 62 with beta_1 value of 2.5873558796412725e+104.\n",
      "Iteration 63 with beta_1 value of -1.053498868225296e+106.\n",
      "Iteration 64 with beta_1 value of 4.289552411730302e+107.\n",
      "Iteration 65 with beta_1 value of -1.7465856345890493e+109.\n",
      "Iteration 66 with beta_1 value of 7.111607660068924e+110.\n",
      "Iteration 67 with beta_1 value of -2.895647514165585e+112.\n",
      "Iteration 68 with beta_1 value of 1.17902658963783e+114.\n",
      "Iteration 69 with beta_1 value of -4.800666145560145e+115.\n",
      "Iteration 70 with beta_1 value of 1.9546968358200154e+117.\n",
      "Iteration 71 with beta_1 value of -7.958978200345076e+118.\n",
      "Iteration 72 with beta_1 value of 3.240673071790907e+120.\n",
      "Iteration 73 with beta_1 value of -1.3195113359872477e+122.\n",
      "Iteration 74 with beta_1 value of 5.372680696965997e+123.\n",
      "Iteration 75 with beta_1 value of -2.187605144745038e+125.\n",
      "Iteration 76 with beta_1 value of 8.907315619961259e+126.\n",
      "Iteration 77 with beta_1 value of -3.626809515610868e+128.\n",
      "Iteration 78 with beta_1 value of 1.4767352840903096e+130.\n",
      "Iteration 79 with beta_1 value of -6.012852590936196e+131.\n",
      "Iteration 80 with beta_1 value of 2.4482652151566745e+133.\n",
      "Iteration 81 with beta_1 value of -9.968650441857734e+134.\n",
      "Iteration 82 with beta_1 value of 4.058955337712099e+136.\n",
      "Iteration 83 with beta_1 value of -1.6526929627669106e+138.\n",
      "Iteration 84 with beta_1 value of 6.729302990357284e+139.\n",
      "Iteration 85 with beta_1 value of -2.739983757189756e+141.\n",
      "Iteration 86 with beta_1 value of 1.1156446663824676e+143.\n",
      "Iteration 87 with beta_1 value of -4.5425927010028213e+144.\n",
      "Iteration 88 with beta_1 value of 1.8496165552527195e+146.\n",
      "Iteration 89 with beta_1 value of -7.531120720353605e+147.\n",
      "Iteration 90 with beta_1 value of 3.066461485947819e+149.\n",
      "Iteration 91 with beta_1 value of -1.2485772561563451e+151.\n",
      "Iteration 92 with beta_1 value of 5.083856985436912e+152.\n",
      "Iteration 93 with beta_1 value of -2.0700042164743206e+154.\n",
      "Iteration 94 with beta_1 value of 8.428477568302825e+155.\n",
      "Iteration 95 with beta_1 value of -3.4318400684409985e+157.\n",
      "Iteration 96 with beta_1 value of 1.3973491843472574e+159.\n",
      "Iteration 97 with beta_1 value of -5.689614620890414e+160.\n",
      "Iteration 98 with beta_1 value of 2.316651764417191e+162.\n",
      "Iteration 99 with beta_1 value of -9.432757322212768e+163.\n",
      "Iteration 100 with beta_1 value of 3.840754664400018e+165.\n",
      "Our algorithm did not converge, so do not trust the value of beta_1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.840754664400018e+165"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call gradient_descent with an initial beta_1 of 20, alpha of 0.01, and 100 iterations.\n",
    "gradient_descent(df['x'],\n",
    "                 df['y_true'],\n",
    "                 beta_1 = 20,\n",
    "                 alpha = 0.01,\n",
    "                 max_iter = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What should we do?</summary>\n",
    "\n",
    "- We **should not** adjust our maximum iterations. It doesn't look like we'll converge.\n",
    "- We should adjust our alpha!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 with beta_1 value of 434.155364.\n",
      "Iteration 1 with beta_1 value of 675.5367064893921.\n",
      "Iteration 2 with beta_1 value of 816.2205115697996.\n",
      "Iteration 3 with beta_1 value of 898.2149723172032.\n",
      "Iteration 4 with beta_1 value of 946.003639885691.\n",
      "Iteration 5 with beta_1 value of 973.8562134272975.\n",
      "Iteration 6 with beta_1 value of 990.089473159405.\n",
      "Iteration 7 with beta_1 value of 999.5506714625496.\n",
      "Iteration 8 with beta_1 value of 1005.0649227471749.\n",
      "Iteration 9 with beta_1 value of 1008.2787827948905.\n",
      "Iteration 10 with beta_1 value of 1010.1519104187804.\n",
      "Iteration 11 with beta_1 value of 1011.2436216455569.\n",
      "Iteration 12 with beta_1 value of 1011.8799015164366.\n",
      "Iteration 13 with beta_1 value of 1012.2507432410217.\n",
      "Iteration 14 with beta_1 value of 1012.4668801816782.\n",
      "Iteration 15 with beta_1 value of 1012.5928508425271.\n",
      "Iteration 16 with beta_1 value of 1012.6662700708484.\n",
      "Our algorithm converged after 16 iterations with a beta_1 value of 1012.6662700708484.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1012.6662700708484"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(df['x'],\n",
    "                 df['y_true'],\n",
    "                 beta_1 = 20,\n",
    "                 alpha = 0.0001,\n",
    "                 max_iter = 100)\n",
    "\n",
    "# try changing the initial value of beta_1 from 20 to whatever number\n",
    "# The algorithm will still find a value of beta_1 very close to the actual value of 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- The value of $\\hat{\\beta_1}$ at the end of gradient descent is 1012 which is so close to the actual value of 1000. \n",
    "- Even though we started the gradient descent algorithm with a random $\\hat{\\beta_1}=20$, it was still able to find a value very close to the true value almost instantaneously on modern computers!\n",
    "- In reality, we would have to concurrently run gradient descent for all our parameters $\\hat{\\beta_1}$ and $\\hat{\\beta_0}$\n",
    "- Implement gradient descent in code is an interview question! As a test for yourself, try writing code to change both $\\hat{\\beta_1}$ and $\\hat{\\beta_0}$ in the gradient descent loop!\n",
    "- As already mentioned, Gradient descent is the basis of the modern AI revolution especially when we're talking about deep learning. And Gradient descent is just the clever application of math that was invented several centuries back! [See: Who's the greatest mathematician/physicist in the history of human civilization?](https://www.youtube.com/watch?v=danYFxGnFxQ)\n",
    "\n",
    "<details><summary>Here's a meme to drive home that point!</summary>\n",
    "\n",
    "<img src='assets/math.jpeg'>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
