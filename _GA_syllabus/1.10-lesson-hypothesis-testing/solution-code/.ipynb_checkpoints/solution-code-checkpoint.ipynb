{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "## Hypothesis Testing\n",
    "\n",
    "_Authors: Tim Book (DC), Matt Brems (DC), et. al_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Define the null and alternative hypotheses.\n",
    "- Perform a two-sample t-test.\n",
    "- Define the t-statistics and p-value.\n",
    "- List the steps of hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in our libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm # a module enabling statistical testing, exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Hypothesis Testing\n",
    "\n",
    "In the real world, we like to make **data-driven decisions$^{\\text{TM}}$**!\n",
    "- In order to make these decisions, though, we need to collect some data.\n",
    "- We take this data, put it into a \"box,\" which gives us a statistics-powered yes-or-no decision.\n",
    "- This \"box\" is *hypothesis testing*.\n",
    "- **Hypothesis testing is a mathematically rigorous way of making yes-or-no decisions!**\n",
    "\n",
    "Hypothesis testing is a little more complicated than that, but not much!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First: How do we interpret statsmodels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqft</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>age</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.104</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.416</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sqft  bedrooms  age  price\n",
       "0  2.104       3.0  7.0  3.999\n",
       "1  1.600       3.0  2.8  3.299\n",
       "2  2.400       3.0  4.4  3.690\n",
       "3  1.416       2.0  4.9  2.320\n",
       "4  3.000       4.0  7.5  5.399"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses = pd.read_csv('../data/houses-norm.csv')\n",
    "print(houses.shape)\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqft</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.104</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.416</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sqft  bedrooms  age\n",
       "0  2.104       3.0  7.0\n",
       "1  1.600       3.0  2.8\n",
       "2  2.400       3.0  4.4\n",
       "3  1.416       2.0  4.9\n",
       "4  3.000       4.0  7.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we wanted to only subset specific columns from our dataframe into a SUBSET dataframe\n",
    "# pass subset columns list within list: dataframe[['subset_col1', 'subset_col2'..]]\n",
    "houses[['sqft', 'bedrooms','age']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double [] returns a pandas DataFrame\n",
    "type(houses[['sqft', 'bedrooms','age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.999\n",
       "1    3.299\n",
       "2    3.690\n",
       "3    2.320\n",
       "4    5.399\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses['price'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single [] will only return a pandas Series\n",
    "type(houses['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What follows might be more familiar for those moving from R programming background, putting statsmodels module to use\n",
    "- In the industry, mostly the stats module imported from scipy library is what is used for statistical testing and related tasks. \n",
    "- As someone that started their coding journey with Python (not knowing R), I've never seen or used statsmodels module before :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = houses[['sqft', 'bedrooms','age']] # X is now a subset df with column, values from only these 3 cols\n",
    "y = houses['price'] # y is now a series with only values from this 1 col\n",
    "\n",
    "X = sm.add_constant(X, prepend=True) # Add a column of ones to first col of X -> print X to see. This is done to let statsmodels know that we want the intercept of linear equation (more details soon)\n",
    "results = sm.OLS(y, X).fit() # OLS: ordinary least squares, fits a simple linear reg model with OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In statistics, ordinary least squares (OLS) is a type of linear least squares method for ***estimating the unknown parameters in a linear regression model*** (further read on [Wikipedia](https://en.wikipedia.org/wiki/Ordinary_least_squares) if interested)\n",
    "- sm.add_constant in statsmodel is the same as sklearn's fit_intercept parameter in LinearRegression().  If you don't do sm.add_constant or when LinearRegression(fit_intercept=False), then both statsmodels and sklearn algorithms assume that b=0 in y = mx + b, and it'll fit the model using b=0 instead of calculating what b is supposed to be based on your data.\n",
    "\n",
    "Google to find [documentation for sm.add_constant](https://www.statsmodels.org/stable/generated/statsmodels.tools.tools.add_constant.html)\n",
    "- Similarly, [documentation for sm.OLS](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html)\n",
    "\n",
    "We'll cover linear regression concept in more details next week, let's just scratch the surface right now. Just understand `fit()` as fitting a relation between features (X) and response (y) with a **mathematical equation**. For linear regression, that equation is `y = m1X1 + m2X2 + m3X3 + b`, *where b is the constant - the y-intercept when X=0*\n",
    "- an intial value of 1 ensures update to the appropriate intercept value during the model fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_vals_const: [1.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>sqft</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.104</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.416</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const   sqft  bedrooms  age\n",
       "0    1.0  2.104       3.0  7.0\n",
       "1    1.0  1.600       3.0  2.8\n",
       "2    1.0  2.400       3.0  4.4\n",
       "3    1.0  1.416       2.0  4.9\n",
       "4    1.0  3.000       4.0  7.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'unique_vals_const: {X[\"const\"].unique()}')\n",
    "X.head() # see const column inserted as first col as a result of sm.add_constant() above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   39.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 20 Oct 2021</td> <th>  Prob (F-statistic):</th> <td>2.12e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:28:25</td>     <th>  Log-Likelihood:    </th> <td> -45.641</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    47</td>      <th>  AIC:               </th> <td>   99.28</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    43</td>      <th>  BIC:               </th> <td>   106.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>    0.9245</td> <td>    0.449</td> <td>    2.060</td> <td> 0.045</td> <td>    0.019</td> <td>    1.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft</th>     <td>    1.3933</td> <td>    0.150</td> <td>    9.305</td> <td> 0.000</td> <td>    1.091</td> <td>    1.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms</th> <td>   -0.0862</td> <td>    0.156</td> <td>   -0.551</td> <td> 0.584</td> <td>   -0.402</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>      <td>   -0.0081</td> <td>    0.043</td> <td>   -0.188</td> <td> 0.852</td> <td>   -0.095</td> <td>    0.079</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.841</td> <th>  Durbin-Watson:     </th> <td>   1.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.147</td> <th>  Jarque-Bera (JB):  </th> <td>   2.771</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.552</td> <th>  Prob(JB):          </th> <td>   0.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.444</td> <th>  Cond. No.          </th> <td>    28.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.733\n",
       "Model:                            OLS   Adj. R-squared:                  0.715\n",
       "Method:                 Least Squares   F-statistic:                     39.38\n",
       "Date:                Wed, 20 Oct 2021   Prob (F-statistic):           2.12e-12\n",
       "Time:                        22:28:25   Log-Likelihood:                -45.641\n",
       "No. Observations:                  47   AIC:                             99.28\n",
       "Df Residuals:                      43   BIC:                             106.7\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.9245      0.449      2.060      0.045       0.019       1.830\n",
       "sqft           1.3933      0.150      9.305      0.000       1.091       1.695\n",
       "bedrooms      -0.0862      0.156     -0.551      0.584      -0.402       0.229\n",
       "age           -0.0081      0.043     -0.188      0.852      -0.095       0.079\n",
       "==============================================================================\n",
       "Omnibus:                        3.841   Durbin-Watson:                   1.819\n",
       "Prob(Omnibus):                  0.147   Jarque-Bera (JB):                2.771\n",
       "Skew:                           0.552   Prob(JB):                        0.250\n",
       "Kurtosis:                       3.444   Cond. No.                         28.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary() # displays various linear regression model stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the statsmodels results\n",
    "\n",
    "![](../images/statsmodels1.png)\n",
    "\n",
    "---\n",
    "\n",
    "![](../images/statsmodels2.png)\n",
    "\n",
    "---\n",
    "\n",
    "![](../images/statsmodels3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key points:\n",
    "- **Hypothesis**: \n",
    "    - In statistical hypothesis testing, we are generally trying to decide if there is a statistically significant difference between two or more groups of data. \n",
    "    - To do this, we formulate a hypothesis called **Null hypothesis ($H_0$)** which states that there is ***NO*** significant difference between specified populations, any observed difference being due to sampling or experimental error.  The opposite of Null hypothesis is called **Alternate hypothesis ($H_A$)**\n",
    "    - The goal of hypothesis testing is to perform statistical analysis and gather evidence to either ***Reject the Null Hypothesis*** or ***Fail to reject the Null Hypothesis***\n",
    "    - The single metric you must look at to make this decision is called the **p-value**. In general, $p-value < 0.05$ indicates we can **Reject the Null Hypothesis**. More about this soon.\n",
    "    \n",
    "\n",
    "- For the above Linear Regression case, we are trying to build an equation that can determine the **Price** of a house using the **Area (sqft)**, **Number of Bedrooms** and **Age**. \n",
    "    - The equation we choose to build is Ordinary Least Squares which is of the form $y=\\beta_1X_1+\\beta_2X_2+\\beta_3X_3+b$ which you must be familiar from secondary school mathematics.\n",
    "    - $y$ is the **Price**\n",
    "    - $X_1$ is the **Area (sqft)**. $\\beta_1$ is the coefficient or weight of **Area (sqft)**\n",
    "    - $X_2$ is the **Number of Bedrooms**. $\\beta_2$ is the coefficient or weight of **Number of Bedrooms**\n",
    "    - $X_3$ is the **Age**. $\\beta_3$ is the coefficient or weight of **Age**\n",
    "    - $b$ is the constant (intercept) term\n",
    "\n",
    "\n",
    "- In this case, the **Null hypothesis** (No statistically significant difference) will ***not be rejected*** if **ALL** coefficients (coef) are 0 or close to 0 because it indicates the 3 variables ($X_1$, $X_2$, $X_3$) we used to determine the $y$ actually have no impact on $y$ at all. As a Data Scientist/Analyst, we are generally checking for evidence to ***reject the null hypothesis ($H_{0}$)***\n",
    "\n",
    "- The values under coef in summary above are $\\beta_0$ or $b$, $\\beta_1$, $\\beta_2$, $\\beta_3$ respectively\n",
    "    \n",
    "- the p-value (is actually a probability) is evidence **AGAINST** a null hypothesis. The **smaller** the p-value, the stronger the evidence that you should **reject the null hypothesis**. A p-value typically ≤ 0.05 is considered statistically significant. **Low p-values are good; They indicate your data did not occur by chance**. For example, a p-value of 0.01 means there is only a 1% probability that the results from an experiment happened by chance\n",
    "    - \"P > |t|\" column in the statsmodel results represents the p-values corresponding to each feature & its impact on the response, y\n",
    "    - p-values are related to t-values [further read](https://www.statisticshowto.com/probability-and-statistics/t-test/#:~:text=Every%20t%2Dvalue%20has%20a,value%20of%205%25%20is%200.05.)\n",
    "    \n",
    "- AIC, BIC are just different criterion used for models selection by means of parameter tuning. In real world Data Science tasks, we will train many different models and use some metrics like these to choose the best model\n",
    "    - Further read from [Wiki-AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion)\n",
    "    - Further read from [Wiki-BIC](https://en.wikipedia.org/wiki/Bayesian_information_criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You Try: Hypothesis Testing our OLS coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>angle</th>\n",
       "      <th>chord_len</th>\n",
       "      <th>velocity</th>\n",
       "      <th>thickness</th>\n",
       "      <th>db</th>\n",
       "      <th>junk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "      <td>-0.279348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "      <td>0.117033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "      <td>0.246328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "      <td>-1.378038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "      <td>0.037208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   freq  angle  chord_len  velocity  thickness       db      junk\n",
       "0   800    0.0     0.3048      71.3   0.002663  126.201 -0.279348\n",
       "1  1000    0.0     0.3048      71.3   0.002663  125.201  0.117033\n",
       "2  1250    0.0     0.3048      71.3   0.002663  125.951  0.246328\n",
       "3  1600    0.0     0.3048      71.3   0.002663  127.591 -1.378038\n",
       "4  2000    0.0     0.3048      71.3   0.002663  127.461  0.037208"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a NASA dataset of airfoils at various wind tunnel speeds and angles of attack.\n",
    "# Their goal was to minimize noise (measured in db)\n",
    "df = pd.read_csv(\n",
    "    \"../data/airfoil_self_noise.dat\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"freq\", \"angle\", \"chord_len\", \"velocity\", \"thickness\", \"db\"]\n",
    ")\n",
    "\n",
    "# Let's create a rubbish column randomly to prove hypothesis testing works!\n",
    "df[\"junk\"] = np.random.randn(df.shape[0]) # Returns df's row number of samples from  “std normal” dist\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating the same feature-response assignment from defined dataframe above\n",
    "X = df.drop(\"db\", axis=1) # dropping db as that'll be response\n",
    "X = sm.add_constant(X)\n",
    "y = df[\"db\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>db</td>        <th>  R-squared:         </th> <td>   0.516</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.514</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   265.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 20 Oct 2021</td> <th>  Prob (F-statistic):</th> <td>2.14e-231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:28:25</td>     <th>  Log-Likelihood:    </th> <td> -4490.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1503</td>      <th>  AIC:               </th> <td>   8994.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1496</td>      <th>  BIC:               </th> <td>   9031.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>  132.8331</td> <td>    0.545</td> <td>  243.767</td> <td> 0.000</td> <td>  131.764</td> <td>  133.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>freq</th>      <td>   -0.0013</td> <td> 4.21e-05</td> <td>  -30.442</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>angle</th>     <td>   -0.4218</td> <td>    0.039</td> <td>  -10.839</td> <td> 0.000</td> <td>   -0.498</td> <td>   -0.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chord_len</th> <td>  -35.6867</td> <td>    1.631</td> <td>  -21.880</td> <td> 0.000</td> <td>  -38.886</td> <td>  -32.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>velocity</th>  <td>    0.0999</td> <td>    0.008</td> <td>   12.275</td> <td> 0.000</td> <td>    0.084</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thickness</th> <td> -147.3613</td> <td>   15.030</td> <td>   -9.805</td> <td> 0.000</td> <td> -176.843</td> <td> -117.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>junk</th>      <td>   -0.0138</td> <td>    0.125</td> <td>   -0.110</td> <td> 0.912</td> <td>   -0.259</td> <td>    0.231</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.914</td> <th>  Durbin-Watson:     </th> <td>   0.447</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  19.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.021</td> <th>  Prob(JB):          </th> <td>6.91e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.552</td> <th>  Cond. No.          </th> <td>5.18e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.18e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     db   R-squared:                       0.516\n",
       "Model:                            OLS   Adj. R-squared:                  0.514\n",
       "Method:                 Least Squares   F-statistic:                     265.5\n",
       "Date:                Wed, 20 Oct 2021   Prob (F-statistic):          2.14e-231\n",
       "Time:                        22:28:25   Log-Likelihood:                -4490.1\n",
       "No. Observations:                1503   AIC:                             8994.\n",
       "Df Residuals:                    1496   BIC:                             9031.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        132.8331      0.545    243.767      0.000     131.764     133.902\n",
       "freq          -0.0013   4.21e-05    -30.442      0.000      -0.001      -0.001\n",
       "angle         -0.4218      0.039    -10.839      0.000      -0.498      -0.345\n",
       "chord_len    -35.6867      1.631    -21.880      0.000     -38.886     -32.487\n",
       "velocity       0.0999      0.008     12.275      0.000       0.084       0.116\n",
       "thickness   -147.3613     15.030     -9.805      0.000    -176.843    -117.880\n",
       "junk          -0.0138      0.125     -0.110      0.912      -0.259       0.231\n",
       "==============================================================================\n",
       "Omnibus:                       12.914   Durbin-Watson:                   0.447\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               19.161\n",
       "Skew:                          -0.021   Prob(JB):                     6.91e-05\n",
       "Kurtosis:                       3.552   Cond. No.                     5.18e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.18e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "# Check out the p-value of the rubbish \"junk\" column and confirm its really unable to reject the null hypothesis (p-value > 0.05). \n",
    "# This indicates that the rubbish \"junk\" column does NOT have a statistically significant impact on our \"db\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses\n",
    "Notice the columns marked `t` and `P>|t|`. These are the $t$-statistics and $p$-values for the hypothesis test:\n",
    "\n",
    "$$\n",
    "H_0: \\beta_i = 0\n",
    "$$\n",
    "$$\n",
    "H_A: \\beta_i \\ne 0\n",
    "$$\n",
    "\n",
    "where $H_{0}$ --> null hypothesis and $H_{A}$ --> alternate hypothesis\n",
    "\n",
    "\n",
    "(THREAD) In your own words, what would it mean if $\\beta_i = 0$?\n",
    "\n",
    "Generally, one way to practically internalize how null hypothesis and p-value work together is: we use a significant p-value result (<=0.05) to reject the null hypothesis, so we can statistically confirm there IS a significant toggle (difference) between the groups we are studying. Like in house dataset, the feature sqft has a statistically significant impact on the response house price (based on a p-value of 0), so we can reject null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing with Puppies\n",
    "\n",
    "[This example is pulled liberally from Cassie Kozyrkov's Medium post.](https://hackernoon.com/explaining-p-values-with-puppies-af63d68005d0)\n",
    "\n",
    "Let's say that we come home at the end of the day to find some unwound toilet paper.\n",
    "\n",
    "<img src=\"./images/pug_toilet_paper.jpg\" alt=\"doggo\" width=\"600\"/>\n",
    "\n",
    "We need to make a **data-driven** decision: Do we yell at our dog? \n",
    "\n",
    "Our possibilities are:\n",
    "- Yes, we yell at our dog.\n",
    "- No, we don't yell at our dog.\n",
    "\n",
    "Let's assume that our dog is innocent (null hypothesis). Being good data scientists, we want to gather data, then use this data to make a decision.\n",
    "- **Gust of wind?** We check to see if the bathroom window is open or closed.\n",
    "- **Floor vent?** We check the thermostat to see if we left the heating/air conditioning on.\n",
    "- **Another human?** We text your sibling to see if they brought our niece over.\n",
    "\n",
    "Once you're done \"gathering your data,\" you determine the probability of observing this naturally, if our dog didn't do it.\n",
    "- If the probability (p-value) is low enough (<= 0.05), the incident *did not* happen naturally, SO, we reject the null hypothesis and blame our dog. (because, smaller p-values stronger evidence ***against*** null hypothesis)\n",
    "- Otherwise, we can't blame our dog!\n",
    "\n",
    "We just walked through a hypothesis test! We had two potential decisions, we gathered data, and used this data to make a decision.\n",
    "\n",
    "> **Note that we only deem our dog guilty or not guilty. The dog is never pronounced innocent! Just like the U.S. court system, hypothesis testing works this way too.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing: A Drug Efficacy Example\n",
    "\n",
    "---\n",
    "\n",
    "Say we are testing the effectiveness of a new drug:\n",
    "\n",
    "- We randomly select 50 people to be in the *control group* who are given the old drug (the one currently on the market), and 50 people to recieve the treatment (or also known as the *experiment group*) in the context our our experiment run.\n",
    "    - In other experiments, the control group is the one that receives no treatment. There can be a placebo group as well, which is one that receives a false treatment. **Is this ethical in this scenario?**\n",
    "- We are interested in the average difference in blood pressure levels between the treatment and control groups to gauge the efficacy of the new drug.\n",
    "- We know our sample is selected from a broader, unknown population pool.\n",
    "- We can imagine that, in a hypothetical parallel world, we could have ended up with a different random sample of subjects from the population pool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='null-hypothesis'></a>\n",
    "\n",
    "### The \"Null\" Hypothesis\n",
    "\n",
    "---\n",
    "\n",
    "The **null hypothesis** is typically the exact opposite of what you want to test for, i.e. the \"status quo\". We typically denote the null hypothesis with $H_0$.\n",
    "- In our dog example, we assume that our dog is innocent.\n",
    "- In our drug efficacy experiment example, our *null hypothesis* is that there is ***no difference in blood pressure between a subject taking a placebo and and one taking the treatment drug***.\n",
    "\n",
    "> $H_0:$ The *average difference* in blood pressure between treatment and control groups is ***zero***.\n",
    "\n",
    "Or, as it's properly written:\n",
    "\n",
    "> $H_0: \\mu_\\text{trt} = \\mu_\\text{ctrl}$\n",
    "\n",
    "Or, as it's often written:\n",
    "\n",
    "> $H_0: \\mu_\\text{trt} - \\mu_\\text{ctrl} = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='alternative-hypothesis'></a>\n",
    "\n",
    "### The \"Alternative Hypothesis\"\n",
    "\n",
    "---\n",
    "\n",
    "The **alternative hypothesis** is the outcome of the experiment that we hope to show. It's the ***opposite of our null hypothesis***!\n",
    "- In our dog example, the alternative hypothesis is that our dog is guilty of unspooling the toilet paper.\n",
    "- In our drug efficacy experiment example, the *alternative hypothesis* is that ***there is in fact an average difference in blood pressure between the treatment and control groups***. \n",
    "\n",
    "> $H_A:$ The parameter of interest (our *average difference* between treatment and control) is ***not zero***.\n",
    "\n",
    "Or, in math:\n",
    "\n",
    "> $H_A: \\mu_\\text{trt} \\ne \\mu_\\text{ctrl}$\n",
    "\n",
    "Again, we usually write\n",
    "\n",
    "> $H_A: \\mu_\\text{trt} - \\mu_\\text{ctrl} \\ne 0$\n",
    "\n",
    "**NOTE:** The null and alternative hypotheses are concerned with the true values, or, in other words, the **parameter of the overall population**. Through hypothesis testing, we will make an **inference** (a decision) about this ***population parameter***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is it written like this? $\\mu$ vs $\\bar{x}$\n",
    "(THREAD) Can you remind me what a *population parameter* is?\n",
    "\n",
    "(THREAD) Can you remind me what a *sample statistic* is?\n",
    "\n",
    "Population parameters are often denoted with Greek letters. It would make no sense to conduct a hypothesis test with sample statistics, since they differ with each experiment, and you don't need to hypothesize about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to the $t$-Test\n",
    "\n",
    "---\n",
    "\n",
    "In our dog example, we gathered data in a way that's different from how we'll usually gather data in order to make a decision.\n",
    "\n",
    "Say that, in our drug experiment, we measure the following results:\n",
    "\n",
    "- The 50 subjects in the control group have an average systolic blood pressure of 121.38.\n",
    "- The 50 subjects in the experimental/treatment group have an average systolic blood pressure of 111.56.\n",
    "\n",
    "The difference between experimental and control samples is -9.82 points. So? is this **statistically significant to make a data-driven decision on the efficacy of the new drug?**\n",
    "\n",
    "With **only 50 subjects** in each sample, how confident can we be that this measured difference is real? Do we have enough evidence to say that the population average blood pressure is different between these two groups?\n",
    "\n",
    "We can perform what is known as a **t-test** to evaluate this. (A $t$-test is one of many, many types of hypothesis tests.)\n",
    "\n",
    "***Four steps to hypothesis testing:***\n",
    "1. Construct a null hypothesis that you want to contradict and prove its complement, the alternative hypothesis.\n",
    "2. Specify a level (or threshold) of statistical significance.\n",
    "3. Calculate your test statistic.\n",
    "4. Find your $p$-value and make a conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bp    group\n",
       "0  166  control\n",
       "1  165  control\n",
       "2  120  control\n",
       "3   94  control\n",
       "4  104  control"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp = pd.read_csv(\"../data/blood-pressure.csv\")\n",
    "print(bp.shape)\n",
    "bp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['control', 'treatment'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at the values in 'group'\n",
    "bp['group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the blood pressure data into two separate vectors, corresponding to each group\n",
    "# (this is how we'll need it for a SciPy t-test)\n",
    "ctrl = bp.loc[bp[\"group\"] == \"control\", \"bp\"] # specifying row, col filter for control group\n",
    "trt = bp.loc[bp[\"group\"] == \"treatment\", \"bp\"] # specifying row, col filter for treatment group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    166\n",
       "1    165\n",
       "2    120\n",
       "3     94\n",
       "4    104\n",
       "Name: bp, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrl.head() # we get all the 'bp' values corresponding to control 'group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50     83\n",
       "51    100\n",
       "52    123\n",
       "53     75\n",
       "54    130\n",
       "Name: bp, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt.head() # we get all the 'bp' values corresponding to treatment 'group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([166, 165, 120,  94, 104, 166,  98,  85,  97,  87, 114, 100, 152,\n",
       "        87, 152, 102,  82,  80,  84, 109,  98, 154, 135, 164, 137, 128,\n",
       "       122, 146,  86, 146,  85, 101, 109, 105, 163, 136, 142, 144, 140,\n",
       "       128, 126, 119, 121, 126, 169,  87,  97, 167,  89, 155])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative way to also extract the bp values corresponding to control group\n",
    "bp[bp['group']=='control']['bp'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.38\n",
      "111.56\n",
      "-9.82\n"
     ]
    }
   ],
   "source": [
    "# Print the average of the control and experimental groups.\n",
    "print(ctrl.mean())\n",
    "print(trt.mean())\n",
    "print(round(trt.mean() - ctrl.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='likelihood-data'></a>\n",
    "\n",
    "### Step 1: Construct the null and alternative hypotheses\n",
    "\n",
    "---\n",
    "\n",
    "For our experiment, we will set up a null hypothesis and an alternative hypothesis:\n",
    "\n",
    "$H_0:$ The true mean difference in systolic blood pressure between those who receive the treatment and those who do not is 0.\n",
    "\n",
    "$H_A:$ The true mean difference in systolic blood pressure between those who receive the treatment and those who do not is NOT 0.\n",
    "\n",
    "### Formally:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "H_0: & \\mu_\\text{trt} = \\mu_\\text{ctrl} \\\\\n",
    "H_A: & \\mu_\\text{trt} \\ne \\mu_\\text{ctrl} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Recall, our measured difference is $\\bar{x}_\\text{trt} - \\bar{x}_\\text{ctrl} = -9.82$\n",
    "\n",
    "Written out using probability notation, we want to know:\n",
    "\n",
    "### $$P(\\text{data}\\;|\\;H_0 \\text{ true})$$\n",
    "\n",
    "**What is the probability that we observed this data, assuming that our null hypothesis is true?**\n",
    "\n",
    "If the probability is *low* --> **reject null hypothesis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Specify a level of significance\n",
    "\n",
    "If we assume that our null hypothesis is true, and the probability of observing the data we observed is \"small,\" then our data does not support our null hypothesis. \n",
    "\n",
    "**But how \"small\" is small enough?**\n",
    "\n",
    "This is set by our level of significance, which we call $\\alpha$.\n",
    "\n",
    "Typically (and arbitrarily) the value $\\alpha=0.05$ is used.\n",
    "\n",
    "We'll check if **p-value < =** $\\alpha$ ***to reject null hypothesis***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculating your Test Statistic\n",
    "\n",
    "---\n",
    "\n",
    "Remember that hypothesis testing is a \"box\" where the inputs are our data and the outputs allow us to make our decision? Well, in this \"box,\" we are calculating $P(\\text{data}\\;|\\;H_0 \\text{ true})$.\n",
    "\n",
    "When comparing two means, the **t-statistic** (based on the [Student's $t$-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution)) is a classic way to quantify the difference between groups. In essence, our $t$-statistic is a standardized version of the difference between groups.\n",
    "\n",
    "Luckily, our computer will do this for us!\n",
    "\n",
    "---\n",
    "\n",
    "<details><summary>Want the mathematical details of the calculation of the t-statistic?</summary>\n",
    "When comparing the difference between groups, we can calculate the two-sample t-statistic like so:\n",
    "\n",
    "### $$t = \\frac{\\bar{x}_E - \\bar{x}_C}{\\sqrt {s^2 \\Big(\\frac{1}{n_E} + \\frac{1}{n_C}\\Big)}}$$\n",
    "\n",
    "In our example, $\\bar{x}_E$ is the mean of our experimental group's sample measurements and $\\bar{x}_C$ is the mean of our control group's sample measurements.\n",
    "\n",
    "$n_E$ and $n_C$ are the number of observations in each group. \n",
    "\n",
    "The $s^2$ denotes our *sample variance*. In this version of the t-test, we are assuming equal variances in our experimental and control groups in the overall population. There is another way to calculate the t-test where equal variance is not assumed, but, in our case, it is a reasonable assumption.\n",
    "\n",
    "The sample variance is calculated like so:\n",
    "\n",
    "### $$ s^2 = \\frac{\\sum_{i=1}^{n_E} (x_i - \\bar{x}_E)^2 + \\sum_{j=1}^{n_C} (x_j - \\bar{x}_C)^2}{ n_E + n_C -2} $$\n",
    "\n",
    "This combines the variance of the two groups' measurements into a single pooled metric. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR What are we doing?\n",
    "(I just found out TL;DR stands for “Too Long; Didn’t Read.” Thanks to Google, again!!)\n",
    "\n",
    "**GOAL:** To tell *whether or not our new treatment is effective*. We define \"effective\" as ***whether or not those who get the treatment see lower systolic blood pressure, on average***, that is **statistically** significant.\n",
    "\n",
    "To do this, we follow the following steps to carry out a **hypothesis test**:\n",
    "\n",
    "1. Set up null and alternative hypotheses. Remember, ours was this:\n",
    "\n",
    "$$ H_0: \\mu_\\text{trt} - \\mu_\\text{ctrl} = 0 $$\n",
    "$$ H_A: \\mu_\\text{trt} - \\mu_\\text{ctrl} \\ne 0 $$\n",
    "\n",
    "2. Decide on a significance level. $\\alpha = 0.05$ is a typical choice.\n",
    "3. Decide on a hypothesis test. There are several different ones. In this case, we're testing the difference between two means, which is a great time to use a **two-sample $t$-test**.\n",
    "\n",
    "> The two-sample (independent) $t$-test tests whether or not two population means differ.\n",
    "\n",
    "4. After carrying out this hypothesis test, we'll see if our data provides enough evidence to reject the null hypothesis. And confirm that the difference in the mean blood pressure between the two groups being studied is statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do it!\n",
    "Uh... how? What function do I use? Help me, Google!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scipy.stats - I did tell about this at the beginning! Here we go..\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.8915462966190273, pvalue=0.061504240672530394)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conduct our t-test between treatment and control groups.\n",
    "# the stats test below does the T-test for the means of two independent samples of scores\n",
    "# toggling equal_var=False has NO impact in this case as we know ctrl & trt have EQUAL sample sizes\n",
    "stats.ttest_ind(trt, ctrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning t_statistic and p-value from the scipy stat test to 2 variables\n",
    "t_stat, p_value = stats.ttest_ind(trt, ctrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p-value'></a>\n",
    "\n",
    "### Step 4: The P-Value\n",
    "\n",
    "---\n",
    "\n",
    "Remember that our goal of doing all of this work is to make a decision? Well, using our $t$-statistic, we can generate a **p-value**.\n",
    "\n",
    "> **The p-value is the probability that, given that the null hypothesis $H_0$ is true, we could have ended up with a statistic at least as extreme as the one we got.**\n",
    "\n",
    "We have measured a difference in blood pressure of -9.82 between the experimental and control groups. We then calculated a $t$-statistic associated with this difference of -1.89. In our specific example:\n",
    "\n",
    "> The p-value is the probability that, assuming there is truly no difference in blood pressure between treatment and control conditions (i.e., no effect of the drug), we get results that yield a t-statistic more extreme than -1.89."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how do we make the decision? *(This will show up in interviews!)*\n",
    "\n",
    "Remember that $\\alpha$ is our level of significance.\n",
    "\n",
    "- If $p\\text{-value} < \\alpha$, then ***there is evidence to reject the null hypothesis***, so you accept that $H_0$ is incorrect and therefore $H_A$ is correct.\n",
    "    - i.e., **a statisically significant difference between the two groups!**\n",
    "    - This is like saying there is enough evidence to say our dog isn't innocent... so we say our dog is guilty.\n",
    "- If $p\\text{-value} \\ge \\alpha$, then there is ***insufficient evidence to reject the null hypothesis*** and you cannot accept that either $H_0$ or $H_A$ is correct.\n",
    "    - i.e., there is **no statistical difference between your two groups.**\n",
    "    - This is like saying there is not enough evidence to say our dog isn't innocent. We can't totally determine that our dog is innocent, but we haven't determined that our dog is guilty, either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So.... what is our decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **DECISION:** Because our $p$-value *(0.06 from our stats test) is greater than* our $\\alpha = 0.05$, **we fail to reject our null hypothesis**. We do not have enough evidence to conclude that the mean systolic blood pressure differs between the treatment and placebo group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for good measure... what's the opposite opinion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **DECISION:** Because our p-value was below 0.05, we reject the null hypothesis and conclude that the mean blood pressure between the treatment and control group differs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Law of Parsimony (aka: Occam's Razor)\n",
    "This is usually paraphrased as:\n",
    "> The simplest explanation for a phenomenon is usually the correct one.\n",
    "\n",
    "We don't want to overspecify our model. In our context, that means we want to avoid any potential overfitting. While we **never accept the null hypothesis**, the truth is, _some decision must be made_. Oftentimes, we drop variables from our model that do not have significant $p$-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Hypothesis Tests\n",
    "The goal of this lesson was to teach you, in general, how hypothesis testing works. We showed you what is probably the most common variety of hypothesis test: the $t$-test. However, there are several other ones out there. It's not worth our time to go over so many more of them, as they all have the same implementation and interpretation, just used in different situations. Instead, here is a list of many of the \"big\" ones and when to use them:\n",
    "\n",
    "| Situation | Common hypothesis test | Example | Notes |\n",
    "| --- | --- | --- | --- |\n",
    "| Testing whether or not one mean is equal to a value | One-sample $t$-test | Do cars on a given road, on average, drive about 65mph? | |\n",
    "| Testing whether or not two means are equal to eachother | Two-sample $t$-test | Is the mean systolic blood pressure of people who receive Medicine A or Medicine B the same? | |\n",
    "| Testing whether or not paired observations have the same value | Paired $t$-test | Among heterosexual married couples, is the husband, on average, taller than the wife? | This is functionally the same as a one-sample $t$-test of the differences |\n",
    "| Testing whether or not three or more means are the same | One-way ANOVA test | Testing for normally distributed variables. Examples - Are base salaries upon graduation different for graduates of Penn State, Ohio State, and Michigan? | The ANOVA test has many variants |\n",
    "| Testing whether or not there is a relationship between two categorical variables | $\\chi^2$ test (read as kie squared) | Is there a relationship between home state and political affiliation? | |\n",
    "| Testing whether or not a given distribution is normally distributed | Kolmogorov-Smirnov Test | Testing whether or not model residuals are normally distributed. Useful for testing linear regression assumptions! | |\n",
    "| Testing whether or not one proportion is equal to a number | One-sample $z$-test | Testing whether or not a coin is fair (ie, testing $P(Heads) = 0.5$) | |\n",
    "| Testing whether or not two proportions are euqal | Two-sample $z$-test | Who is going to win an election? | Testing two or more proportions can be done better with a $\\chi^2$ test |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "Four steps to hypothesis testing:\n",
    "1. Construct a null hypothesis that you want to contradict and its complement, the alternative hypothesis.\n",
    "2. Specify a level of significance.\n",
    "3. Calculate your test statistic.\n",
    "4. Find your $p$-value and make a conclusion."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
